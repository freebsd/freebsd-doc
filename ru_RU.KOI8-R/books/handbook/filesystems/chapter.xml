<?xml version="1.0" encoding="koi8-r"?>
<!--
     The FreeBSD Russian Documentation Project
     $FreeBSD$
     Original revision: r34969
-->
<!--
Translation:    Taras Korenko
-->
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="filesystems">
  <info><title>Поддержка файловых систем</title>
    <authorgroup>
      <author><personname><firstname>Tom</firstname><surname>Rhodes</surname></personname><contrib>Написал </contrib></author>
    </authorgroup>
  </info>

  

  <sect1 xml:id="filesystems-synopsis">
    <title>Краткий обзор</title>

    <indexterm>
       <primary>Файловые Системы</primary>
    </indexterm>

    <indexterm>
      <primary>File Systems Support</primary>
      <see>File Systems</see>
    </indexterm>

    <para>Файловые системы &mdash; неотъемлемая часть любой операционной
      системы.  Они позволяют пользователям записывать и хранить файлы,
      получать доступ к данным, и, конечно-же, пользоваться жесткими дисками.
      У разных операционных систем есть одна общая черта &mdash;
      их основная файловая система (native filesystem).  Для &os; это Fast
      File System (или <acronym>FFS</acronym>), которая произошла от
      Unix&trade; File System (сокращенно <acronym>UFS</acronym>).</para>

    <para>&os; также поддерживает ряд других файловых систем, тем самым
      предоставляя возможность получать доступ к данным от других операционных
      систем локально, например: к данным, находящимся на подключенных
      <acronym>USB</acronym> устройствах хранения, флэш-накопителях и жестких
      дисках.  В списке поддерживаемых есть файловые системы, разработанные
      для других операционных систем, например &linux; Extended File System
      (<acronym>EXT</acronym>) и &sun; Z File System
      (<acronym>ZFS</acronym>).</para>

    <para>&os; имеет разные уровни поддержки для разных файловых систем.
      Для некоторых будет достаточно загрузки модуля ядра, другим может
      потребоваться установка набора утилит (toolset).  Цель этого раздела
      &mdash; дать представления пользователям &os; о возможностях
      использования других файловых систем на их операционных системах.
      Начнем с &sun; Z file system.</para>

    <para>После прочтения этого раздела вы будете знать:</para>

    <itemizedlist>
      <listitem>
	<para>Разницу между основной и поддерживаемой файловой системой.</para>
      </listitem>

      <listitem>
	<para>Какие файловые системы поддерживаются &os;.</para>
      </listitem>

      <listitem>
	<para>Как подключить, сконфигурировать, получить доступ и использовать
	  поддерживаемые файловые системы.</para>
      </listitem>
    </itemizedlist>

    <para>Перед прочтением этого раздела вам необходимо:</para>

    <itemizedlist>
      <listitem>
	<para>Понимать основы &unix; и &os; (<xref linkend="basics"/>).</para>
      </listitem>

      <listitem>
	<para>Знать азы конфигурирования и компиляции ядра
	  (<xref linkend="kernelconfig"/>).</para>
      </listitem>

      <listitem>
	<para>Уметь устанавливать приложения сторонних разработчиков
	  в &os; (<xref linkend="ports"/>).</para>
      </listitem>

      <listitem>
	<para>Быть знакомым с именованием дисков и устройств хранения
	  в &os; (<xref linkend="disks"/>).</para>
      </listitem>
    </itemizedlist>
  </sect1>

  <sect1 xml:id="filesystems-zfs">
    <title>Файловая система ZFS</title>

    <para>Файловая система ZFS, разработанная компанией &sun;, основана
      на использовании метода пулов устройств хранения данных.  Это
      значит, что емкость носителя занимается только тогда, когда она
      становится необходимой для сохранения данных.  ZFS также была
      разработана с упором на максимальную целостность данных, поддерживая
      снимки (snapshot), множество копий и контрольные суммы данных.  Новая
      модель репликации данных, известная как <acronym>RAID</acronym>-Z,
      подобна <acronym>RAID</acronym>-5, но специально разработана для
      предотвращения повреждений данных при записи.</para>

    <sect2>
      <title>Настройка ZFS</title>

      <para>Подсистема <acronym>ZFS</acronym> занимает значительную часть
	ресурсов системы.  Чтобы получить от нее максимум эффективности
	в повседневном использовании, потребуется выполнить некоторые
	настройки.  <acronym>ZFS</acronym> является экспериментальной
	функциональной возможностью в &os;, но ситуация может измениться
	в ближайшем будущем; однако на данный момент рекомендуется выполнить
	следующие шаги.</para>

      <sect3>
	<title>Память</title>

	<para>Общий размер ОЗУ должен быть как минимум равен одному гигабайту,
	  хотя рекомендуется два гигабайта или более.  Во всех нижеследующих
	  примерах используется система с 1ГБ памяти совместно с другими
	  специальными настройками.</para>

	<para>Известно, что некоторые пользователи преуспели в использовании
	  <acronym>ZFS</acronym> на системах, имеющих менее одного гигабайта
	  памяти, но с таким ограниченным объемом ОЗУ и при серьезной загрузке
	  машины очень вероятны паники &os; из-за нехватки памяти.</para>
      </sect3>

      <sect3>
	<title>Настройка ядра</title>

	<para>Рекомендуется исключить из файла конфигурации ядра
	  неиспользуемые драйвера и опции.  Так как большинство драйверов
	  устройств доступно в виде модулей, то они просто могут быть загружены
	  с помощью соответствующих записей в файле
	  <filename>/boot/loader.conf</filename>.</para>

	<para>Пользователям архитектуры &i386; необходимо добавить
	  следующую опцию в их файл конфигурации ядра, перестроить
	  ядро и перезагрузиться:</para>

	<programlisting>options         KVA_PAGES=512</programlisting>

	<para>Эта опция расширит адресное пространство ядра, тем самым позволяя
	  переменной <varname>vm.kvm_size</varname> быть установленной за
	  текущий предел в 1&nbsp;ГБ (2&nbsp;ГБ для <acronym>PAE</acronym>).
	  Чтобы найти наиболее подходящее значение для этой опции, разделите
	  имеющийся объем ОЗУ, выраженный в мегабайтах, на 4.  Приведенное
	  выше значение <literal>512</literal> рекомендуется для систем
	  с 2&nbsp;ГБ оперативной памяти.</para>
      </sect3>

      <sect3>
	<title>Параметры loader.conf</title>

	<para>Адресное пространство <filename>kmem</filename> должно быть
	  увеличено на всех &os; архитектурах.  На тестовой системе с одним
	  гигабайтом физической памяти стабильная работа была получена со
	  следующими параметрами, которые необходимо внести в файл
	  <filename>/boot/loader.conf</filename> и перезагрузить
	  систему.</para>

	<programlisting>vm.kmem_size="330M"
vm.kmem_size_max="330M"
vfs.zfs.arc_max="40M"
vfs.zfs.vdev.cache.size="5M"</programlisting>

	<para>За более детальными рекомендациями по тонкой настройке
	  системы под ZFS, обратитесь к странице:
	  <uri xlink:href="http://wiki.freebsd.org/ZFSTuningGuide">http://wiki.freebsd.org/ZFSTuningGuide</uri>.</para>
      </sect3>
    </sect2>

    <sect2>
      <title>Использование <acronym>ZFS</acronym></title>

      <para>Существует стартовый механизм, позволяющий монтировать
	<acronym>ZFS</acronym> пулы во время инициализации системы.
	Чтобы его задействовать, выполните следующие команды:</para>

	<screen>&prompt.root; <userinput>echo 'zfs_enable="YES"' &gt;&gt; /etc/rc.conf</userinput>
&prompt.root; <userinput>/etc/rc.d/zfs start</userinput></screen>

	<para>Здесь и далее в статье подразумевается, что в системе
	  установлено три <acronym>SCSI</acronym> диска с именами
	  устройств
	  <filename><replaceable>da0</replaceable></filename>,
	  <filename><replaceable>da1</replaceable></filename> и
	  <filename><replaceable>da2</replaceable></filename>.
	  Использующим <acronym>IDE</acronym> диски необходимо
	  подставить имена устройств
	  <filename><replaceable>ad</replaceable></filename>
	  вместо имен устройств <acronym>SCSI</acronym>.</para>

      <sect3>
	<title>Простой дисковый пул</title>

	<para>Для создания простого пула <acronym>ZFS</acronym>
	  без избыточности, задействовав при этом один жесткий диск,
	  воспользуйтесь командой <command>zpool</command>:</para>

	<screen>&prompt.root; <userinput>zpool create example /dev/da0</userinput></screen>

	<para>Чтобы увидеть новый пул, просмотрите вывод команды
	  <command>df</command>:</para>

	<screen>&prompt.root; <userinput>df</userinput>
Filesystem  1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a   2026030  235230  1628718    13%    /
devfs               1       1        0   100%    /dev
/dev/ad0s1d  54098308 1032846 48737598     2%    /usr
example      17547136       0 17547136     0%    /example</screen>

	<para>Этот вывод четко показывает, что пул <literal>example</literal>
	  был не только создан, но также и <emphasis>примонтирован</emphasis>.
	  Он также доступен, как и обычная файловая система, в нем можно
	  создавать файлы, а пользователи могут просматривать его содержимое,
	  например:</para>

	<screen>&prompt.root; <userinput>cd /example</userinput>
&prompt.root; <userinput>ls</userinput>
&prompt.root; <userinput>touch testfile</userinput>
&prompt.root; <userinput>ls -al</userinput>
total 4
drwxr-xr-x   2 root  wheel    3 Aug 29 23:15 .
drwxr-xr-x  21 root  wheel  512 Aug 29 23:12 ..
-rw-r--r--   1 root  wheel    0 Aug 29 23:15 testfile</screen>

	<para>Однако в этом примере простого пула не задействованы
	  никакие функциональные возможности <acronym>ZFS</acronym>.
	  Создайте файловую систему в этом пуле и активируйте
	  сжатие данных на ней:</para>

	<screen>&prompt.root; <userinput>zfs create example/compressed</userinput>
&prompt.root; <userinput>zfs set compression=gzip example/compressed</userinput></screen>

	<para>С этого момента для файловой системы <acronym>ZFS</acronym>
	  <literal>example/compressed</literal> активировано сжатие данных.
	  Попробуйте поместить на нее несколько больших файлов
	  копируя их в
	  <filename>/example/compressed</filename>.</para>


	<para>А вот как можно отключить сжатие данных:</para>

	<screen>&prompt.root; <userinput>zfs set compression=off example/compressed</userinput></screen>

	<para>Для того чтобы размонтировать файловую систему, выполните
	  следующую команду и проверьте результат утилитой
	  <command>df</command>:</para>

	<screen>&prompt.root; <userinput>zfs umount example/compressed</userinput>
&prompt.root; <userinput>df</userinput>
Filesystem  1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a   2026030  235232  1628716    13%    /
devfs               1       1        0   100%    /dev
/dev/ad0s1d  54098308 1032864 48737580     2%    /usr
example      17547008       0 17547008     0%    /example</screen>

	<para>Снова смонтируйте файловую систему и проверьте результат
	  при помощи <command>df</command>:</para>

	<screen>&prompt.root; <userinput>zfs mount example/compressed</userinput>
&prompt.root; <userinput>df</userinput>
Filesystem         1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a          2026030  235234  1628714    13%    /
devfs                      1       1        0   100%    /dev
/dev/ad0s1d         54098308 1032864 48737580     2%    /usr
example             17547008       0 17547008     0%    /example
example/compressed  17547008       0 17547008     0%    /example/compressed</screen>

	<para>Пул и файловая система также отображается в выводе
	  команды <command>mount</command>:</para>

	<screen>&prompt.root; <userinput>mount</userinput>
/dev/ad0s1a on / (ufs, local)
devfs on /dev (devfs, local)
/dev/ad0s1d on /usr (ufs, local, soft-updates)
example on /example (zfs, local)
example/data on /example/data (zfs, local)
example/compressed on /example/compressed (zfs, local)</screen>

	<para>Как вы уже убедились, файловые системы <acronym>ZFS</acronym>
	  после создания могут использоваться как и обычные файловые
	  системы; однако доступно множество других возможностей.  В следующем
	  примере мы создадим новую файловую систему <literal>data</literal>.
	  На ней мы будем содержать важные данные, поэтому файловая система
	  сконфигурирована хранить две копии каждого блока:</para>

	<screen>&prompt.root; <userinput>zfs create example/data</userinput>
&prompt.root; <userinput>zfs set copies=2 example/data</userinput></screen>

	<para>Снова проверьте свободное и использованное место выполнив
	  команду <command>df</command>:</para>

	<screen>&prompt.root; <userinput>df</userinput>
Filesystem         1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a          2026030  235234  1628714    13%    /
devfs                      1       1        0   100%    /dev
/dev/ad0s1d         54098308 1032864 48737580     2%    /usr
example             17547008       0 17547008     0%    /example
example/compressed  17547008       0 17547008     0%    /example/compressed
example/data        17547008       0 17547008     0%    /example/data</screen>

	<para>Заметьте, что каждая файловая система в пуле имеет тот же объем
	  свободного места.  Мы использовали команду <command>df</command>
	  на протяжении этих примеров, чтобы показать, что файловые системы
	  занимают только необходимое им пространство, используя ресурс
	  одного и того же пула.  <acronym>ZFS</acronym> уходит от привычных
	  понятий "том (volume)" и "раздел (partition)", позволяя файловым
	  системам занимать один и тот же пул.  Уничтожьте файловые системы,
	  потом уничтожьте пул, так как в них уже нет нужды:</para>

	<screen>&prompt.root; <userinput>zfs destroy example/compressed</userinput>
&prompt.root; <userinput>zfs destroy example/data</userinput>
&prompt.root; <userinput>zpool destroy example</userinput></screen>

	<para>Жесткие диски со временем выходят из строя, это неизбежно.
	  Когда этот диск выйдет из строя, данные будут утеряны.  Одним из
	  способов избежать потери данных из-за вышедшего из строя жесткого
	  диска является построение <acronym>RAID</acronym> массивов.
	  <acronym>ZFS</acronym> поддерживает эту функциональную возможность
	  в своем дизайне, и это описано в следующем разделе.</para>
      </sect3>

      <sect3>
	<title><acronym>ZFS</acronym> RAID-Z</title>

	<para>Как уже было сказано выше, в этой статье подразумевается,
	  что в нашей системе в распоряжении есть три <acronym>SCSI</acronym>
	  диска: <filename>da0</filename>, <filename>da1</filename>
	  и <filename>da2</filename> (или <filename>ad0</filename>
	  и далее в случае <acronym>IDE</acronym> дисков).  Для того, чтобы
	  создать <acronym>RAID</acronym>-Z пул, выполните следующую
	  команду:</para>

	<screen>&prompt.root; <userinput>zpool create storage raidz da0 da1 da2</userinput></screen>

	<note>
	  <para>&sun; рекомендует использовать от трех до девяти жестких дисков
	    в конфигурации <acronym>RAID</acronym>-Z.  Если есть необходимость
	    в использовании 10 или более дисков, подумайте над тем, чтобы
	    разбить их на меньшие группы <acronym>RAID</acronym>-Z.  Если у вас
	    есть только два диска и вам всё-таки требуется избыточность,
	    возможно лучшим вариантом будет создание <acronym>ZFS</acronym>
	    зеркала.  Смотрите страницу справочника &man.zpool.8;
	    для получения более подробных сведений.</para>
	</note>

	<para>По завершении команды должен создаться пул
	  <literal>storage</literal>.  Как и прежде, это может быть проверено
	  при помощи команд &man.mount.8; и &man.df.1;.  Больше дисковых
	  устройств может быть задействовано путем добавления их в конец списка
	  параметров команды, приведенной выше.  Создайте в пуле новую файловую
	  систему, называемую <literal>home</literal>, в которой будут
	  размещаться пользовательские файлы:</para>

	<screen>&prompt.root; <userinput>zfs create storage/home</userinput></screen>

	<para>На данном этапе возможно активировать сжатие данных и
	  организовать автоматическое создание копий пользовательских домашних
	  каталогов и файлов.  Это может быть достигнуто так же, как и ранее,
	  при помощи следующих команд:</para>

	<screen>&prompt.root; <userinput>zfs set copies=2 storage/home</userinput>
&prompt.root; <userinput>zfs set compression=gzip storage/home</userinput></screen>

	<para>Чтобы организовать в этой файловой системе хранение домашних
	  каталогов пользователей, скопируйте сюда их содержимое и создайте
	  соответствующие символические ссылки:</para>

	<screen>&prompt.root; <userinput>cp -rp /home/* /storage/home</userinput>
&prompt.root; <userinput>rm -rf /home /usr/home</userinput>
&prompt.root; <userinput>ln -s /storage/home /home</userinput>
&prompt.root; <userinput>ln -s /storage/home /usr/home</userinput></screen>

	<para>С этого момента пользовательские данные сохраняются на новой
	  файловой системе <filename>/storage/home</filename>.
	  Для проверки создайте учетную запись нового пользователя
	  и войдите ею в систему.</para>

	<para>Попробуйте создать снимок (snapshot), к которому можно будет
	  откатиться при необходимости:</para>

	<screen>&prompt.root; <userinput>zfs snapshot storage/home@08-30-08</userinput></screen>

	<para>Заметьте, что снимок (snapshot) захватит реальную файловую
	  систему, а не домашний каталог или файл.  Символ
	  <literal>@</literal> отделяет имя файловой системы или имя тома
	  от имени снимка.  Когда возникнет необходимость восстановить
	  пользовательские домашние каталоги, выполните следующую
	  команду:</para>

	<screen>&prompt.root; <userinput>zfs rollback storage/home@08-30-08</userinput></screen>

	<para>Чтобы получить список имеющихся в наличии снимков, выполните
	  команду <command>ls</command> в каталоге
	  <filename>.zfs/snapshot</filename>.  Например,
	  чтобы увидеть сделанный ранее снимок, выполните следующую
	  команду:</para>

	<screen>&prompt.root; <userinput>ls /storage/home/.zfs/snapshot</userinput></screen>

	<para>Можно написать скрипт, выполняющий снимки пользовательских данных
	  ежемесячно; однако, со временем, они могут занять значительную часть
	  дискового пространства.  Предыдущий снимок может быть удален
	  используя следующую команду:</para>

	<screen>&prompt.root; <userinput>zfs destroy storage/home@08-30-08</userinput></screen>

	<para>Нет причины после наших экспериментов далее держать
	  в текущем состоянии
	  <filename>/storage/home</filename>.
	  Сделаем ее реальной файловой системой
	  <filename>/home</filename>:</para>

	<screen>&prompt.root; <userinput>zfs set mountpoint=/home storage/home</userinput></screen>

	<para>Выполнение команд <command>df</command> и
	  <command>mount</command> покажет, что с этого момента операционная
	  система воспринимает нашу файловую систему как обычную
	  <filename>/home</filename>:</para>

	<screen>&prompt.root; <userinput>mount</userinput>
/dev/ad0s1a on / (ufs, local)
devfs on /dev (devfs, local)
/dev/ad0s1d on /usr (ufs, local, soft-updates)
storage on /storage (zfs, local)
storage/home on /home (zfs, local)
&prompt.root; <userinput>df</userinput>
Filesystem   1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a    2026030  235240  1628708    13%    /
devfs                1       1        0   100%    /dev
/dev/ad0s1d   54098308 1032826 48737618     2%    /usr
storage       26320512       0 26320512     0%    /storage
storage/home  26320512       0 26320512     0%    /home</screen>

	<para>На этом завершим конфигурацию <acronym>RAID</acronym>-Z.
	  Чтобы во время ночных запусков &man.periodic.8; получать информацию
	  о статусе созданных файловых систем, выполните следующую
	  команду:</para>

	<screen>&prompt.root; <userinput>echo 'daily_status_zfs_enable="YES"' &gt;&gt; /etc/periodic.conf</userinput></screen>
      </sect3>

      <sect3>
	<title>Восстановление <acronym>RAID</acronym>-Z</title>

	<para>Каждая система программных <acronym>RAID</acronym> массивов
	  предоставляет возможность отображать информацию о своем
	  <literal>состоянии</literal>.
	  <acronym>ZFS</acronym> &mdash; не исключение.  Статус устройств
	  <acronym>RAID</acronym>-Z может быть просмотрен при помощи
	  следующей команды:</para>

	<screen>&prompt.root; <userinput>zpool status -x</userinput></screen>

	<para>Если пулы исправны и всё нормально, возвратится следующее
	  сообщение:</para>

	<screen>all pools are healthy</screen>

	<para>А если есть какие-то неполадки, например диск выведен из массива,
	  возвращенное состояние пула будет подобным следующему:</para>

	<screen>  pool: storage
 state: DEGRADED
status: One or more devices has been taken offline by the administrator.
	Sufficient replicas exist for the pool to continue functioning in a
	degraded state.
action: Online the device using 'zpool online' or replace the device with
	'zpool replace'.
 scrub: none requested
config:

	NAME        STATE     READ WRITE CKSUM
	storage     DEGRADED     0     0     0
	  raidz1    DEGRADED     0     0     0
	    da0     ONLINE       0     0     0
	    da1     OFFLINE      0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</screen>

	<para>Вывод показывает, что устройство было переведено в автономный
	  режим	администратором.  Это верно для данного отдельного примера.
	  Чтобы перевести диск в автономный режим, была выполнена
	  команда:</para>

	<screen>&prompt.root; <userinput>zpool offline storage da1</userinput></screen>

	<para>Теперь после останова системы возможно заменить
	  <filename>da1</filename>.  Когда система загрузится снова,
	  выполните следующую команду чтобы заменить диск в массиве:</para>

	<screen>&prompt.root; <userinput>zpool replace storage da1</userinput></screen>

	<para>С этого момента статус может быть проверен опять и на этот раз
	  без флага <option>-x</option>:</para>

	<screen>&prompt.root; <userinput>zpool status storage</userinput>
 pool: storage
 state: ONLINE
 scrub: resilver completed with 0 errors on Sat Aug 30 19:44:11 2008
config:

	NAME        STATE     READ WRITE CKSUM
	storage     ONLINE       0     0     0
	  raidz1    ONLINE       0     0     0
	    da0     ONLINE       0     0     0
	    da1     ONLINE       0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</screen>

	<para>В выводе сообщается, что при перестроении массива ошибок
	  обнаружено не было.</para>
      </sect3>

      <sect3>
	<title>Проверка данных</title>

	<para>Как уже было сказано ранее, <acronym>ZFS</acronym> использует
	  <literal>контрольные суммы</literal> для проверки целостности
	  сохраненных данных.  Подсчет и сохранение контрольных сумм включается
	  автоматически во время создания файловых систем и может быть отключен
	  при помощи команды:</para>

	<screen>&prompt.root; <userinput>zfs set checksum=off storage/home</userinput></screen>

	<para>Отключение подсчета контрольных сумм &mdash; не очень хорошая
	  идея; особенно ввиду того, что они занимают мало места, а также
	  при их использовании нет существенных расходов ресурсов системы.
	  Пока подсчет включен, возможно выполнять проверки целостности данных
	  <acronym>ZFS</acronym>, используя контрольные суммы.  Этот процесс
	  известен как <quote>очистка (scrubbing)</quote>.  Чтобы проверить
	  целостность данных пула <literal>storage</literal>, выполните
	  следующую команду:</para>

	<screen>&prompt.root; <userinput>zpool scrub storage</userinput></screen>

	<para>Этот процесс может занять значительное время в зависимости
	  от количества сохранённых данных.  Очистка (scrubbing) порождает
	  интенсивный ввод/вывод, поэтому только один экземпляр этой операции
	  может выполняться в один момент времени.  После завершения очистки
	  (scrubbing) статус обновится, его можно просмотреть выполнив
	  следующий запрос:</para>

	<screen>&prompt.root; <userinput>zpool status storage</userinput>
 pool: storage
 state: ONLINE
 scrub: scrub completed with 0 errors on Sat Aug 30 19:57:37 2008
config:

	NAME        STATE     READ WRITE CKSUM
	storage     ONLINE       0     0     0
	  raidz1    ONLINE       0     0     0
	    da0     ONLINE       0     0     0
	    da1     ONLINE       0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</screen>

	<para>Время завершения отображается в простом виде в этом примере.
	  Очистка помогает удостовериться в целостности данных на протяжении
	  длительного времени.</para>

	<para>В этом разделе была освещена лишь малая часть возможностей
	  <acronym>ZFS</acronym>.  За более подробной информацией обратитесь
	  к страницам справочника &man.zfs.8; и &man.zpool.8;.</para>
      </sect3>
    </sect2>
  </sect1>

</chapter>
