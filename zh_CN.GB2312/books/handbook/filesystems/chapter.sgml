<!--
     The FreeBSD Documentation Project
     Original Revision: r37255
     $FreeBSD$
-->

<chapter id="filesystems">
  <chapterinfo>
    <authorgroup>
      <author>
	<firstname>Tom</firstname>
	<surname>Rhodes</surname>
	<contrib>Written by </contrib>
      </author>
    </authorgroup>
  </chapterinfo>

  <title>文件系统 Support</title>

  <sect1 id="filesystems-synopsis">
    <title>概述</title>

    <indexterm><primary>File Systems</primary></indexterm>
    <indexterm>
      <primary>File Systems Support</primary>
      <see>File Systems</see>
    </indexterm>

    <para>文件系统对于任何操作系统来说都是一个不可缺的部分。
      它们允许用户上载和存储文件，提供对数据的访问，当然，
      是使硬盘能具有实际的用途。不同的操作系统通常都有一个共同的主要方面，
      那就是它们原生的文件系统。在 &os;
      上这个文件系统通常被称为快速文件系统或者 <acronym>FFS</acronym>，
      这是基于原来的 Unix&trade; 文件系统，通常也被称为
      <acronym>UFS</acronym>。 这是 &os;
      用于在磁盘上访问数据的原生的文件系统。</para>

    <para>&os; 也支持数量繁多的不同的文件系统，
      用于提供本地从其他操作系统上访问数据的支持，
      那些就是指存放在本地挂载的 <acronym>USB</acronym>
      存储设备，闪存设备和硬盘上的数据。还支持一些非原生的文件系统。
      这些文件系统是在其他的操作系统上开发的，像 &linux;
      的扩展文件系统 （<acronym>EXT</acronym>），和 &sun;
      的 Z 文件系统 （<acronym>ZFS</acronym>）。</para>

    <para>&os; 上对于各种文件系统的支持分成不同的层次。
      一些要求加载内核模块，另外的可能要求安装一系列的工具。
      这一章节旨在帮助 &os; 用户在他们的系统上访问其他的文件系统，
      由 &sun; 的 Z 文件系统开始。</para>

    <para>在阅读了这一章节之后，你将了解：</para>

    <itemizedlist>
      <listitem>
        <para>原生与被支持的文件系统之间的区别。</para>
      </listitem>

      <listitem>
        <para>&os; 支持哪些文件系统。</para>
      </listitem>

      <listitem>
        <para>如何起用，配置，访问和使用非原生的文件系统。</para>
      </listitem>
    </itemizedlist>

    <para>在阅读这章以前，你应该：</para>

    <itemizedlist>
      <listitem>
        <para>了解 &unix; 和 &os; 基本知识
	  (<xref linkend="basics">)。</para>
      </listitem>

      <listitem>
        <para>熟悉基本的内核配置/编译方法
	  (<xref linkend="kernelconfig">)。</para>
      </listitem>

      <listitem>
        <para>熟悉在 &os; 上安装第三方软件
          (<xref linkend="ports">)。</para>
      </listitem>

      <listitem>
        <para>熟悉 &os; 上的磁盘，存储和设备名
          (<xref linkend="disks">)。</para>
      </listitem>
    </itemizedlist>
  </sect1>

  <sect1 id="filesystems-zfs">
    <title>Z 文件系统 (ZFS)</title>

    <para>Z 文件系统是由 &sun; 开发使用存储池方法的新技术。
      这就是说只有在需要存储数据的时候空间才会被使用。
      它也为保护数据最大完整性而设计的，支持数据快照，
      多份拷贝和数据校验。增加了被称为 <acronym>RAID</acronym>-Z
      的新的数据复制类型。<acronym>RAID</acronym>-Z 是种类似于
      <acronym>RAID</acronym>5类型, 但被设计成防止写入漏洞。<para>

    <sect2>
      <title>调整 ZFS</title>

      <para><acronym>ZFS</acronym> 子系统需利用到大量的系统资源，
        所以可能需要一些调校来为日常应用提供最大化的效能。
        作为 &os; 的一项试验性的特性，这可能在不久的将来有所变化；
        无论如何，下面的这些步骤是我们推荐的：</para>

      <sect3>
        <title>内存</title>

        <para>总共的系统内存至少应有 1GB，推荐 2GB 或者更多。
          在此处所有的例子中，我们使用了 1GB
          内存的系统并配合了一些恰当的调校。</para>

        <para>有些人在少于 1GB 内存的环境有幸正常使用，
          但是在这样有限的物理内存的条件下，当系统的负载很高时，
          &os; 极有可能因于内存耗尽而崩溃。</para>
      </sect3>

      <sect3>
        <title>内核配置</title>

        <para>我们建议把未使用的驱动和选项从内核配置文件中去除。
          既然大部份的驱动都有以模块的形式存在，它们就可以很容易的通过
          <filename>/boot/loader.conf</filename> 加载。</para>

        <para>&i386; 构架的用户应在内核配置文件中加入以下的选项，
          重新编译内核并重启机器：</para>

	<programlisting>options 	KVA_PAGES=512</programlisting>

        <para>这个选项将扩展内核的地址空间， 因而允许
          <varname>vm.kvm_size</varname> 能够超越 1&nbsp;GB
          的限制(<acronym>PAE</acronym>为 2&nbsp;GB)。
          为了找出这个选项最合适的值，
          把以兆(MB)为单位所需的地址空间除以 4 得到。
          在这个例子中，<literal>512</literal> 则为 2&nbsp;GB。</para>
      </sect3>

      <sect3>
        <title>Loader 可调参数</title>

        <para>所有构架上 &os; 都应该加大 <devicename>kmem</devicename> 
          地址空间。在有 1GB 物理内存的测试系统上，在
          <filename>/boot/loader.conf</filename>
          中加入如下的参数并且重启后通过了测试。</para>

	<programlisting>vm.kmem_size="330M"
vm.kmem_size_max="330M"
vfs.zfs.arc_max="40M"
vfs.zfs.vdev.cache.size="5M"</programlisting>

	<para>更多 ZFS 相关推荐调校的细节请参阅
	  <ulink url="http://wiki.freebsd.org/ZFSTuningGuide"></ulink>.</para>
      </sect3>
    </sect2>

    <sect2>
      <title>使用 <acronym>ZFS</acronym></title>

      <para>&os; 有一种启动机制能在系统初始化时挂载
        <acronym>ZFS</acronym> 存储池。
        可以通过以下的命令设置：</para>

	<screen>&prompt.root; <userinput>echo 'zfs_enable="YES"' &gt;&gt; /etc/rc.conf</userinput>
&prompt.root; <userinput>/etc/rc.d/zfs start</userinput></screen>

        <para>这份文档剩余的部分假定系统中有 3 块
          <acronym>SCSI</acronym> 磁盘可用，
          它们的设备名分别为
	  <devicename><replaceable>da0</replaceable></devicename>，
          <devicename><replaceable>da1</replaceable></devicename>
	  和 <devicename><replaceable>da2</replaceable></devicename>。
          <acronym>IDE</acronym> 硬件的用户可以使用
          <devicename><replaceable>ad</replaceable></devicename>
          代替 <acronym>SCSI</acronym>。</para>
      <sect3>
        <title>单个磁盘存储池</title>

        <para>在单个磁盘上创建一个简单， 非冗余的 <acronym>ZFS</acronym>，
          使用 <command>zpool</command> 命令：</para>

	<screen>&prompt.root; <userinput>zpool create example /dev/da0</userinput></screen>

        <para>可以通过 <command>df</command>
          的输出查看新的存储池：</para>

	<screen>&prompt.root; <userinput>df</userinput>
Filesystem  1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a   2026030  235230  1628718    13%    /
devfs               1       1        0   100%    /dev
/dev/ad0s1d  54098308 1032846 48737598     2%    /usr
example      17547136       0 17547136     0%    /example</screen>

        <para>这份输出清楚的表明了 <literal>example</literal>
          存储池不仅创建成功而且被 <emphasis>挂载</emphasis> 了。
          我们能像访问普通的文件系统那样访问它，
          就像以下例子中演示的那样，用户能够在上面创建文件并浏览：</para>

	<screen>&prompt.root <userinput>cd /example</userinput>
&prompt.root; <userinput>ls</userinput>
&prompt.root; <userinput>touch testfile</userinput>
&prompt.root; <userinput>ls -al</userinput>
total 4
drwxr-xr-x   2 root  wheel    3 Aug 29 23:15 .
drwxr-xr-x  21 root  wheel  512 Aug 29 23:12 ..
-rw-r--r--   1 root  wheel    0 Aug 29 23:15 testfile</screen>

        <para>遗憾的是这个存储池并没有利用到
          <acronym>ZFS</acronym> 的任何特性。
          在这个存储池上创建一个文件系统，并启用压缩：</para>

	<screen>&prompt.root; <userinput>zfs create example/compressed</userinput>
&prompt.root; <userinput>zfs set compression=gzip example/compressed</userinput></screen>

        <para>现在 <literal>example/compressed</literal>
          是一个启用了压缩的 <acronym>ZFS</acronym> 文件系统了。
          可以尝试复制一些大的文件到
          <filename class="directory">/example/compressed</filename>。</para>

        <para>使用这个命令可以禁用压缩：</para>

	<screen>&prompt.root; <userinput>zfs set compression=off example/compressed</userinput></screen>

        <para>使用如下的命令卸载这个文件系统，并用
          <command>df</command> 工具确认：</para>

	<screen>&prompt.root; <userinput>zfs umount example/compressed</userinput>
&prompt.root; <userinput>df</userinput>
Filesystem  1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a   2026030  235232  1628716    13%    /
devfs               1       1        0   100%    /dev
/dev/ad0s1d  54098308 1032864 48737580     2%    /usr
example      17547008       0 17547008     0%    /example</screen>

        <para>重新挂在这个文件系统使之能被访问，
          并用 <command>df</command> 确认：</para>

	<screen>&prompt.root; <userinput>zfs mount example/compressed</userinput>
&prompt.root; <userinput>df</userinput>
Filesystem         1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a          2026030  235234  1628714    13%    /
devfs                      1       1        0   100%    /dev
/dev/ad0s1d         54098308 1032864 48737580     2%    /usr
example             17547008       0 17547008     0%    /example
example/compressed  17547008       0 17547008     0%    /example/compressed</screen>

        <para>存储池与文件系统也可通过 <command>mount</command>
          的输出查看：</para>

	<screen>&prompt.root; <userinput>mount</userinput>
/dev/ad0s1a on / (ufs, local)
devfs on /dev (devfs, local)
/dev/ad0s1d on /usr (ufs, local, soft-updates)
example on /example (zfs, local)
example/data on /example/data (zfs, local)
example/compressed on /example/compressed (zfs, local)</screen>

        <para>正如前面所提到的，<acronym>ZFS</acronym> 文件系统，
          在创建之后就能像普通的文件系统那样使用。然而，
          还有很多其他的特性是可用的。在下面的例子中，
          我们将创建一个新的文件系统，<literal>data</literal>。
          并要在上面存储些重要的文件，
          所以文件系统需要被设置成把每一个数据块都保存两份拷贝：</para>

	<screen>&prompt.root; <userinput>zfs create example/data</userinput>
&prompt.root; <userinput>zfs set copies=2 example/data</userinput></screen>

        <para>现在可以再次使用 <command>df</command>
          查看数据和空间的使用状况：</para>

	<screen>&prompt.root; <userinput>df</userinput>
Filesystem         1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a          2026030  235234  1628714    13%    /
devfs                      1       1        0   100%    /dev
/dev/ad0s1d         54098308 1032864 48737580     2%    /usr
example             17547008       0 17547008     0%    /example
example/compressed  17547008       0 17547008     0%    /example/compressed
example/data        17547008       0 17547008     0%    /example/data</screen>

        <para>请注意存储池上的每一个文件系统都有着相同数量的可用空间。
          这就是我们在这些例子中使用 <command>df</command> 的原因，
          是为了文件系统都是从相同的存储池取得它们所需的空间。
          <acronym>ZFS</acronym> 去掉了诸如卷和分区此类的概念，
          并允许多个文件系统占用同一个存储池。
          不再需要文件系统与存储池的时候能像这样销毁它们：</para>

	<screen>&prompt.root; <userinput>zfs destroy example/compressed</userinput>
&prompt.root; <userinput>zfs destroy example/data</userinput>
&prompt.root; <userinput>zpool destroy example</userinput></screen>

        <para>磁盘无法避免的会坏掉和停止运转。
          当这块磁盘坏掉的时候，上面的数据都将丢失。
          一个避免因磁盘损坏而丢失数据的方法是使用
          <acronym>RAID</acronym>。<acronym>ZFS</acronym>
          在它的存储池设计中支持这样的特性，
          这便是下一节将探讨的。</para>
          
      </sect3>

      <sect3>
	<title><acronym>ZFS</acronym> RAID-Z</title>

        <para>正如前文中所提到的，这一章节将假设存在 3 个
          <acronym>SCSI</acronym> 设备，
          <devicename>da0</devicename>， <devicename>da1</devicename>
          和 <devicename>da2</devicename> (或者 <devicename>ad0</devicename>
          和超出此例使用了 IDE 磁盘)。 使用如下的命令创建一个
          <acronym>RAID</acronym>-Z 存储池:</para>

	<screen>&prompt.root; <userinput>zpool create storage raidz da0 da1 da2</userinput></screen>

        <note><para>&sun; 推荐在一个 <acronym>RAID</acronym>-Z
            配置中使用的磁盘数量为 3 至 9 块。
            如果你要求在单独的一个存储池中使用 10 块或更多的磁盘，
            请考虑分拆成更小 <acronym>RAID</acronym>-z 组。
            如果你只有 2 块磁盘， 并仍然需要冗余，
            请考虑使用 <acronym>ZFS</acronym> 的 mirror 特性。
            更多细节请参考 &man.zpool.8; 手册页。</para></note>

        <para>zpool <literal>storage</literal> 至此就创建好了。
          可以如前文提到的那样使用 &man.mount.8; 和 &man.df.1; 确认。
          如需配给更多的磁盘设备则把它们加这个列表的后面。
          在存储池上创建一个叫 <literal>home</literal> 的文件系统，
          用户的文件最终都将被保存在上面：</para>

	<screen>&prompt.root; <userinput>zfs create storage/home</userinput></screen>

        <para>像前文中提到的那样，用户的目录与文件也可启用压缩并保存多份拷贝，
          可通过如下的命令完成：</para>

	<screen>&prompt.root; <userinput>zfs set copies=2 storage/home</userinput>
&prompt.root; <userinput>zfs set compression=gzip storage/home</userinput></screen>

        <para>把用户的数据都拷贝过来并创建一个符号链接，
          让他们开始使用这个新的目录：</para>

	<screen>&prompt.root; <userinput>cp -rp /home/* /storage/home</userinput>
&prompt.root; <userinput>rm -rf /home /usr/home</userinput>
&prompt.root; <userinput>ln -s /storage/home /home</userinput>
&prompt.root; <userinput>ln -s /storage/home /usr/home</userinput></screen>

        <para>现在用户的数据应该都保存在新创建的
          <filename class="directory">/storage/home</filename>
          上了。 测试添加一个新用户并以这个身份登录。</para>

        <para>尝试创建一个可日后用来回退的快照：</para>

	<screen>&prompt.root; <userinput>zfs snapshot storage/home@08-30-08</userinput></screen>

        <para>请注意快照选项将只会抓取一个真实的文件系统，
          而不是某个用户目录或文件。<literal>@</literal>
          字符为文件系统名或卷名的分隔符。
          当用户目录被损坏时，可用如下命令恢复：</para>

	<screen>&prompt.root; <userinput>zfs rollback storage/home@08-30-08</userinput></screen>

        <para>获得所有可用快照的列表，可使用
          <command>ls</command> 命令查看文件系统的
          <filename class="directory">.zfs/snapshot</filename>
          目录。例如，执行如下命令来查看之前抓取的快照：</para>

	<screen>&prompt.root; <userinput>ls /storage/home/.zfs/snapshot</userinput></screen>

        <para>可以编写一个脚本来每月定期抓取用户数据的快照，久而久之，
          快照可能消耗掉大量的磁盘空间。
          之前创建的快照可用以下命令删除：</para>

	<screen>&prompt.root; <userinput>zfs destroy storage/home@08-30-08</userinput></screen>

        <para>在所有这些测试之后，我们没有理由再把
          <filename class="directory">/store/home</filename>
          这样放置了。让它称为真正的
          <filename class="directory">/home</filename>
          文件系统：</para>

	<screen>&prompt.root; <userinput>zfs set mountpoint=/home storage/home</userinput></screen>

        <para>使用 <command>df</command> 和
          <command>mount</command>
          命令将显示现在系统把我们的文件系统真正当作了
	  <filename class="directory">/home</filename>：</para>

	<screen>&prompt.root; <userinput>mount</userinput>
/dev/ad0s1a on / (ufs, local)
devfs on /dev (devfs, local)
/dev/ad0s1d on /usr (ufs, local, soft-updates)
storage on /storage (zfs, local)
storage/home on /home (zfs, local)
&prompt.root; <userinput>df</userinput>
Filesystem   1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a    2026030  235240  1628708    13%    /
devfs                1       1        0   100%    /dev
/dev/ad0s1d   54098308 1032826 48737618     2%    /usr
storage       26320512       0 26320512     0%    /storage
storage/home  26320512       0 26320512     0%    /home</screen>

        <para>这样就基本完成了 <acronym>RAID</acronym>-Z
          的配置了。使用夜间 &man.periodic.8; 
          获取有关文件系统创建之类的状态更新，
          执行如下的命令：</para>

	<screen>&prompt.root; <userinput>echo 'daily_status_zfs_enable="YES"' &gt;&gt; /etc/periodic.conf</userinput></screen>
      </sect3>

      <sect3>
        <title>修复 <acronym>RAID</acronym>-Z</title>

        <para>每一种软 <acronym>RAID</acronym>
          都有监测它们 <literal>状态</literal> 的方法。
          <acronym>ZFS</acronym> 也不例外。
          可以使用如下的命令查看 <acronym>RAID</acronym>-Z
          设备：</para>

	<screen>&prompt.root; <userinput>zpool status -x</userinput></screen>

        <para>如果所有的存储池处于健康状态并且一切正常的话，
          将返回如下信息：</para>

	<screen>all pools are healthy</screen>

        <para>如果存在问题，可能是一个磁盘设备下线了，
          那么返回的存储池的状态将看上去是类似这个样子的：</para>

	<screen>  pool: storage
 state: DEGRADED
status: One or more devices has been taken offline by the administrator.
	Sufficient replicas exist for the pool to continue functioning in a
	degraded state.
action: Online the device using 'zpool online' or replace the device with
	'zpool replace'.
 scrub: none requested
config:

	NAME        STATE     READ WRITE CKSUM
	storage     DEGRADED     0     0     0
	  raidz1    DEGRADED     0     0     0
	    da0     ONLINE       0     0     0
	    da1     OFFLINE      0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</screen>

        <para>在这个例子中，这是由管理员把此设备下线后的状态。
          可以使用如下的命令将磁盘下线：</para>

	<screen>&prompt.root; <userinput>zpool offline storage da1</userinput></screen>

        <para>现在切断系统电源之后就可以替换下
          <devicename>da1</devicename> 了。
          当系统再次上线时，使用如下的命令替换磁盘：</para>

	<screen>&prompt.root; <userinput>zpool replace storage da1</userinput></screen>

        <para>至此可用不带 <option>-x</option>
          标志的命令再次检查状态：</para>

	<screen>&prompt.root; <userinput>zpool status storage</userinput>
 pool: storage
 state: ONLINE
 scrub: resilver completed with 0 errors on Sat Aug 30 19:44:11 2008
config:

	NAME        STATE     READ WRITE CKSUM
	storage     ONLINE       0     0     0
	  raidz1    ONLINE       0     0     0
	    da0     ONLINE       0     0     0
	    da1     ONLINE       0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</screen>

        <para>在这个例子中，一切都显示正常。</para>
      </sect3>

      <sect3>
        <title>数据校验</title>

        <para>正如前面所提到的，<acronym>ZFS</acronym>
          使用 <literal>校验和</literal>(checksum) 来检查存储数据的完整性。
          这时在文件系统创建时自动启用的，可使用以下的命令禁用：</para>

	<screen>&prompt.root; <userinput>zfs set checksum=off storage/home</userinput></screen>

        <para>这不是个明智的选择，因为校验和
          不仅非常有用而且只需占用少量的存储空间。
          并且启用它们也不会明显的消耗过多资源。
          启用后就可以让 <acronym>ZFS</acronym>
          使用校验和校验来检查数据的完整。
          这个过程通常称为 <quote>scrubbing</quote>。
          可以使用以下的命令检查 <literal>storage</literal>
          存储池里数据的完整性：</para>

	<screen>&prompt.root; <userinput>zpool scrub storage</userinput></screen>

        <para>这个过程需花费相当长的时间，取决于存储的数据量。
          而且 <acronym>I/O</acronym> 非常密集，
          所以在任何时间只能执行一个这样的操作。
          在 scrub 完成之后，状态就会被更新，
          可使用如下的命令查看：</para>

	<screen>&prompt.root; <userinput>zpool status storage</userinput>
 pool: storage
 state: ONLINE
 scrub: scrub completed with 0 errors on Sat Aug 30 19:57:37 2008
config:

	NAME        STATE     READ WRITE CKSUM
	storage     ONLINE       0     0     0
	  raidz1    ONLINE       0     0     0
	    da0     ONLINE       0     0     0
	    da1     ONLINE       0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</screen>

        <para>这个例子中完成时间非常的清楚。
          这个特性可以帮助你在很长的一段时间内确保数据的完整。</para>

        <para>Z 文件系统有更多的选项，请参阅
          &man.zfs.8; 和 &man.zpool.8; 手册页。</para>
      </sect3>
    </sect2>
  </sect1>


  <!--
      XXXTR: stub sections (added later, as needed, as desire,
      after I get opinions from -doc people):

      Still need to discuss native and foreign file systems.

  <sect1>
    <title>Device File System</title>
  </sect1>

  <sect1>
    <title>DOS and NTFS File Systems</title>
    <para>This is a good section for those who transfer files, using
      USB devices, from Windows to FreeBSD and vice-versa.  My camera,
      and many other cameras I have seen default to using FAT16.  There
      is (was?) a kde utility, I think called kamera, that could be used
      to access camera devices.  A section on this would be useful.</para>

    <para>XXXTR: Though!  The disks chapter, covers a bit of this and
      devfs under it's USB devices.  It leaves a lot to be desired though,
      see:
http://www.freebsd.org/doc/en_US.ISO8859-1/books/handbook/usb-disks.html
      It may be better to flesh out that section a bit more.  Add the
      word "camera" to it so that others can easily notice.</para>
  </sect1>

  <sect1>
    <title>Linux EXT 文件系统</title>

    <para>Probably NOT as useful as the other two, but it requires
      knowledge of the existence of the tools.  Which are hidden in
      the ports collection.  Most Linux guys would probably only use
      Linux, BSD guys would be smarter and use NFS.</para>
  </sect1>

  <sect1>
    <title>HFS</title>

    <para>I think this is the file system used on Apple OSX.  There are
      tools in the ports collection, and with Apple being a big
      FreeBSD supporter and user of our technologies, surely there
      is enough cross over to cover this?</para>
  </sect1>
  -->

</chapter>
