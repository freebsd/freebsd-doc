<!--
     The FreeBSD Documentation Project
     The FreeBSD German Documentation Project

     $FreeBSD$
     $FreeBSDde: de-docproj/books/handbook/filesystems/chapter.sgml,v 1.7 2011/05/25 20:31:26 jkois Exp $
     basiert auf: 1.10
-->

<chapter id="filesystems">
  <chapterinfo>
    <authorgroup>
      <author>
	<firstname>Tom</firstname>
	<surname>Rhodes</surname>
	<contrib>Geschrieben von </contrib>
      </author>
    </authorgroup>

    <authorgroup>
      <author>
	<firstname>Benedict</firstname>
	<surname>Reuschling</surname>
	<contrib>&Uuml;bersetzt von </contrib>
      </author>
      <author>
	<firstname>Daniel</firstname>
	<surname>Seuffert</surname>
      </author>
    </authorgroup>
  </chapterinfo>

  <title>Dateisystemunterst&uuml;tzung</title>

  <sect1 id="filesystems-synopsis">
    <title>&Uuml;bersicht</title>

    <indexterm><primary>File Systems</primary></indexterm>
    <indexterm>
      <primary>File Systems Support</primary>
      <see>File Systems</see>
    </indexterm>

    <para>Dateisysteme sind ein wesentlicher Bestandteil von Betriebssystemen.
      Sie erlauben es den Benutzern Dateien zu laden und zu speichern,
      erm&ouml;glichen den Zugriff auf die Daten und machen Festplatten
      &uuml;berhaupt erst n&uuml;tzlich.  Unterschiedliche Betriebssysteme
      besitzen normalerweise eine Gemeinsamkeit, n&auml;mlich deren
      mitgeliefertes Dateisystem.  Bei &os; ist dieses Dateisystem bekannt
      unter dem Namen Fast File System <acronym>FFS</acronym>, das direkt auf
      dem Original-Unix&trade; Dateisystem, <acronym>UFS</acronym> genannt,
      basiert.  Dieses ist das von &os; mitgelieferte Dateisystem, das auf
      Festplatten f&uuml;r den Dateizugriff verwendet wird.</para>

    <para>&os; unterst&uuml;tzt auch eine Vielzahl von anderen Dateisystemen,
      um auf Daten von anderen Betriebssystemen lokal zuzugreifen, wie z.B.
      Daten auf <acronym>USB</acronym>-Speichermedien, Flash-Speichern und
      Festplatten.  Es gibt auch Unterst&uuml;tzung f&uuml;r fremde
      Dateisysteme.  Dabei handelt es sich um Dateisysteme, die auf anderen
      Betriebssystemen entwickelt wurden, wie beispielsweise das &linux;
      Extended File System (<acronym>EXT</acronym>) und das Z-Dateisystem
      (<acronym>ZFS</acronym>) von &sun;.</para>

    <para>Es gibt verschiedene Stufen der Unterst&uuml;tzung in &os;
      f&uuml;r diese unterschiedlichen Dateisysteme.  Manche ben&ouml;tigen ein
      geladenes Kernelmodul, andere die Installation bestimmter Werkzeuge.
      Dieses Kapitel dient dazu, den Benutzern von &os; dazu helfen, auf andere
      Dateisysteme zuzugreifen, beginnend mit &sun;s Z-Dateisystem (ZFS).</para>

    <para>Nachdem Sie dieses Kapitel gelesen haben, werden Sie die folgenden
      Dinge wissen:</para>

    <itemizedlist>
      <listitem>
	<para>Den Unterschied zwischen eingebauten und unterst&uuml;tzten
	  Dateisystemen.</para>
      </listitem>

      <listitem>
	<para>Welche Dateisysteme von &os; unterst&uuml;tzt werden.</para>
      </listitem>

      <listitem>
	<para>Wie man fremde Dateisysteme aktiviert, konfiguriert, darauf
	  zugreift und diese verwendet.</para>
      </listitem>
    </itemizedlist>

    <para>Bevor Sie dieses Kapitel lesen, sollten Sie:</para>

    <itemizedlist>
      <listitem>
	<para>Grundlagen von &unix; und &os; verstehen
	  (<xref linkend="basics">).</para>
      </listitem>

      <listitem>
	<para>Mit den Grundlagen der Konfiguration und dem Bauen des Kernels
	  vertraut sein (<xref linkend="kernelconfig">).</para>
      </listitem>

      <listitem>
	<para>Problemlos Software von Drittherstellern in &os; installieren
	  k&ouml;nnen (<xref linkend="ports">).</para>
      </listitem>

      <listitem>
	<para>sich ein wenig mit Festplatten, Speicher und Ger&auml;tenamen
	  in &os; auskennen (<xref linkend="disks">).</para>
      </listitem>
    </itemizedlist>
  </sect1>

  <sect1 id="filesystems-zfs">
    <title>Das Z-Dateisystem (ZFS)</title>

    <para>Das Z-Dateisystem ist eine neue von &sun; entwickelte Technologie,
      mit dem Konzept einer gepoolten Speichermethodik.  Das bedeutet, dass
      Speicher nur verwendet wird, wenn dieser als Datenspeicher benutzt wird.
      ZFS wurde auch f&uuml;r maximale Datenintegrit&auml;t entwickelt und
      unterst&uuml;tzt dabei mehrfache Kopien, Schnappsch&uuml;sse und
      Pr&uuml;fsummen f&uuml;r Daten.  Ein neues Datenreplikationsmodell,
      bekannt als <acronym>RAID</acronym>-Z, wurde ebenfalls hinzugef&uuml;gt.
      Das <acronym>RAID</acronym>-Z-Modell ist &auml;hnlich zu
      <acronym>RAID</acronym>5, wurde aber mit dem Ziel entworfen,
      Datenverf&auml;lschung beim Schreiben zu verhindern.</para>

    <sect2>
      <title>ZFS Einstellungen</title>

      <para>Das <acronym>ZFS</acronym>-Teilsystem ben&ouml;tigt viele
        Systemressourcen, weshalb gewisse Einstellungen notwendig sind, um
        maximale Effizienz w&auml;hrend des t&auml;glichen Gebrauchs zu
        gew&auml;hrleisten.  Da es sich um eine experimentelle Funktion in &os;
        handelt, wird sich das in naher Zukunft &auml;ndern. Wie dem auch sei,
        zum gegenw&auml;rtigen Zeitpunkt wird die Anwendung der folgenden
        Schritte empfohlen.</para>

      <sect3>
	<title>Hauptspeicher</title>

	<para>Der verf&uuml;gbare Hauptspeicher im System sollte mindestens
	  1&nbsp;Gigabyte betragen, jedoch werden 2&nbsp;Gigabyte oder mehr
	  empfohlen.  In allen gezeigten Beispielen in diesem Abschnitt
	  verwendet das System 1&nbsp;Gigabyte Hauptspeicher mit mehreren
	  anderen Einstellungen.</para>

	<para>Manche Nutzer hatten Erfolg bei der Verwendung von weniger
	  als 1&nbsp;GB Hauptspeicher, aber mit dieser begrenzten Menge an RAM
	  ist es sehr wahrscheinlich, dass &os; eine Panic wegen
	  ersch&ouml;pftem Hauptspeicher erleiden wird, wenn es hohen
	  Belastungen ausgesetzt ist.</para>
      </sect3>

      <sect3>
	<title>Kernelkonfiguration</title>

	<para>Es wird vorgeschlagen, nicht ben&ouml;tigte Treiber und Optionen
	  aus der Kernelkonfigurationsdatei zu entfernen.  Da die meisten
	  Ger&auml;te als Module verf&uuml;gbar sind, k&ouml;nnen diese einfach
	  mittels der Datei <filename>/boot/loader.conf</filename> geladen
	  werden.</para>

	<para>Nutzer der &i386;-Architektur sollten die folgende Option in
	  ihrer Kernelkonfigurationsdatei hinzuf&uuml;gen, den Kernel neu
	  erstellen und anschliessend das System neustarten:</para>

	<programlisting>options 	KVA_PAGES=512</programlisting>

	<para>Diese Option wird den Adressraum des Kernels vergr&ouml;ssern,
	  was es erm&ouml;glicht, die Einstellung <varname>vm.kvm_size</varname>
	  &uuml;ber die momentan verh&auml;ngte Grenze von 1&nbsp;GB
	  (2&nbsp;GB f&uuml;r <acronym>PAE</acronym>) zu erh&ouml;hen.  Um den
	  passenden Wert dieser Option zu ermitteln, teilen Sie den
	  gew&uuml;nschten Adressraum in Megabyte durch vier.  In diesem Fall
	  betr&auml;gt er <literal>512</literal> f&uuml;r 2&nbsp;GB.</para>
      </sect3>

      <sect3>
	<title>Einstellungen des Loaders</title>

	<para>Der <devicename>kmem</devicename>-Addressraum sollte auf allen
	  &os;-Architekturen erh&ouml;ht werden.  Die folgende Option, die dem
	  Testsystem mit einem Gigabyte Hauptspeicher der Datei
	  <filename>/boot/loader.conf</filename> hinzugef&uuml;gt und welches
	  anschliessend neu gestartet wurde, war erfolgreich:</para>

	<programlisting>vm.kmem_size="330M"
vm.kmem_size_max="330M"
vfs.zfs.arc_max="40M"
vfs.zfs.vdev.cache.size="5M"</programlisting>

	<para>Eine detailliertere Liste von Vorschl&auml;gen zu ZFS-verwandten
	  Einstellungen finden Sie unter <ulink
	  url="http://wiki.freebsd.org/ZFSTuningGuide"></ulink>.</para>
      </sect3>
    </sect2>

    <sect2>
      <title>Verwenden von <acronym>ZFS</acronym></title>

      <para>Es existiert ein Startmechanismus, der es &os; erlaubt,
        <acronym>ZFS</acronym> als Pool w&auml;hrend des Systemstarts
        zu initialisieren.  Um das zu tun, geben Sie die folgenden Befehle
        ein:</para>

	<screen>&prompt.root; <userinput>echo 'zfs_enable="YES"' &gt;&gt; /etc/rc.conf</userinput>
&prompt.root; <userinput>/etc/rc.d/zfs start</userinput></screen>

	<para>F&uuml;r den Rest dieses Dokuments wird angenommen, dass drei
	  <acronym>SCSI</acronym>-Platten im System verf&uuml;gbar sind und
	  dass deren Ger&auml;tenamen
	  <devicename><replaceable>da0</replaceable></devicename>,
	  <devicename><replaceable>da1</replaceable></devicename> und
	  <devicename><replaceable>da2</replaceable></devicename> lauten.
	  Benutzer von <acronym>IDE</acronym>-Hardware k&ouml;nnen
	  <devicename><replaceable>ad</replaceable></devicename>-Ger&auml;te
	  an Stelle von <acronym>SCSI</acronym>-Hardware einsetzen.</para>

      <sect3>
	<title>Pool mit nur einer Platte</title>

	<para>Um ein einfaches, nicht-redundantes <acronym>ZFS</acronym> auf
	  einer einzelnen Festplatte zu erstellen, benutzen Sie das
	  <command>zpool</command>-Kommando:</para>

	<screen>&prompt.root; <userinput>zpool create example /dev/da0</userinput></screen>

	<para>Um den neuen Pool anzusehen, &uuml;berpr&uuml;fen Sie die
	  Ausgabe von <command>df</command>:</para>

	<screen>&prompt.root; <userinput>df</userinput>
Filesystem  1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a   2026030  235230  1628718    13%    /
devfs               1       1        0   100%    /dev
/dev/ad0s1d  54098308 1032846 48737598     2%    /usr
example      17547136       0 17547136     0%    /example</screen>

	<para>Diese Ausgabe zeigt deutlich, dass der
	  <literal>example</literal>-Pool nicht nur erstellt, sondern auch
	  <emphasis>gemountet</emphasis> wurde.  Er ist genau wie andere
	  Dateisysteme verf&uuml;gbar, Dateien k&ouml;nnen darin erstellt und
	  von den Benutzern aufgelistet werden, wie im folgenden Beispiel
	  gezeigt wird:</para>

	<screen>&prompt.root <userinput>cd /example</userinput>
&prompt.root; <userinput>ls</userinput>
&prompt.root; <userinput>touch testfile</userinput>
&prompt.root; <userinput>ls -al</userinput>
total 4
drwxr-xr-x   2 root  wheel    3 Aug 29 23:15 .
drwxr-xr-x  21 root  wheel  512 Aug 29 23:12 ..
-rw-r--r--   1 root  wheel    0 Aug 29 23:15 testfile</screen>

	<para>Leider verwendet dieser Pool keine der Vorteile der
	  <acronym>ZFS</acronym>-Eigenschaften.  Erstellen Sie ein Dateisystem
	  auf diesem Pool und aktivieren Sie die Komprimierung darauf:</para>

	<screen>&prompt.root; <userinput>zfs create example/compressed</userinput>
&prompt.root; <userinput>zfs set compression=gzip example/compressed</userinput></screen>

	<para>Jetzt ist <literal>example/compressed</literal> ein von
	  <acronym>ZFS</acronym> komprimiertes Dateisystem.  Versuchen Sie, ein
	  paar grosse Dateien in das Verzeichnis <filename
	  class="directory">/example/compressed</filename> zu kopieren.</para>

	<para>Die Komprimierung kann jetzt deaktiviert werden mittels:</para>

	<screen>&prompt.root; <userinput>zfs set compression=off example/compressed</userinput></screen>

	<para>Um das Dateisystem aus dem Verzeichnisbaum abzuh&auml;ngen, geben
          Sie den folgenden Befehl ein und vergewissern Sie sich &uuml;ber
	  <command>df</command> vom Erfolg dieser Aktion:</para>

	<screen>&prompt.root; <userinput>zfs umount example/compressed</userinput>
&prompt.root; <userinput>df</userinput>
Filesystem  1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a   2026030  235232  1628716    13%    /
devfs               1       1        0   100%    /dev
/dev/ad0s1d  54098308 1032864 48737580     2%    /usr
example      17547008       0 17547008     0%    /example</screen>

	<para>Mounten Sie das Dateisystem erneut, um es wieder verf&uuml;gbar
	  zu machen und best&auml;tigen Sie mit <command>df</command>:</para>

	<screen>&prompt.root; <userinput>zfs mount example/compressed</userinput>
&prompt.root; <userinput>df</userinput>
Filesystem         1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a          2026030  235234  1628714    13%    /
devfs                      1       1        0   100%    /dev
/dev/ad0s1d         54098308 1032864 48737580     2%    /usr
example             17547008       0 17547008     0%    /example
example/compressed  17547008       0 17547008     0%    /example/compressed</screen>

	<para>Der Pool und das Dateisystem k&ouml;nnen genausogut &uuml;ber die
          Ausgabe von <command>mount</command> &uuml;berwacht werden:</para>

	<screen>&prompt.root; <userinput>mount</userinput>
/dev/ad0s1a on / (ufs, local)
devfs on /dev (devfs, local)
/dev/ad0s1d on /usr (ufs, local, soft-updates)
example on /example (zfs, local)
example/data on /example/data (zfs, local)
example/compressed on /example/compressed (zfs, local)</screen>

	<para>Wie zu beobachten ist, k&ouml;nnen
	  <acronym>ZFS</acronym>-Dateisysteme nach deren Erstellung genauso
	  wie normale Dateisysteme verwendet werden, jedoch sind auch noch viele
	  andere Eigenschaften verf&uuml;gbar.  Im folgenden Beispiel wird ein
	  neues Dateisystem, <literal>data</literal>, erstellt.  Wichtige
	  Dateien sollen hier gespeichert werden, weshalb das Dateisystem
	  angewiesen wird, jeweils zwei Kopien jedes Datenblocks zu
	  unterhalten:</para>

	<screen>&prompt.root; <userinput>zfs create example/data</userinput>
&prompt.root; <userinput>zfs set copies=2 example/data</userinput></screen>

	<para>Es ist nun m&ouml;glich, den Speicherplatzverbrauch der Daten
	  mittels <command>df</command> erneut zu betrachten:</para>

	<screen>&prompt.root; <userinput>df</userinput>
Filesystem         1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a          2026030  235234  1628714    13%    /
devfs                      1       1        0   100%    /dev
/dev/ad0s1d         54098308 1032864 48737580     2%    /usr
example             17547008       0 17547008     0%    /example
example/compressed  17547008       0 17547008     0%    /example/compressed
example/data        17547008       0 17547008     0%    /example/data</screen>

	<para>Beachten Sie, dass jedem Dateisystem des Pools die gleiche Menge
	  an Speicher zur Verf&uuml;gung steht.  Das ist der Grund f&uuml;r die
	  Verwendung von <command>df</command> in all diesen Beispielen, da es
	  zeigt, dass das Dateisystem nur den Speicher belegt, den es auch
	  ben&ouml;tigt und alles wird von dem gleichen Pool abgezogen.
	  <acronym>ZFS</acronym> macht Konzepte wie Volumen und Partitionen
	  &uuml;berfl&uuml;ssig und erlaubt mehrere Dateisysteme auf demselben
	  Pool.  Zerst&ouml;ren Sie die Datensysteme und anschliessend den Pool,
	  da sie nicht l&auml;nger gebraucht werden:</para>

	<screen>&prompt.root; <userinput>zfs destroy example/compressed</userinput>
&prompt.root; <userinput>zfs destroy example/data</userinput>
&prompt.root; <userinput>zpool destroy example</userinput></screen>

	<para>Festplatten werden mit der Zeit schlechter und fallen aus, eine
	  unvermeidliche Tatsache.  Wenn diese Platte ausf&auml;llt, sind die
	  Daten verloren.  Eine M&ouml;glichkeit, diesen Datenverlust beim
	  Plattenausfall zu vermeiden, ist die Verwendung von
	  <acronym>RAID</acronym>.  <acronym>ZFS</acronym> unterst&uuml;tzt
	  diese Eigenschaft im Entwurf seiner Pools und wird im n&auml;chsten
	  Abschnitt behandelt.</para>
      </sect3>

      <sect3>
	<title><acronym>ZFS</acronym> RAID-Z</title>

	<para>Wie zuvor bereits erw&auml;hnt, wird in diesem Abschnitt
	  angenommen, dass drei <acronym>SCSI</acronym>-Ger&auml;te vorhanden
	  sind (<devicename>da0</devicename>, <devicename>da1</devicename>
	  und <devicename>da1</devicename> bzw. <devicename>ad0</devicename>
	  und so weiter, falls IDE-Platten verwendet werden).  Um einen
	  <acronym>RAID</acronym>-Z Pool zu erstellen, geben Sie das
	  folgende Kommando ein:</para>

	<screen>&prompt.root; <userinput>zpool create storage raidz da0 da1 da2</userinput></screen>

        <note>
          <para>&sun; empfiehlt, dass die Anzahl von Ger&auml;ten in einer
            <acronym>RAID</acronym>-Z Konfiguration drei bis neun betr&auml;gt.
            Falls Ihre Anforderungen unbedingt einen einzelnen Pool, bestehend
            aus zehn oder mehr Platten, erfordern, sollten Sie &uuml;berlegen,
            diesen in kleinere <acronym>RAID</acronym>-Z Gruppen aufzuteilen.
            Sollten Sie nur zwei Platten zur Verf&uuml;gung haben und trotzdem
            Redundanz ben&ouml;tigen, ziehen Sie den Einsatz der
            <acronym>ZFS</acronym>-Mirror (Spiegel) F&auml;higkeiten in
            Betracht.  Lesen Sie die &man.zpool.8; Manualpage, um mehr
            dar&uuml;ber zu erfahren.</para>
  	</note>

	<para>Der <literal>storage</literal>-zPool sollte jetzt erstellt worden
	  sein.  Sie k&ouml;nnen das &uuml;berpr&uuml;fen, indem Sie die Befehle
	  &man.mount.8; und &man.df.1; wie zuvor verwenden.  Weitere
	  Plattenspeicher k&ouml;nnen an das Ende der oben stehenden Liste
	  hinzugef&uuml;gt werden.  Erstellen Sie ein neues Dateisystem in dem
	  Pool, <literal>home</literal> genannt, in dem sp&auml;ter Dateien von
	  Benutzern platziert werden:</para>

	<screen>&prompt.root; <userinput>zfs create storage/home</userinput></screen>

	<para>Nun kann die Komprimierung aktiviert und zus&auml;tzliche
	  Kopien der Benutzerverzeichnisse und der darin enthaltenen Dateien
	  angelegt werden.  Dies geschieht &uuml;ber die gleichen Befehle
	  wie bereits zuvor:</para>

	<screen>&prompt.root; <userinput>zfs set copies=2 storage/home</userinput>
&prompt.root; <userinput>zfs set compression=gzip storage/home</userinput></screen>

	<para>Um dieses Verzeichnis als neues Benutzerverzeichnis zu verwenden,
	  kopieren Sie die Nutzerdaten dort hin und erstellen Sie die
	  entsprechenden Symlinks:</para>

	<screen>&prompt.root; <userinput>cp -rp /home/* /storage/home</userinput>
&prompt.root; <userinput>rm -rf /home /usr/home</userinput>
&prompt.root; <userinput>ln -s /storage/home /home</userinput>
&prompt.root; <userinput>ln -s /storage/home /usr/home</userinput></screen>

	<para>Anwender sollten jetzt ihre Daten in dem neu angelegten <filename
	  class="directory">/storage/home</filename> Dateisystem auffinden.
	  Pr&uuml;fen Sie das, indem Sie einen neuen Benutzer hinzuf&uuml;gen
	  und sich als dieser Benutzer am System anmelden.</para>

	<para>Versuchen Sie, einen Schnappschuss anzulegen, der sp&auml;ter
	  wieder zur&uuml;ckgerollt werden kann:</para>

	<screen>&prompt.root; <userinput>zfs snapshot storage/home@08-30-08</userinput></screen>

	<para>Beachten Sie, dass die Schnappschuss-Option nur auf echte
	  Dateisysteme, jedoch nicht auf Verzeichnisse oder eine Datei
	  angewendet werden kann.  Das <literal>@</literal>-Zeichen dient als
	  Begrenzer zwischen dem Dateisystem- oder Volumenamen.  Wenn ein
	  Benutzerverzeichnis zerst&ouml;rt wird, k&ouml;nnen Sie es &uuml;ber
	  den folgenden Befehl wieder herstellen:</para>

	<screen>&prompt.root; <userinput>zfs rollback storage/home@08-30-08</userinput></screen>

	<para>Um eine Liste von allen verf&uuml;gbaren Schnappsch&uuml;ssen zu
	  erhalten, starten Sie das <command>ls</command>-Kommando in
	  Verzeichnis <filename
	  class="directory">.zfs/snapshot</filename> des entsprechenden
	  Dateisystems.  Beispielsweise k&ouml;nnen Sie den vorhin angelegten
	  Schnappschuss mit dem folgenden Befehl auflisten:</para>

	<screen>&prompt.root; <userinput>ls /storage/home/.zfs/snapshot</userinput></screen>

	<para>Es ist m&ouml;glich ein Skript zu schreiben, dass monatliche
	  Schnappsch&uuml;sse der Nutzerdaten anlegt.  Allerdings werden die
	  Schnappsch&uuml;sse mit der Zeit eine grosse Menge an Speicherplatz
	  einnehmen.  Den vorherigen Schnappschuss k&ouml;nnen Sie &uuml;ber
	  das folgende Kommando l&ouml;schen:</para>

	<screen>&prompt.root; <userinput>zfs destroy storage/home@08-30-08</userinput></screen>

	<para>Nach all diesen Tests gibt es keinen Grund, das Verzeichnis
	  <filename
	  class="directory">/storage/home</filename> noch l&auml;nger in seinem
	  momentanen Zustand zu belassen.  Ernennen Sie es zum echten <filename
	  class="directory">/home</filename>-Dateisystem:</para>

	<screen>&prompt.root; <userinput>zfs set mountpoint=/home storage/home</userinput></screen>

	<para>Die Eingabe der Befehle <command>df</command> und
	  <command>mount</command> zeigt, dass das System das Dateisystem nun
	  als das echte <filename class="directory">/home</filename>
          behandelt:</para>

	<screen>&prompt.root; <userinput>mount</userinput>
/dev/ad0s1a on / (ufs, local)
devfs on /dev (devfs, local)
/dev/ad0s1d on /usr (ufs, local, soft-updates)
storage on /storage (zfs, local)
storage/home on /home (zfs, local)
&prompt.root; <userinput>df</userinput>
Filesystem   1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a    2026030  235240  1628708    13%    /
devfs                1       1        0   100%    /dev
/dev/ad0s1d   54098308 1032826 48737618     2%    /usr
storage       26320512       0 26320512     0%    /storage
storage/home  26320512       0 26320512     0%    /home</screen>

	<para>Damit ist die <acronym>RAID</acronym>-Z-Konfiguration
	  abgeschlossen.  Um &uuml;ber den Status des Dateisystems mittels des
	  n&auml;chtlichen &man.periodic.8;-Skripts auf dem Laufenden gehalten
	  zu werden, geben Sie das folgende Kommando ein:</para>

	<screen>&prompt.root; <userinput>echo 'daily_status_zfs_enable="YES"' &gt;&gt; /etc/periodic.conf</userinput></screen>
      </sect3>

      <sect3>
	<title>Wiederherstellung von <acronym>RAID</acronym>-Z</title>

	<para>Jedes Software-<acronym>RAID</acronym> besitzt Verfahren, um
	  dessen <literal>Zustand</literal> zu &uuml;berwachen.
	  <acronym>ZFS</acronym> ist da keine Ausnahme.  Der Status von
	  <acronym>RAID</acronym>-Z Ger&auml;ten kann mittels des folgenden
	  Kommandos betrachtet werden:</para>

	<screen>&prompt.root; <userinput>zpool status -x</userinput></screen>

	<para>Wenn alle Pools gesund sind und alles normal ist, wird die
	  folgende Nachricht zur&uuml;ckgegeben:</para>

	<screen>all pools are healthy</screen>

	<para>Wenn ein Problem existiert (m&ouml;glicherweise ist eine Platte
	  ausgefallen), wird der Zustand des Pools &auml;hnlich dem Folgenden
	  ausgegeben:</para>

	<screen>  pool: storage
 state: DEGRADED
status: One or more devices has been taken offline by the administrator.
	Sufficient replicas exist for the pool to continue functioning in a
	degraded state.
action: Online the device using 'zpool online' or replace the device with
	'zpool replace'.
 scrub: none requested
config:

	NAME        STATE     READ WRITE CKSUM
	storage     DEGRADED     0     0     0
	  raidz1    DEGRADED     0     0     0
	    da0     ONLINE       0     0     0
	    da1     OFFLINE      0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</screen>

	<para>Das bedeutet, dass das Ger&auml;t vom Systemadministrator
	  abgeschaltet wurde.  In diesem Fall trifft das zu.  Um eine Platte
	  abzuschalten, wurde das folgende Kommando eingegeben:</para>

	<screen>&prompt.root; <userinput>zpool offline storage da1</userinput></screen>

	<para>Es ist jetzt m&ouml;glich, <devicename>da1</devicename> zu
	  ersetzen, nachdem das System ausgeschaltet wurde.  Wenn das System
	  wieder l&auml;uft, kann der folgende Befehl benutzt werden, um die
	  Platte zu ersetzen:</para>

	<screen>&prompt.root; <userinput>zpool replace storage da1</userinput></screen>

	<para>Von da an kann der Status erneut &uuml;berpr&uuml;ft werden,
	  jedoch dieses Mal ohne die Option <option>-x</option>, um die
	  Zustandsinformation zu bekommen:</para>

	<screen>&prompt.root; <userinput>zpool status storage</userinput>
 pool: storage
 state: ONLINE
 scrub: resilver completed with 0 errors on Sat Aug 30 19:44:11 2008
config:

	NAME        STATE     READ WRITE CKSUM
	storage     ONLINE       0     0     0
	  raidz1    ONLINE       0     0     0
	    da0     ONLINE       0     0     0
	    da1     ONLINE       0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</screen>

	<para>Wie in diesem Beispiel gezeigt, scheint alles wieder normal zu
	  sein.</para>
      </sect3>

      <sect3>
	<title>Daten&uuml;berpr&uuml;fung</title>

	<para>Wie bereits erw&auml;hnt, verwendet <acronym>ZFS</acronym>
	  <literal>Pr&uuml;fsummen</literal>, um die Integrit&auml;t der
	  gespeicherten Daten zu verifizieren.  Die Pr&uuml;fsummen werden
	  automatisch beim Erstellen des Dateisystem aktiviert und k&ouml;nnen
	  &uuml;ber den folgenden Befehl deaktiviert werden:</para>

	<screen>&prompt.root; <userinput>zfs set checksum=off storage/home</userinput></screen>

	<para>Das ist jedoch kein schlauer Einfall, da die Pr&uuml;fsummen nur
	  ganz wenig Speicherplatz einnehmen und viel n&uuml;tzlicher sind,
	  wenn Sie aktiviert bleiben.  Es scheint auch kein nennenswerter
	  Ressourcenverbrauch mit deren Aktivierung verbunden zu sein. Wenn die
	  Pr&uuml;fsummen aktiv sind, kann <acronym>ZFS</acronym> die
	  Datenintegrit&auml;t &uuml;ber den Vergleich der Pr&uuml;fsummen
	  gew&auml;hrleisten.  Dieser Prozess wird als <quote>reinigen</quote>
	  bezeichnet.  Um die Datenintegrit&auml;t des
	  <literal>storage</literal>-Pools zu &uuml;berpr&uuml;fen, geben Sie
	  den folgenden Befehl ein:</para>

	<screen>&prompt.root; <userinput>zpool scrub storage</userinput></screen>

	<para>Dieser Prozess kann einige Zeit in Anspruch nehmen, abh&auml;ngig
	  davon, wieviele Daten gespeichert sind.  Es handelt sich dabei auch
	  um eine <acronym>I/O</acronym>-intensive Aktion, weshalb auch jeweils
	  nur eine dieser Operationen durchgef&uuml;hrt werden darf.  Nachdem
	  die Reinigung abgeschlossen ist, wird der Status aktualisiert und
	  kann &uuml;ber eine Statusabfrage eingesehen werden:</para>

	<screen>&prompt.root; <userinput>zpool status storage</userinput>
 pool: storage
 state: ONLINE
 scrub: scrub completed with 0 errors on Sat Aug 30 19:57:37 2008
config:

	NAME        STATE     READ WRITE CKSUM
	storage     ONLINE       0     0     0
	  raidz1    ONLINE       0     0     0
	    da0     ONLINE       0     0     0
	    da1     ONLINE       0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</screen>

	<para>Die Zeit des Abschlusses der Aktion kann in diesem Beispiel direkt
	  abgelesen werden. Die Pr&uuml;fsummen helfen dabei, sicherzustellen,
	  dass die Datenintegrit&auml;t &uuml;ber einen langen Zeitraum hinaus
	  erhalten bleibt.</para>

	<para>Es gibt viele weitere Optionen f&uuml;r das Z-Dateisystem, lesen
	  Sie dazu die Manualpage &man.zfs.8; und &man.zpool.8;.</para>
      </sect3>
    </sect2>
  </sect1>


  <!--
      XXXTR: stub sections (added later, as needed, as desire,
      after I get opinions from -doc people):

      Still need to discuss native and foreign file systems.

  <sect1>
    <title>Device File System</title>
  </sect1>

  <sect1>
    <title>DOS and NTFS File Systems</title>
    <para>This is a good section for those who transfer files, using
      USB devices, from Windows to FreeBSD and vice-versa.  My camera,
      and many other cameras I have seen default to using FAT16.  There
      is (was?) a kde utility, I think called kamera, that could be used
      to access camera devices.  A section on this would be useful.</para>

    <para>XXXTR: Though!  The disks chapter, covers a bit of this and
      devfs under it's USB devices.  It leaves a lot to be desired though,
      see:
http://www.freebsd.org/doc/en_US.ISO8859-1/books/handbook/usb-disks.html
      It may be better to flesh out that section a bit more.  Add the
      word "camera" to it so that others can easily notice.</para>
  </sect1>

  <sect1>
    <title>Linux EXT File System</title>

    <para>Probably NOT as useful as the other two, but it requires
      knowledge of the existence of the tools.  Which are hidden in
      the ports collection.  Most Linux guys would probably only use
      Linux, BSD guys would be smarter and use NFS.</para>
  </sect1>

  <sect1>
    <title>HFS</title>

    <para>I think this is the file system used on Apple OSX.  There are
      tools in the ports collection, and with Apple being a big
      FreeBSD supporter and user of our technologies, surely there
      is enough cross over to cover this?</para>
  </sect1>
  -->


</chapter>

<!--
     Local Variables:
     mode: sgml
     sgml-declaration: "../chapter.decl"
     sgml-indent-data: t
     sgml-omittag: nil
     sgml-always-quote-attributes: t
     sgml-parent-document: ("../book.sgml" "part" "chapter")
     End:
-->
