---
description: 'FreeBSD에서 GEOM 프레임워크는 공급자 또는 /dev의 디스크 장치를 사용하여 마스터 부트 레코드 및 BSD 레이블과 같은 클래스에 대한 액세스 및 제어를 허용합니다.'
next: books/handbook/zfs
part: '파트 III. 시스템 관리'
path: /books/handbook/
prev: books/handbook/disks
showBookMenu: 'true'
tags: ["GEOM", "RAID", "RAID0", "RAID1", "RAID3", "Striping", "bsdlabel", "newfs", "labelling", "UFS", "journaling"]
title: '20장. GEOM: 모듈식 디스크 변환 프레임워크'
weight: 24
---

[[geom]]
= GEOM: 모듈식 디스크 변환 프레임워크
:doctype: book
:toc: macro
:toclevels: 1
:icons: font
:sectnums:
:sectnumlevels: 6
:sectnumoffset: 20
:partnums:
:source-highlighter: rouge
:experimental:
:images-path: books/handbook/geom/

ifdef::env-beastie[]
ifdef::backend-html5[]
:imagesdir: ../../../../images/{images-path}
endif::[]
ifndef::book[]
include::shared/authors.adoc[]
include::shared/mirrors.adoc[]
include::shared/releases.adoc[]
include::shared/attributes/attributes-{{% lang %}}.adoc[]
include::shared/{{% lang %}}/teams.adoc[]
include::shared/{{% lang %}}/mailing-lists.adoc[]
include::shared/{{% lang %}}/urls.adoc[]
toc::[]
endif::[]
ifdef::backend-pdf,backend-epub3[]
include::../../../../../shared/asciidoctor.adoc[]
endif::[]
endif::[]

ifndef::env-beastie[]
toc::[]
include::../../../../../shared/asciidoctor.adoc[]
endif::[]

[[geom-synopsis]]
== 요약

FreeBSD에서 GEOM 프레임워크는 공급자 또는 [.filename]#/dev#의 디스크 장치를 사용하여 마스터 부트 레코드 및 BSD 레이블과 같은 클래스에 대한 액세스 및 제어를 허용합니다. 다양한 소프트웨어 RAID 구성을 지원함으로써 GEOM은 운영 체제 및 운영 체제 유틸리티에 대한 액세스를 투명하게 제공합니다.

이 장에서는 FreeBSD의 GEOM 프레임워크에서 디스크를 사용하는 방법을 다룹니다. 여기에는 구성을 위해 프레임워크를 사용하는 주요 RAID 제어 유틸리티가 포함됩니다. 이 장은 RAID 구성에 대한 결정적인 가이드가 아니며 GEOM 지원 RAID 분류에 대해서만 설명합니다.

이 챕터를 읽고 나면, 여러분은:

* GEOM을 통해 사용할 수 있는 RAID 지원 유형.
* 기본 유틸리티를 사용하여 다양한 RAID 레벨을 구성, 유지 및 조작하는 방법.
* GEOM을 통해 디스크 장치를 미러링, 스트라이프, 암호화 및 원격으로 연결하는 방법.
* GEOM 프레임워크에 연결된 디스크 문제를 해결하는 방법.

이 챕터를 읽기 전에 여러분은:

* FreeBSD가 디스크 장치를 처리하는 방식을 이해합니다(crossref:disks[disks,Storage]).
* 새 커널을 구성하고 설치하는 방법을 알고 있습니다(crossref:kernelconfig[kernelconfig,FreeBSD 커널 구성]).

[[geom-striping]]
== RAID0 - Striping

스트라이핑은 여러 디스크 드라이브를 단일 볼륨으로 결합합니다. 스트라이핑은 하드웨어 RAID 컨트롤러를 사용하여 수행할 수 있습니다. GEOM 디스크 하위 시스템은 RAID 디스크 컨트롤러 없이 RAID0이라고도 하는 디스크 스트라이핑에 대한 소프트웨어 지원을 제공합니다.

RAID0에서 데이터는 어레이의 모든 드라이브에 기록되는 블록으로 분할됩니다. 다음 그림에서 볼 수 있듯이 RAID0은 하나의 디스크에 256k를 쓰기 위해 시스템을 기다릴 필요 없이 어레이에 있는 4개의 디스크 각각에 동시에 64k를 쓸 수 있어 뛰어난 I/O 성능을 제공합니다. 이 성능은 여러 디스크 컨트롤러를 사용하여 더욱 향상될 수 있습니다.

image::striping.png["디스크 스트라이핑 그림"]

I/O 요청이 여러 디스크를 병렬로 읽거나 쓰기 위해 인터리브되므로 RAID0 스트라이프의 각 디스크는 크기가 같아야 합니다.

[NOTE]
====
RAID0은 _중복성을 제공하지 않습니다_. 즉, 어레이의 디스크 하나에 오류가 발생하면 디스크의 모든 데이터가 손실됩니다. 데이터가 중요한 경우 원격 시스템이나 장치에 정기적으로 백업을 저장하는 백업 전략을 구현하십시오.
====

상용 디스크를 사용하여 FreeBSD 시스템에서 소프트웨어, GEOM 기반 RAID0을 생성하는 프로세스는 다음과 같습니다. 스트라이프가 생성되면 기존 스트라이프를 제어하는 방법에 대한 자세한 내용은 man:gstripe[8]를 참조하십시오.

[.procedure]
****
*절차: 포맷되지 않은 ATA 디스크 스트라이프 만들기*

. [.filename]#geom_stripe.ko# module을 로드합니다:
+
[source, shell]
....
# kldload geom_stripe
....

. 적합한 마운트 지점이 있는지 확인하십시오. 이 볼륨이 루트 파티션이 될 경우 임시로 [.filename]#/mnt#와 같은 다른 마운트 지점을 사용하십시오.
. 스트라이핑할 디스크의 장치 이름을 결정하고 새 스트라이프 장치를 만듭니다. 예를 들어, 사용하지 않고 파티션 되지 않은 두 개의 ATA 디스크를 [.filename]#/dev/ad2# 및 [.filename]#/dev/ad3#의 장치 이름으로 스트라이핑합니다:
+
[source, shell]
....
# gstripe label -v st0 /dev/ad2 /dev/ad3
Metadata value stored on /dev/ad2.
Metadata value stored on /dev/ad3.
Done.
....

. 새 볼륨에 표준 레이블(파티션 테이블이라고도 함)을 작성하고 기본 부트스트랩 코드를 설치합니다:
+
[source, shell]
....
# bsdlabel -wB /dev/stripe/st0
....

. 이 프로세스는 [.filename]#/dev/stripe#에 [.filename]#st0# 외에 두 개의 다른 장치를 생성해야 합니다. 여기에는 [.filename]#st0a# 및 [.filename]#st0c#가 포함됩니다. 이 시점에서 `newfs`를 사용하여 [.filename]#st0a#에 UFS 파일 시스템을 생성할 수 있습니다:
+
[source, shell]
....
# newfs -U /dev/stripe/st0a
....
+
많은 숫자가 화면을 가로지르며 미끄러지듯 지나가고 몇 초 후 프로세스가 완료됩니다. 볼륨이 생성되었으며 마운트할 준비가 되었습니다.
. 생성된 디스크 스트라이프를 수동으로 마운트하려면:
+
[source, shell]
....
# mount /dev/stripe/st0a /mnt
....

. 부팅 프로세스 중에 이 스트라이프 파일 시스템을 자동으로 마운트하려면 볼륨 정보를 [.filename]#/etc/fstab#에 작성합니다. 이 예제에서는 [.filename]#stripe#라는 이름의 영구 마운트 지점이 생성됩니다:
+
[source, shell]
....
# mkdir /stripe
# echo "/dev/stripe/st0a /stripe ufs rw 2 2" \
>> /etc/fstab
....

. 또한 시스템 초기화 중에 [.filename]#/boot/loader.conf#에 한 줄을 추가하여 [.filename]#geom_stripe.ko# 모듈을 자동으로 로드해야 합니다:
+
[source, shell]
....
# echo 'geom_stripe_load="YES"' >> /boot/loader.conf
....
****

[[geom-mirror]]
== RAID1 - 미러링

RAID1 또는 _미러링_은 둘 이상의 디스크 드라이브에 동일한 데이터를 쓰는 기술입니다. 미러는 일반적으로 드라이브 장애로 인한 데이터 손실을 방지하는 데 사용됩니다. 미러의 각 드라이브에는 동일한 데이터 사본이 들어 있습니다. 개별 드라이브에 장애가 발생해도 미러는 계속 작동하며 정상 작동 중인 드라이브에서 데이터를 제공할 수 있습니다. 컴퓨터는 계속 실행되고 관리자는 시스템의 중단 없이 장애가 발생한 드라이브를 교체할 수 있는 시간을 확보할 수 있습니다.

이 예에서는 두 가지 일반적인 상황을 설명합니다. 첫 번째는 두 개의 새 드라이브에서 미러를 생성하여 기존 단일 드라이브를 대체하는 데 사용합니다. 두 번째 예는 새 드라이브 하나에 미러를 생성하고 이전 드라이브의 데이터를 미러에 복사한 다음 이전 드라이브를 미러에 삽입하는 것입니다. 이 절차는 약간 더 복잡하지만 새 드라이브가 하나만 필요합니다.

일반적으로 미러의 두 드라이브는 모델과 용량이 동일해야 하지만, man:gmirror[8]는 그럴 필요가 없습니다. 서로 다른 드라이브로 미러를 만들면 미러에서 가장 작은 드라이브의 용량과 동일한 용량을 갖게 됩니다. 더 큰 드라이브의 추가 공간은 사용되지 않습니다. 나중에 미러에 추가되는 드라이브는 미러에 이미 있는 가장 작은 드라이브만큼의 용량을 가져야 합니다.

[WARNING]
====
여기에 표시된 미러링 절차는 비파괴적이지만 모든 주요 디스크 작업과 마찬가지로 먼저 전체 백업을 만드세요.
====

[WARNING]
====
이 절차에서 man:dump[8]는 파일 시스템을 복사하는 데 사용되지만, 소프트 업데이트 저널링이 있는 파일 시스템에서는 작동하지 않습니다. 소프트 업데이트 저널링을 감지하고 비활성화하는 방법에 대한 자세한 내용은 man:tunefs[8]을 참조하십시오.
====

[[geom-mirror-metadata]]
=== 메타데이터 문제

대부분의 디스크 시스템은 각 디스크의 끝에 메타데이터를 저장합니다. 미러용으로 디스크를 재사용하기 전에 오래된 메타데이터를 지워야 합니다. 대부분의 문제는 두 가지 특정 유형의 남은 메타데이터로 인해 발생합니다: GPT 파티션 테이블과 이전 미러의 오래된 메타데이터입니다.

GPT 메타데이터는 man:gpart[8]로 지울 수 있습니다. 이 예는 디스크 [.filename]#ada8#에서 기본 및 백업 GPT 파티션 테이블을 모두 지웁니다:

[source, shell]
....
# gpart destroy -F ada8
....

man:gmirror[8]를 사용하여 활성 미러에서 디스크를 제거하고 메타데이터를 한 번에 지울 수 있습니다. 여기서는 예제 디스크 [.filename]#ada8#이 활성 미러 [.filename]#gm4#에서 제거됩니다:

[source, shell]
....
# gmirror remove gm4 ada8
....

미러가 실행되고 있지 않지만 이전 미러 메타데이터가 여전히 디스크에 남아 있는 경우, `gmirror clear`를 사용하여 제거합니다:

[source, shell]
....
# gmirror clear ada8
....

man:gmirror[8]은 디스크 끝에 하나의 메타데이터 블록을 저장합니다. GPT 파티션 스키마도 디스크 끝에 메타데이터를 저장하므로 man:gmirror[8]로 전체 GPT 디스크를 미러링하는 것은 권장되지 않습니다. MBR 파티션은 디스크 시작 부분에만 파티션 테이블을 저장하고 미러 메타데이터와 충돌하지 않기 때문에 여기에 사용됩니다.

[[geom-mirror-two-new-disks]]
=== 두 개의 새 디스크로 미러 만들기

이 예제에서는 FreeBSD가 이미 단일 디스크인 [.filename]#ada0#에 설치되어 있습니다. 두 개의 새 디스크인 [.filename]#ada1# 및 [.filename]#ada2#가 시스템에 연결되었습니다. 이 두 디스크에 새 미러가 생성되어 이전 단일 디스크를 대체하는 데 사용됩니다.

[.filename]#geom_mirror.ko# 커널 모듈은 커널에 빌드되거나 부팅 또는 런타임에 로드되어야 합니다. 지금 커널 모듈을 수동으로 로드하세요:

[source, shell]
....
# gmirror load
....

두 개의 새 드라이브로 미러를 만듭니다:

[source, shell]
....
# gmirror label -v gm0 /dev/ada1 /dev/ada2
....

[.filename]#gm0#은 새 미러에 할당된 사용자가 선택한 장치 이름입니다. 미러가 시작되면 이 장치 이름은 [.filename]#/dev/mirror/#에 표시됩니다.

이제 man:gpart[8]를 사용하여 미러에 MBR 및 bsdlabel 파티션 테이블을 생성할 수 있습니다. 이 예제에서는 [.filename]#/#, 스왑, [.filename]#/var#, [.filename]#/tmp#, [.filename]#/usr#에 대한 파티션이 있는 기존 파일 시스템 레이아웃을 사용합니다. 단일 [.filename]#/# 및 스왑 파티션도 작동합니다.

미러의 파티션은 기존 디스크의 파티션과 크기가 같을 필요는 없지만 [.filename]#ada0#에 이미 있는 모든 데이터를 저장할 수 있을 만큼 충분히 커야 합니다.

[source, shell]
....
# gpart create -s MBR mirror/gm0
# gpart add -t freebsd -a 4k mirror/gm0
# gpart show mirror/gm0
=>       63  156301423  mirror/gm0  MBR  (74G)
         63         63                    - free -  (31k)
        126  156301299                 1  freebsd  (74G)
  156301425         61                    - free -  (30k)
....

[source, shell]
....
# gpart create -s BSD mirror/gm0s1
# gpart add -t freebsd-ufs  -a 4k -s 2g mirror/gm0s1
# gpart add -t freebsd-swap -a 4k -s 4g mirror/gm0s1
# gpart add -t freebsd-ufs  -a 4k -s 2g mirror/gm0s1
# gpart add -t freebsd-ufs  -a 4k -s 1g mirror/gm0s1
# gpart add -t freebsd-ufs  -a 4k mirror/gm0s1
# gpart show mirror/gm0s1
=>        0  156301299  mirror/gm0s1  BSD  (74G)
          0          2                      - free -  (1.0k)
          2    4194304                   1  freebsd-ufs  (2.0G)
    4194306    8388608                   2  freebsd-swap (4.0G)
   12582914    4194304                   4  freebsd-ufs  (2.0G)
   16777218    2097152                   5  freebsd-ufs  (1.0G)
   18874370  137426928                   6  freebsd-ufs  (65G)
  156301298          1                      - free -  (512B)
....

미러를 부팅할 수 있게 하려면 부트코드를 MBR과 bsdlabel에 설치하고 활성 슬라이스를 설정합니다:

[source, shell]
....
# gpart bootcode -b /boot/mbr mirror/gm0
# gpart set -a active -i 1 mirror/gm0
# gpart bootcode -b /boot/boot mirror/gm0s1
....

새 미러에서 파일 시스템을 포맷하여 소프트 업데이트를 활성화합니다.

[source, shell]
....
# newfs -U /dev/mirror/gm0s1a
# newfs -U /dev/mirror/gm0s1d
# newfs -U /dev/mirror/gm0s1e
# newfs -U /dev/mirror/gm0s1f
....

이제 man:dump[8] 및 man:restore[8]을 사용하여 원본 [.filename]#ada0# 디스크의 파일 시스템을 미러에 복사할 수 있습니다.

[source, shell]
....
# mount /dev/mirror/gm0s1a /mnt
# dump -C16 -b64 -0aL -f - / | (cd /mnt && restore -rf -)
# mount /dev/mirror/gm0s1d /mnt/var
# mount /dev/mirror/gm0s1e /mnt/tmp
# mount /dev/mirror/gm0s1f /mnt/usr
# dump -C16 -b64 -0aL -f - /var | (cd /mnt/var && restore -rf -)
# dump -C16 -b64 -0aL -f - /tmp | (cd /mnt/tmp && restore -rf -)
# dump -C16 -b64 -0aL -f - /usr | (cd /mnt/usr && restore -rf -)
....

새 미러 파일 시스템을 가리키도록 [.filename]#/mnt/etc/fstab#을 편집합니다:

[.programlisting]
....
# Device		Mountpoint	FStype	Options	Dump	Pass#
/dev/mirror/gm0s1a	/		ufs	rw	1	1
/dev/mirror/gm0s1b	none		swap	sw	0	0
/dev/mirror/gm0s1d	/var		ufs	rw	2	2
/dev/mirror/gm0s1e	/tmp		ufs	rw	2	2
/dev/mirror/gm0s1f	/usr		ufs	rw	2	2
....

커널 모듈이 커널에 빌드되지 않은 경우 [.filename]#geom_mirror.ko# 커널 모듈이 부팅 시 모듈을 로드하도록 [.filename]#/mnt/boot/loader.conf#를 편집합니다:

[.programlisting]
....
geom_mirror_load="YES"
....

시스템을 재부팅하여 새 미러를 테스트하고 모든 데이터가 복사되었는지 확인합니다. BIOS는 미러를 하나의 드라이브가 아닌 두 개의 개별 드라이브로 인식합니다. 드라이브가 동일하므로 어떤 드라이브를 부팅하도록 선택하든 상관없습니다.

부팅에 문제가 있는 경우 <<gmirror-troubleshooting>>을 참조하세요. 원본 [.filename]#ada0# 디스크의 전원을 끄고 연결을 해제하면 오프라인 백업으로 보관할 수 있습니다.

사용 중 미러는 기존의 단일 드라이브와 똑같이 작동합니다.

[[geom-mirror-existing-drive]]
=== 기존 드라이브로 미러 만들기

이 예제에서는 FreeBSD가 이미 단일 디스크인 [.filename]#ada0#에 설치되어 있습니다. 새 디스크인 [.filename]#ada1#이 시스템에 연결되었습니다. 새 디스크에 하나의 디스크 미러가 생성되고 기존 시스템이 이 디스크에 복사된 다음 이전 디스크가 미러에 삽입됩니다. 이 약간 복잡한 절차가 필요한 이유는 `gmirror`가 각 디스크 끝에 512바이트의 메타데이터 블록을 넣어야 하고, 기존 [.filename]#ada0#에는 일반적으로 이미 모든 공간이 할당되어 있기 때문입니다.

[.filename]#geom_mirror.ko# 커널 모듈을 로드합니다:

[source, shell]
....
# gmirror load
....

`diskinfo`로 원본 디스크의 미디어 크기를 확인합니다:

[source, shell]
....
# diskinfo -v ada0 | head -n3
/dev/ada0
        512             # sectorsize
        1000204821504   # mediasize in bytes (931G)
....

새 디스크에 미러를 만듭니다. 미러 용량이 원래 [.filename]#ada0# 드라이브보다 크지 않도록 하기 위해 man:gnop[8]을 사용하여 정확히 같은 크기의 가짜 드라이브를 만듭니다. 이 드라이브는 데이터를 저장하지 않고 미러의 크기를 한정하는 데만 사용됩니다. man:gmirror[8]가 미러를 생성하면 새 [.filename]#ada1# 드라이브에 더 많은 공간이 있더라도 용량을 [.filename]#gzero.nop#의 크기로 제한합니다. 두 번째 줄의 _1000204821504_는 위의 `diskinfo`에 표시된 대로 [.filename]#ada0#의 미디어 크기와 동일하다는 점에 유의하세요.

[source, shell]
....
# geom zero load
# gnop create -s 1000204821504 gzero
# gmirror label -v gm0 gzero.nop ada1
# gmirror forget gm0
....

[.filename]#gzero.nop#는 데이터를 저장하지 않으므로 미러는 연결된 것으로 인식하지 않습니다. 미러는 연결되지 않은 구성 요소를 "잊어버리도록" 지시하여 [.filename]#gzero.nop#에 대한 참조를 제거합니다. 그 결과 미러 장치에는 [.filename]#ada1#이라는 단일 디스크만 포함됩니다.

[.filename]#gm0#을 만든 후 [.filename]#ada0#에서 파티션 테이블을 확인합니다. 이 출력은 1TB 드라이브에서 가져온 것입니다. 드라이브 끝에 할당되지 않은 공간이 있는 경우 [.filename]#ada0#에서 새 미러로 콘텐츠를 직접 복사할 수 있습니다.

그러나 다음 목록과 같이 출력에 디스크의 모든 공간이 할당된 것으로 표시되면 디스크 끝에 512바이트의 미러 메타데이터에 사용할 수 있는 공간이 없는 것입니다.

[source, shell]
....
# gpart show ada0
=>        63  1953525105        ada0  MBR  (931G)
          63  1953525105           1  freebsd  [active]  (931G)
....

이 경우 파티션 테이블을 편집하여 [.filename]#mirror/gm0#의 용량을 한 섹터씩 줄여야 합니다. 절차는 나중에 설명하겠습니다.

두 경우 모두 기본 디스크의 파티션 테이블은 먼저 `gpart backup` 및 `gpart restore`을 사용하여 복사해야 합니다.

[source, shell]
....
# gpart backup ada0 > table.ada0
# gpart backup ada0s1 > table.ada0s1
....

이 명령은 [.filename]#table.ada0# 및 [.filename]#table.ada0s1#이라는 두 개의 파일을 생성합니다. 이 예는 1TB 드라이브에서 가져온 것입니다:

[source, shell]
....
# cat table.ada0
MBR 4
1 freebsd         63 1953525105   [active]
....

[source, shell]
....
# cat table.ada0s1
BSD 8
1  freebsd-ufs          0    4194304
2 freebsd-swap    4194304   33554432
4  freebsd-ufs   37748736   50331648
5  freebsd-ufs   88080384   41943040
6  freebsd-ufs  130023424  838860800
7  freebsd-ufs  968884224  984640881
....

디스크 끝에 여유 공간이 표시되지 않으면 슬라이스와 마지막 파티션의 크기를 모두 한 섹터씩 줄여야 합니다. 두 파일을 편집하여 슬라이스와 마지막 파티션의 크기를 모두 하나씩 줄입니다. 이것이 각 목록의 마지막 숫자입니다.

[source, shell]
....
# cat table.ada0
MBR 4
1 freebsd         63 1953525104   [active]
....

[source, shell]
....
# cat table.ada0s1
BSD 8
1  freebsd-ufs          0    4194304
2 freebsd-swap    4194304   33554432
4  freebsd-ufs   37748736   50331648
5  freebsd-ufs   88080384   41943040
6  freebsd-ufs  130023424  838860800
7  freebsd-ufs  968884224  984640880
....

디스크 끝에 하나 이상의 섹터가 할당되지 않은 경우, 이 두 파일은 수정 없이 사용할 수 있습니다.

이제 파티션 테이블을 [.filename]#mirror/gm0#로 복원합니다:

[source, shell]
....
# gpart restore mirror/gm0 < table.ada0
# gpart restore mirror/gm0s1 < table.ada0s1
....

`gpart show`로 파티션 테이블을 확인합니다. 이 예제에서는 [.filename]#/#가 [.filename]#gm0s1a#에, [.filename]#/var#는 [.filename]#gm0s1d#에, [.filename]#/usr#는 [.filename]#gm0s1e#에, [.filename]#/data1#는 [.filename]#gm0s1f#에, [.filename]#/data2#는 [.filename]#gm0s1g#에 위치합니다.

[source, shell]
....
# gpart show mirror/gm0
=>        63  1953525104  mirror/gm0  MBR  (931G)
          63  1953525042           1  freebsd  [active]  (931G)
  1953525105          62              - free -  (31k)

# gpart show mirror/gm0s1
=>         0  1953525042  mirror/gm0s1  BSD  (931G)
           0     2097152             1  freebsd-ufs  (1.0G)
     2097152    16777216             2  freebsd-swap  (8.0G)
    18874368    41943040             4  freebsd-ufs  (20G)
    60817408    20971520             5  freebsd-ufs  (10G)
    81788928   629145600             6  freebsd-ufs  (300G)
   710934528  1242590514             7  freebsd-ufs  (592G)
  1953525042          63                - free -  (31k)
....

슬라이스와 마지막 파티션 모두 디스크 끝에 하나 이상의 여유블록이 있어야 합니다.

이 새 파티션에 파일 시스템을 만듭니다. 파티션 수는 원본 디스크인 [.filename]#ada0#와 일치하도록 변경됩니다.

[source, shell]
....
# newfs -U /dev/mirror/gm0s1a
# newfs -U /dev/mirror/gm0s1d
# newfs -U /dev/mirror/gm0s1e
# newfs -U /dev/mirror/gm0s1f
# newfs -U /dev/mirror/gm0s1g
....

미러를 부팅할 수 있게 하려면 부트코드를 MBR과 bsdlabel에 설치하고 활성 슬라이스를 설정합니다:

[source, shell]
....
# gpart bootcode -b /boot/mbr mirror/gm0
# gpart set -a active -i 1 mirror/gm0
# gpart bootcode -b /boot/boot mirror/gm0s1
....

미러에서 새 파티션을 사용하도록 [.filename]#/etc/fstab#을 변경합니다. 먼저 이 파일을 [.filename]#/etc/fstab.orig#에 복사하여 백업합니다.

[source, shell]
....
# cp /etc/fstab /etc/fstab.orig
....

[.filename]#/etc/fstab#을 편집하여 [.filename]#/dev/ada0#을 [.filename]#mirror/gm0#로 바꿉니다.

[.programlisting]
....
# Device		Mountpoint	FStype	Options	Dump	Pass#
/dev/mirror/gm0s1a	/		ufs	rw	1	1
/dev/mirror/gm0s1b	none		swap	sw	0	0
/dev/mirror/gm0s1d	/var		ufs	rw	2	2
/dev/mirror/gm0s1e	/usr		ufs	rw	2	2
/dev/mirror/gm0s1f	/data1		ufs	rw	2	2
/dev/mirror/gm0s1g	/data2		ufs	rw	2	2
....

커널 모듈이 커널에 빌드되지 않은 경우 [.filename]#geom_mirror.ko# 커널 모듈이 부팅 시 로드되도록 [.filename]#/boot/loader.conf#를 편집합니다:

[.programlisting]
....
geom_mirror_load="YES"
....

이제 man:dump[8] 및 man:restore[8]를 사용하여 원본 디스크의 파일 시스템을 미러에 복사할 수 있습니다. `dump -L`로 덤프된 각 파일 시스템은 먼저 스냅샷을 생성하므로 시간이 다소 걸릴 수 있습니다.

[source, shell]
....
# mount /dev/mirror/gm0s1a /mnt
# dump -C16 -b64 -0aL -f - /    | (cd /mnt && restore -rf -)
# mount /dev/mirror/gm0s1d /mnt/var
# mount /dev/mirror/gm0s1e /mnt/usr
# mount /dev/mirror/gm0s1f /mnt/data1
# mount /dev/mirror/gm0s1g /mnt/data2
# dump -C16 -b64 -0aL -f - /usr | (cd /mnt/usr && restore -rf -)
# dump -C16 -b64 -0aL -f - /var | (cd /mnt/var && restore -rf -)
# dump -C16 -b64 -0aL -f - /data1 | (cd /mnt/data1 && restore -rf -)
# dump -C16 -b64 -0aL -f - /data2 | (cd /mnt/data2 && restore -rf -)
....

시스템을 재시작하여 [.filename]#ada1#에서 부팅합니다. 모든 것이 정상적으로 작동하면 시스템이 [.filename]#mirror/gm0#에서 부팅되며, 이제 [.filename]#ada0#에 이전에 있던 것과 동일한 데이터가 포함됩니다. 부팅에 문제가 있는 경우 <<gmirror-troubleshooting>>을 참조하세요.

이 시점에 미러는 여전히 단일 [.filename]#ada1# 디스크로만 구성됩니다.

[.filename]#mirror/gm0#에서 성공적으로 부팅된 후 마지막 단계는 [.filename]#ada0#를 미러에 삽입하는 것입니다.

[IMPORTANT]
====
[.filename]#ada0#를 미러에 삽입하면 이전 내용이 미러의 데이터로 덮어씌워집니다. 미러에 [.filename]#ada0#을 추가하기 전에 [.filename]#mirror/gm0#이 [.filename]#ada0#와 동일한 내용을 가지고 있는지 확인하세요. man:dump[8] 및 man:restore[8]로 이전에 복사한 내용이 [.filename]#ada0#에 있는 내용과 동일하지 않으면 [.filename]#/etc/fstab#을 되돌리고 [.filename]#ada0#에 파일 시스템을 마운트한 후 재부팅하여 전체 절차를 다시 시작하세요.
====

[source, shell]
....
# gmirror insert gm0 ada0
GEOM_MIRROR: Device gm0: rebuilding provider ada0
....

두 디스크 간의 동기화가 즉시 시작됩니다. 진행 상황을 보려면 `gmirror status`를 사용하세요.

[source, shell]
....
# gmirror status
      Name    Status  Components
mirror/gm0  DEGRADED  ada1 (ACTIVE)
                      ada0 (SYNCHRONIZING, 64%)
....

잠시 후 동기화가 완료됩니다.

[source, shell]
....
GEOM_MIRROR: Device gm0: rebuilding provider ada0 finished.
# gmirror status
      Name    Status  Components
mirror/gm0  COMPLETE  ada1 (ACTIVE)
                      ada0 (ACTIVE)
....

이제 [.filename]#mirror/gm0#는 두 개의 디스크 [.filename]#ada0#과 [.filename]#ada1#으로 구성되며, 콘텐츠는 서로 자동으로 동기화됩니다. 사용 시 [.filename]#mirror/gm0#은 기존의 단일 드라이브처럼 작동합니다.

[[gmirror-troubleshooting]]
=== 문제 해결

시스템이 더 이상 부팅되지 않으면 새 미러 드라이브 중 하나에서 부팅하도록 BIOS 설정을 변경해야 할 수 있습니다. 두 미러 드라이브 모두 동일한 데이터가 포함되어 있으므로 부팅에 사용할 수 있습니다.

이 메시지와 함께 부팅이 중지되면 미러 장치에 문제가 있는 것입니다:

[source, shell]
....
Mounting from ufs:/dev/mirror/gm0s1a failed with error 19.

Loader variables:
  vfs.root.mountfrom=ufs:/dev/mirror/gm0s1a
  vfs.root.mountfrom.options=rw

Manual root filesystem specification:
  <fstype>:<device> [options]
      Mount <device> using filesystem <fstype>
      and with the specified (optional) option list.

    e.g. ufs:/dev/da0s1a
        zfs:tank
        cd9660:/dev/acd0 ro
          (which is equivalent to: mount -t cd9660 -o ro /dev/acd0 /)

  ?               List valid disk boot devices
  .               Yield 1 second (for background tasks)
  <empty line>    Abort manual input

mountroot>
....

[.filename]#/boot/loader.conf#에 [.filename]#geom_mirror.ko# 모듈을 로드하는 것을 잊어버리면 이런 문제가 발생할 수 있습니다. 이 문제를 해결하려면 FreeBSD 설치 미디어에서 부팅하고 첫 번째 프롬프트에서 `Shell`을 선택합니다. 그런 다음 미러 모듈을 로드하고 미러 장치를 마운트합니다:

[source, shell]
....
# gmirror load
# mount /dev/mirror/gm0s1a /mnt
....

[.filename]#/mnt/boot/loader.conf#를 편집하여 미러 모듈을 로드하도록 내용을 추가합니다:

[.programlisting]
....
geom_mirror_load="YES"
....

파일을 저장하고 재부팅합니다.

`error 19`를 유발하는 다른 문제는 수정하는 데 더 많은 노력이 필요합니다. 시스템이 [.filename]#ada0#에서 부팅되어야 하는데 [.filename]#/etc/fstab#이 올바르지 않은 경우 셸을 선택하라는 다른 프롬프트가 나타납니다. 부트로더 프롬프트에 `ufs:/dev/ada0s1a`를 입력하고 kbd:[Enter]를 누릅니다. [.filename]#/etc/fstab#의 편집한 내용을 취소한 다음, 미러가 아닌 원본 디스크([.filename]#ada0#)에서 파일 시스템을 마운트합니다. 시스템을 재부팅하고 절차를 다시 시도합니다.

[source, shell]
....
Enter full pathname of shell or RETURN for /bin/sh:
# cp /etc/fstab.orig /etc/fstab
# reboot
....

=== 디스크 장애에서 복구하기

디스크 미러링의 장점은 개별 디스크에 장애가 발생해도 미러 자체의 데이터는 손실되지 않는다는 것입니다. 위의 예에서 [.filename]#ada0#에 장애가 발생해도 미러는 계속 동작하며 나머지 정상 드라이브인 [.filename]#ada1#에서 데이터를 제공합니다.

고장난 드라이브를 교체하려면 시스템을 종료하고 고장난 드라이브를 동일하거나 더 큰 용량의 새 드라이브로 물리적으로 교체합니다. 제조업체는 드라이브를 기가바이트 단위로 평가할 때 다소 자의적인 기준을 사용하므로 실제로 확인하는 유일한 방법은 `diskinfo -v`에 표시된 총 섹터 수를 비교하는 것입니다. 미러보다 용량이 큰 드라이브는 작동하지만 새 드라이브의 남는 공간은 사용되지 않습니다.

컴퓨터의 전원이 다시 켜지면 미러는 하나의 드라이브만 있는 '성능 저하' 모드로 실행됩니다. 미러는 현재 연결되지 않은 드라이브를 무시하도록 지시받습니다:

[source, shell]
....
# gmirror forget gm0
....

<<geom-mirror-metadata>>의 지침에 따라 교체 디스크에서 이전 메타데이터를 모두 지워야 합니다. 그런 다음 대체 디스크(이 예에서는 [.filename]#ada4#)를 미러에 삽입합니다:

[source, shell]
....
# gmirror insert gm0 /dev/ada4
....

새 드라이브를 미러에 삽입하면 재동기화가 시작됩니다. 미러 데이터를 새 드라이브에 복사하는 이 과정은 시간이 오래 걸릴 수 있습니다. 복사하는 동안 미러의 성능이 크게 저하되므로 새 드라이브를 삽입하는 것은 컴퓨터의 부하가 적을 때 하는 것이 가장 좋습니다.

동기화 중인 드라이브와 완료 비율을 표시하는 `gmirror status`로 진행 상황을 모니터링할 수 있습니다. 재동기화 중에 상태는 `DEGRADED`으로 표시되며, 프로세스가 완료되면 `COMPLETE`로 변경됩니다.

[[geom-raid3]]
== RAID3 - 전용 패리티를 사용한 바이트 레벨 스트라이핑

RAID3는 여러 디스크 드라이브를 전용 패리티 디스크와 함께 단일 볼륨으로 결합하는 데 사용하는 방법입니다. RAID3 시스템에서 데이터는 전용 패리티 디스크 역할을 하는 하나의 디스크를 제외한 어레이의 모든 드라이브에 기록되는 여러 바이트 단위로 분할됩니다. 즉, RAID3 구현에서 디스크를 읽으면 어레이의 모든 디스크에 액세스합니다. 여러 디스크 컨트롤러를 사용하면 성능을 향상시킬 수 있습니다. RAID3 어레이는 1개의 드라이브에 대해 내결함성을 제공하는 동시에 어레이에 있는 모든 드라이브의 총 용량의 1 - 1/n배의 용량을 제공합니다(여기서 n은 어레이에 있는 하드 드라이브의 수입니다). 이러한 구성은 주로 멀티미디어 파일과 같이 크기가 큰 데이터를 저장하는 데 적합합니다.

RAID3 어레이를 구축하려면 최소 3개의 물리적 하드 드라이브가 필요합니다.  여러 디스크를 병렬로 읽거나 쓰기 위해 I/O 요청이
인터리빙되므로 각 디스크의 크기는 동일해야 합니다.  또한 RAID3의 특성상 드라이브의 수는 3, 5, 9, 17 등 또는 2^n +
1과 같아야 합니다.

이 섹션에서는 FreeBSD 시스템에서 소프트웨어 RAID3를 생성하는 방법을 설명합니다.

[NOTE]
====
이론적으로는 FreeBSD의 RAID3 어레이에서 부팅할 수 있지만, 이 구성은 일반적이지 않으며 권장하지 않습니다.
====

=== 전용 RAID3 어레이 만들기

FreeBSD에서 RAID3에 대한 지원은 man:graid3[8] GEOM 클래스에 의해 구현됩니다. FreeBSD에서 전용 RAID3 어레이를 만들려면 다음 단계가 필요합니다.

[.procedure]
. 먼저 다음 명령 중 하나를 실행하여 [.filename]#geom_raid3.ko# 커널 모듈을 로드합니다:
+
[source, shell]
....
# graid3 load
....
+
또는:
+
[source, shell]
....
# kldload geom_raid3
....

. 적절한 마운트 지점이 있는지 확인합니다. 이 명령은 마운트 지점으로 사용할 새 디렉터리를 만듭니다:
+
[source, shell]
....
# mkdir /multimedia
....

. 어레이에 추가할 디스크의 장치 이름을 결정하고 새 RAID3 장치를 생성합니다. 마지막으로 나열된 장치가 전용 패리티 디스크로 작동합니다. 이 예에서는 파티션되지 않은 ATA 드라이브 3개를 사용합니다: 데이터용은 [.filename]#ada1#과 [.filename]#ada2#, 패리티용은 [.filename]#ada3#입니다.
+
[source, shell]
....
# graid3 label -v gr0 /dev/ada1 /dev/ada2 /dev/ada3
Metadata value stored on /dev/ada1.
Metadata value stored on /dev/ada2.
Metadata value stored on /dev/ada3.
Done.
....

. 새로 생성한 [.filename]#gr0# 장치를 파티션하고 그 위에 UFS 파일 시스템을 설치합니다:
+
[source, shell]
....
# gpart create -s GPT /dev/raid3/gr0
# gpart add -t freebsd-ufs /dev/raid3/gr0
# newfs -j /dev/raid3/gr0p1
....
+
많은 숫자가 화면을 가로질러 미끄러지듯 움직이고 잠시 후 프로세스가 완료됩니다. 볼륨이 생성되었으며 마운트할 준비가 되었습니다:
+
[source, shell]
....
# mount /dev/raid3/gr0p1 /multimedia/
....
+
이제 RAID3 어레이를 사용할 준비가 되었습니다.

시스템 재부팅 시에도 이 설정을 유지하려면 추가 구성이 필요합니다.

[.procedure]
. 어레이를 마운트하기 전에 [.filename]#geom_raid3.ko# 모듈을 로드해야 합니다. 시스템 초기화 중에 커널 모듈을 자동으로 로드하려면 [.filename]#/boot/loader.conf#에 다음 줄을 추가합니다:
+
[.programlisting]
....
geom_raid3_load="YES"
....

. 시스템 부팅 프로세스 중에 어레이의 파일 시스템을 자동으로 마운트하려면 [.filename]#/etc/fstab#에 다음 볼륨 정보를 추가해야 합니다:
+
[.programlisting]
....
/dev/raid3/gr0p1	/multimedia	ufs	rw	2	2
....

[[geom-graid]]
== 소프트웨어 RAID 장치

일부 마더보드와 확장 카드는 컴퓨터가 RAID 어레이에서 부팅할 수 있도록 간단한 하드웨어(일반적으로 ROM 뿐인)를 추가합니다. 부팅 후에는 컴퓨터의 메인 프로세서에서 실행되는 소프트웨어에 의해 RAID 어레이에 대한 액세스가 처리됩니다. 이 "하드웨어 지원 소프트웨어 RAID"는 특정 운영 체제에 종속되지 않고 운영 체제가 로드되기 전에도 동작하는 RAID 어레이를 제공합니다.

사용 중인 하드웨어에 따라 여러 수준의 RAID가 지원됩니다. 전체 목록은 man:graid[8]를 참조하세요.

man:graid[8]를 사용하려면 [.filename]#geom_raid.ko# 커널 모듈이 필요하며, 이 모듈은 FreeBSD 9.1부터 [.filename]#GENERIC# 커널에 포함되어 있습니다. 필요한 경우 `graid load`로 수동 로드할 수 있습니다.

[[geom-graid-creating]]
=== 어레이 만들기

소프트웨어 RAID 장치에는 컴퓨터가 부팅될 때 특수 키를 눌러 들어갈 수 있는 메뉴가 있는 경우가 많습니다. 이 메뉴는 RAID 어레이를 생성하고 삭제하는 데 사용할 수 있습니다. man:graid[8]는 명령줄에서 직접 어레이를 생성할 수도 있습니다.

`graid label`은 새 어레이를 생성하는 데 사용됩니다. 이 예제에 사용된 마더보드에는 인텔 소프트웨어 RAID 칩셋이 있으므로 인텔 메타데이터 형식이 지정됩니다. 새 어레이에는 [.filename]#gm0# 레이블이 지정되며, 미러(RAID1)이며 [.filename]#ada0#와 [.filename]#ada1# 드라이브를 사용합니다.

[CAUTION]
====
드라이브의 일부 공간은 새 배열로 만들 때 덮어쓰기됩니다. 기존 데이터를 먼저 백업하세요!
====

[source, shell]
....
# graid label Intel gm0 RAID1 ada0 ada1
GEOM_RAID: Intel-a29ea104: Array Intel-a29ea104 created.
GEOM_RAID: Intel-a29ea104: Disk ada0 state changed from NONE to ACTIVE.
GEOM_RAID: Intel-a29ea104: Subdisk gm0:0-ada0 state changed from NONE to ACTIVE.
GEOM_RAID: Intel-a29ea104: Disk ada1 state changed from NONE to ACTIVE.
GEOM_RAID: Intel-a29ea104: Subdisk gm0:1-ada1 state changed from NONE to ACTIVE.
GEOM_RAID: Intel-a29ea104: Array started.
GEOM_RAID: Intel-a29ea104: Volume gm0 state changed from STARTING to OPTIMAL.
Intel-a29ea104 created
GEOM_RAID: Intel-a29ea104: Provider raid/r0 for volume gm0 created.
....

상태 확인을 통해 새 미러를 사용할 준비가 되었음을 알 수 있습니다:

[source, shell]
....
# graid status
   Name   Status  Components
raid/r0  OPTIMAL  ada0 (ACTIVE (ACTIVE))
                  ada1 (ACTIVE (ACTIVE))
....

어레이 장치는 [.filename]#/dev/raid/#에 나타납니다. 첫 번째 어레이는 [.filename]#r0#이라고 합니다. 추가 어레이가 있는 경우 [.filename]#r1#, [.filename]#r2# 등의 어레이로 명명됩니다.

이러한 장치 중 일부의 BIOS 메뉴에서는 이름에 특수 문자가 포함된 어레이를 만들 수 있습니다. 이러한 특수 문자로 인한 문제를 방지하기 위해 어레이에는 [.filename]#r0#과 같은 간단한 번호가 매겨진 이름이 지정됩니다. 위 예제에서 [.filename]#gm0#과 같은 실제 레이블을 표시하려면 man:sysctl[8]을 사용합니다:

[source, shell]
....
# sysctl kern.geom.raid.name_format=1
....

[[geom-graid-volumes]]
=== 다중 볼륨

일부 소프트웨어 RAID 장치는 하나의 어레이에 둘 이상의 _볼륨_을 지원합니다. 볼륨은 파티션처럼 작동하여 물리적 드라이브의 공간을 분할하여 다른 방식으로 사용할 수 있습니다. 예를 들어, 인텔 소프트웨어 RAID 장치는 두 개의 볼륨을 지원합니다. 이 예에서는 운영 체제를 안전하게 저장하기 위해 40G 미러를 생성하고, 빠른 임시 저장공간을 위해 20G RAID0(스트라이프) 볼륨을 생성합니다:

[source, shell]
....
# graid label -S 40G Intel gm0 RAID1 ada0 ada1
# graid add -S 20G gm0 RAID0
....

볼륨은 [.filename]#/dev/raid/#에 추가되어 [.filename]#rX#로 표시됩니다. 볼륨이 2개인 어레이는 [.filename]#r0# 및 [.filename]#r1#으로 표시됩니다.

다른 소프트웨어 RAID 장치에서 지원하는 볼륨 수는 man:graid[8]를 참조하세요.

[[geom-graid-converting]]
=== 단일 드라이브를 미러로 변환하기

특정 조건에서는 기존 단일 드라이브를 다시 포맷하지 않고도 man:graid[8] 어레이로 변환할 수 있습니다. 변환하는 동안 데이터 손실을 방지하려면 기존 드라이브가 다음의 최소 요구 사항을 충족해야 합니다:

* 드라이브는 MBR 파티션 체계로 파티셔닝해야 합니다. 드라이브 끝에 메타데이터가 있는 GPT 또는 기타 파티셔닝 체계는 man:graid[8] 메타데이터로 덮어 씌여지며 손상됩니다.
* 드라이브 끝에 man:graid[8] 메타데이터를 저장할 수 있는 파티션되지 않고 사용되지 않은 충분한 공간이 있어야 합니다. 이 메타데이터의 크기는 다양하지만 가장 큰 메타데이터는 64M를 차지하므로 최소한 그 정도의 여유 공간을 확보하는 것이 좋습니다.

드라이브가 이러한 요구 사항을 충족하는 경우, 먼저 전체 백업을 만드세요. 그런 다음 해당 드라이브로 단일 드라이브 미러를 만듭니다:

[source, shell]
....
# graid label Intel gm0 RAID1 ada0 NONE
....

man:graid[8] 메타데이터가 드라이브 끝의 사용되지 않는 공간에 기록됩니다. 이제 미러에 두 번째 드라이브를 삽입할 수 있습니다:

[source, shell]
....
# graid insert raid/r0 ada1
....

원본 드라이브의 데이터가 즉시 두 번째 드라이브에 복사되기 시작합니다. 미러는 복사가 완료될 때까지 성능이 저하된 상태로 작동합니다.

[[geom-graid-inserting]]
=== 어레이에 새 드라이브 추가하기

장애가 발생했거나 누락된 드라이브의 대체하기 위해 드라이브를 어레이에 추가할 수 있습니다. 실패하거나 누락된 드라이브가 없는 경우 새 드라이브가 예비 드라이브(스페어 드라이브)가 됩니다. 예를 들어, 작동 중인 2-드라이브 미러에 새 드라이브를 삽입하면 3-드라이브 미러가 아니라 예비 드라이브가 하나 있는 2-드라이브 미러가 됩니다.

예제에선, 미러 어레이에 새로 삽입된 드라이브로 즉시 데이터를 복사하기 시작합니다. 새 드라이브에 있는 기존 정보는 모두 덮어쓰기됩니다.

[source, shell]
....
# graid insert raid/r0 ada1
GEOM_RAID: Intel-a29ea104: Disk ada1 state changed from NONE to ACTIVE.
GEOM_RAID: Intel-a29ea104: Subdisk gm0:1-ada1 state changed from NONE to NEW.
GEOM_RAID: Intel-a29ea104: Subdisk gm0:1-ada1 state changed from NEW to REBUILD.
GEOM_RAID: Intel-a29ea104: Subdisk gm0:1-ada1 rebuild start at 0.
....

[[geom-graid-removing]]
=== 어레이에서 드라이브 제거하기

개별 드라이브는 어레이에서 영구적으로 제거하고 해당 메타데이터를 삭제할 수 있습니다:

[source, shell]
....
# graid remove raid/r0 ada1
GEOM_RAID: Intel-a29ea104: Disk ada1 state changed from ACTIVE to OFFLINE.
GEOM_RAID: Intel-a29ea104: Subdisk gm0:1-[unknown] state changed from ACTIVE to NONE.
GEOM_RAID: Intel-a29ea104: Volume gm0 state changed from OPTIMAL to DEGRADED.
....

[[geom-graid-stopping]]
=== 어레이 중지하기

드라이브에서 메타데이터를 제거하지 않고도 어레이를 중지할 수 있습니다. 시스템이 부팅되면 어레이가 다시 시작됩니다.

[source, shell]
....
# graid stop raid/r0
....

[[geom-graid-status]]
=== 어레이 상태 확인하기

어레이 상태는 언제든지 확인할 수 있습니다. 위의 예에서 미러에 드라이브를 추가한 후 원본 드라이브에서 새 드라이브로 데이터가 복사되고 있습니다:

[source, shell]
....
# graid status
   Name    Status  Components
raid/r0  DEGRADED  ada0 (ACTIVE (ACTIVE))
                   ada1 (ACTIVE (REBUILD 28%))
....

`RAID0` 또는 `CONCAT`과 같은 일부 유형의 어레이는 디스크가 실패한 경우 상태 보고서에 표시되지 않을 수 있습니다. 이러한 부분적으로 실패한 어레이를 보려면 `-ga`를 추가합니다:

[source, shell]
....
# graid status -ga
          Name  Status  Components
Intel-e2d07d9a  BROKEN  ada6 (ACTIVE (ACTIVE))
....

[[geom-graid-deleting]]
=== 어레이 삭제하기

어레이는 어레이에서 모든 볼륨을 삭제하여 파괴됩니다. 마지막으로 존재하는 볼륨이 삭제되면 어레이가 중지되고 메타데이터가 드라이브에서 제거됩니다:

[source, shell]
....
# graid delete raid/r0
....

[[geom-graid-unexpected]]
=== 예기치 않은 어레이 삭제하기

드라이브에 이전에 사용했거나 제조업체 테스트에서 사용된 man:graid[8] 메타데이터가 포함되어 있을 수 있습니다. man:graid[8]는 이러한 드라이브를 감지하고 어레이를 생성하여 개별 드라이브에 대한 액세스를 방해합니다. 원치 않는 메타데이터를 제거하려면:

[.procedure]
. 시스템을 부팅합니다. 부팅 메뉴에서 로더 프롬프트에서 `2`를 선택합니다. 엔터를 칩니다:
+
[source, shell]
....
OK set kern.geom.raid.enable=0
OK boot
....
+
시스템이 man:graid[8]를 비활성화한 상태로 부팅됩니다.
. 영향을 받은 드라이브의 모든 데이터를 백업하세요.
. 해결 방법으로 다음을 추가하여 man:graid[8] 어레이 감지를 비활성화할 수 있습니다
+
[.programlisting]
....
kern.geom.raid.enable=0
....
+
[.filename]#/boot/loader.conf#에서.
+
영향을 받은 드라이브에서 man:graid[8] 메타데이터를 영구적으로 제거하려면, FreeBSD 설치 CD-ROM 또는 메모리 스틱으로 부팅하고 `Shell`을 선택합니다. `status`를 사용하여 어레이의 이름(일반적으로 `raid/r0`)을 찾습니다:
+
[source, shell]
....
# graid status
   Name   Status  Components
raid/r0  OPTIMAL  ada0 (ACTIVE (ACTIVE))
                  ada1 (ACTIVE (ACTIVE))
....
+
이름을 이용해 볼륨을 삭제합니다:
+
[source, shell]
....
# graid delete raid/r0
....
+
표시된 볼륨이 두 개 이상인 경우 각 볼륨에 대해 이 과정을 반복합니다. 마지막 어레이가 삭제되면 볼륨이 삭제됩니다.
+
재부팅하고 데이터를 확인하며 필요한 경우 백업에서 복원합니다. 메타데이터를 제거한 후 [.filename]#/boot/loader.conf#의 `kern.geom.raid.enable=0` 항목도 제거할 수 있습니다.

[[geom-ggate]]
== GEOM 게이트 네트워크

GEOM은 디스크, CD, 파일 시스템과 같은 장치에 원격 액세스를 제공하기 위한 간단한 메커니즘을 제공하는데, 이 메커니즘은 GEOM 게이트 네트워크 데몬인 ggated를 사용합니다. 장치가 있는 시스템은 서버 데몬을 실행하며, 이 서버 데몬은 ggatec를 사용하여 클라이언트의 요청을 처리합니다. 클라이언트와 서버 간의 연결이 암호화되지 않으므로 장치에 민감한 데이터가 포함되어서는 안 됩니다.

Crossref:network-servers[network-nfs,"네트워크 파일 시스템(NFS)"]에서 설명하는 NFS와 유사하게, ggated는 내보내기 파일을 사용하여 구성됩니다. 이 파일은 내보낸 리소스에 액세스할 수 있는 시스템과 제공되는 액세스 수준을 지정합니다. 예를 들어 클라이언트 `192.168.1.5`에 첫 번째 SCSI 디스크의 네 번째 슬라이스에 대한 읽기 및 쓰기 액세스 권한을 부여하려면 다음 줄을 사용하여 [.filename]#/etc/gg.exports#를 만듭니다:

[.programlisting]
....
192.168.1.5 RW /dev/da0s4d
....

장치를 내보내기 전에 장치가 현재 마운트되어 있지 않은지 확인하세요. 그런 다음 ggated를 시작합니다:

[source, shell]
....
# ggated
....

대체 수신 포트를 지정하거나 내보내기 파일의 기본 위치를 변경하는 데 몇 가지 옵션을 사용할 수 있습니다. 자세한 내용은 man:ggated[8]을 참조하세요.

클라이언트 시스템에서 내보낸 장치에 액세스하려면 먼저 `ggatec`을 사용하여 서버의 IP 주소와 내보낸 장치의 장치 이름을 지정합니다. 성공하면 이 명령은 마운트할 `ggate` 장치 이름을 표시합니다. 지정한 장치 이름을 사용 가능한 마운트 지점에 마운트합니다. 이 예는 `192.168.1.1`의 [.filename]#/dev/da0s4d# 파티션에 연결한 다음 [.filename]#/mnt#에 [.filename]#/dev/ggate0#을 마운트합니다:

[source, shell]
....
# ggatec create -o rw 192.168.1.1 /dev/da0s4d
ggate0
# mount /dev/ggate0 /mnt
....

이제 클라이언트에서 [.filename]#/mnt#를 통해 서버의 장치에 액세스할 수 있습니다. `ggatec`에 대한 자세한 내용과 몇 가지 사용 예는 man:ggatec[8]를 참조하세요.

[NOTE]
====
장치가 현재 서버 또는 네트워크의 다른 클라이언트에 마운트되어 있으면 마운트가 실패합니다. 네트워크 리소스에 동시에 액세스해야 하는 경우 대신 NFS를 사용하세요.
====

장치가 더 이상 필요하지 않으면 다른 클라이언트에서 리소스를 사용할 수 있도록 `umount`로 장치를 마운트 해제합니다.

[[geom-glabel]]
== 디스크 장치에 라벨 지정

시스템 초기화 중에 FreeBSD 커널은 디바이스가 발견되면 디바이스 노드를 생성합니다. 이 장치 검색 방법에는 몇 가지 문제가 있습니다. 예를 들어, USB를 통해 새 디스크 장치가 추가되면 어떻게 될까요? 플래시 장치에 [.filename]#da0#의 장치 이름이 전달되고 원래 [.filename]#da0#이 [.filename]#da1#으로 바뀔 수 있습니다. 이로 인해 파일 시스템이 [.filename]#/etc/fstab#에 나열되어 있는 파일 시스템을 마운트하는 데 문제가 발생하여 시스템이 부팅되지 않을 수도 있습니다.

한 가지 해결책은 SCSI 장치를 순서대로 연결하여 SCSI 카드에 추가된 새 장치에 사용하지 않는 장치 번호가 발급되도록 하는 것입니다. 하지만 기본 SCSI 디스크를 대체할 수 있는 USB 장치는 어떻게 해야 할까요? USB 장치는 일반적으로 SCSI 카드보다 먼저 프로빙되기 때문에 이런 문제가 발생합니다. 한 가지 해결책은 시스템이 부팅된 후에만 이러한 장치를 삽입하는 것입니다. 또 다른 방법은 단일 ATA 드라이브만 사용하고 [.filename]#/etc/fstab#에 SCSI 장치를 나열하지 않는 것입니다.

더 나은 해결책은 `glabel`을 사용하여 디스크 장치에 레이블을 지정하고 [.filename]#/etc/fstab#에 레이블을 사용하는 것입니다. `glabel`은 주어진 공급자의 마지막 섹터에 레이블을 저장하므로 재부팅 시에도 레이블이 영구적으로 유지됩니다. 이 레이블을 장치로 사용하면 어떤 장치 노드를 통해 액세스하는지에 관계없이 파일 시스템을 항상 마운트할 수 있습니다.

[NOTE]
====
`glabel`은 일시적 레이블과 영구 레이블을 모두 생성할 수 있습니다. 재부팅할 때마다 영구 레이블만 일관되게 유지됩니다. 레이블 간의 차이점에 대한 자세한 내용은 man:glabel[8]을 참조하세요.
====

=== 레이블 유형 및 예제

영구 레이블은 일반 또는 파일 시스템 레이블이 될 수 있습니다. 영구 파일 시스템 레이블은 man:tunefs[8] 또는 man:newfs[8]로 만들 수 있습니다. 이러한 유형의 레이블은 [.filename]#/dev#의 하위 디렉터리에 생성되며 파일 시스템 유형에 따라 이름이 지정됩니다. 예를 들어, UFS2 파일 시스템 레이블은 [.filename]#/dev/ufs#에 생성됩니다. 일반 영구 레이블은 `glabel label`로 생성할 수 있습니다. 이러한 레이블은 파일 시스템별로 다르지 않으며 [.filename]#/dev/label#에 생성됩니다.

임시 레이블은 다음 재부팅 시 삭제됩니다. 이러한 레이블은 [.filename]#/dev/label#에 생성되며 테스트를 할 때 적합합니다. 임시 레이블은 `glabel create`를 사용하여 만들 수 있습니다.

데이터를 파괴하지 않고 UFS2 파일 시스템에 대한 영구 레이블을 만들려면 다음 명령을 실행합니다:

[source, shell]
....
# tunefs -L home /dev/da3
....

이제 레이블이 [.filename]#/dev/ufs#에 존재해야 하며, [.filename]#/etc/fstab#에 추가할 수 있습니다:

[.programlisting]
....
/dev/ufs/home		/home            ufs     rw              2      2
....

[NOTE]
====
`tunefs`를 실행하는 동안 파일 시스템을 마운트해서는 안됩니다.
====

이제 파일 시스템을 마운트할 수 있습니다:

[source, shell]
....
# mount /home
....

이 시점부터는 부팅 시 [.filename]#/boot/loader.conf#로 [.filename]#geom_label.ko# 커널 모듈이 로드되거나 `GEOM_LABEL` 커널 옵션이 있는 한 시스템에 악영향을 미치지 않고 장치 노드를 변경할 수 있습니다.

파일 시스템은 `newfs`와 함께 `-L` 플래그를 사용하여 기본 레이블로 만들 수도 있습니다. 자세한 내용은 man:newfs[8]을 참조하십시오.

다음 명령을 사용하여 레이블을 삭제할 수 있습니다:

[source, shell]
....
# glabel destroy home
....

다음 예는 부팅 디스크의 파티션에 레이블을 지정하는 방법을 보여줍니다.

.부팅 디스크의 파티션에 레이블 지정하기
[example]
====
부팅 디스크의 파티션에 영구적으로 레이블을 지정하면 디스크가 다른 컨트롤러로 이동하거나 다른 시스템으로 전송되더라도 시스템이 정상적으로 부팅할 수 있습니다. 이 예에서는 현재 시스템에서 [.filename]#ad0#으로 인식되는 단일 ATA 디스크가 사용된다고 가정합니다. 또한 [.filename]#/#, [.filename]#/var#, [.filename]#/usr# 및 [.filename]#/tmp#와 스왑 파티션이 있는 표준 FreeBSD 파티션 체계가 사용된다고 가정합니다.

시스템을 재부팅하고 man:loader[8] 프롬프트에서 kbd:[4]를 눌러 단일 사용자 모드로 부팅합니다. 그런 다음, 다음 명령을 입력합니다:

[source, shell]
....
# glabel label rootfs /dev/ad0s1a
GEOM_LABEL: Label for provider /dev/ad0s1a is label/rootfs
# glabel label var /dev/ad0s1d
GEOM_LABEL: Label for provider /dev/ad0s1d is label/var
# glabel label usr /dev/ad0s1f
GEOM_LABEL: Label for provider /dev/ad0s1f is label/usr
# glabel label tmp /dev/ad0s1e
GEOM_LABEL: Label for provider /dev/ad0s1e is label/tmp
# glabel label swap /dev/ad0s1b
GEOM_LABEL: Label for provider /dev/ad0s1b is label/swap
# exit
....

시스템이 다중 사용자 부팅을 계속 진행합니다. 부팅이 완료되면 [.filename]#/etc/fstab#을 편집하고 기존 장치 이름을 해당 레이블로 바꿉니다. 최종 [.filename]#/etc/fstab#은 다음과 같이 표시됩니다:

[.programlisting]
....
# Device                Mountpoint      FStype  Options         Dump    Pass#
/dev/label/swap         none            swap    sw              0       0
/dev/label/rootfs       /               ufs     rw              1       1
/dev/label/tmp          /tmp            ufs     rw              2       2
/dev/label/usr          /usr            ufs     rw              2       2
/dev/label/var          /var            ufs     rw              2       2
....

이제 시스템을 재부팅할 수 있습니다. 모든 것이 잘 되었다면 정상적으로 나타나고 `mount` 명령은 다음과 같이 표시됩니다:

[source, shell]
....
# mount
/dev/label/rootfs on / (ufs, local)
devfs on /dev (devfs, local)
/dev/label/tmp on /tmp (ufs, local, soft-updates)
/dev/label/usr on /usr (ufs, local, soft-updates)
/dev/label/var on /var (ufs, local, soft-updates)
....

====

man:glabel[8] 클래스는 고유한 파일 시스템 ID인 `ufsid`를 기반으로 하는 UFS 파일 시스템용 레이블 유형을 지원합니다. 이러한 레이블은 [.filename]#/dev/ufsid#에서 찾을 수 있으며 시스템 시작 중에 자동으로 생성됩니다. `ufsid` 레이블은 [.filename]#/etc/fstab#을 이용하여 파티션을 마운트할 수 있습니다. `glabel status`를 사용하여 파일 시스템과 해당 `ufsid` 레이블 목록을 받습니다:

[source, shell]
....
% glabel status
                  Name  Status  Components
ufsid/486b6fc38d330916     N/A  ad4s1d
ufsid/486b6fc16926168e     N/A  ad4s1f
....

위의 예에서 [.filename]#ad4s1d#는 [.filename]#/var#를 나타내고, [.filename]#ad4s1f#는 [.filename]#/usr#를 나타냅니다. 표시된 `ufsid` 값을 사용하면 이제 이러한 파티션을 [.filename]#/etc/fstab#에 다음 항목으로 마운트할 수 있습니다:

[.programlisting]
....
/dev/ufsid/486b6fc38d330916        /var        ufs        rw        2      2
/dev/ufsid/486b6fc16926168e        /usr        ufs        rw        2      2
....

'ufsid' 레이블이 있는 모든 파티션은 이러한 방식으로 마운트할 수 있으므로 수동으로 영구 레이블을 생성할 필요가 없으며, 장치 이름 독립 마운트의 이점을 그대로 누릴 수 있습니다.

[[geom-gjournal]]
== GEOM을 통한 UFS 저널링

UFS 파일 시스템에서 저널에 대한 지원은 FreeBSD에서 사용할 수 있습니다. 이 구현은 GEOM 서브시스템을 통해 제공되며 `gjournal`을 사용하여 구성됩니다. 다른 파일 시스템 저널링 구현과 달리, `gjournal` 방법은 블록 기반이며 파일 시스템의 일부로 구현되지 않습니다. 이것은 GEOM 확장입니다.

저널링은 메타데이터 및 파일 쓰기가 디스크에 커밋되기 전에, 전체 디스크 쓰기 작업을 구성하는 변경 사항과 같은 파일 시스템 트랜잭션 로그를 저장합니다. 이 트랜잭션 로그를 나중에 재생하여 파일 시스템 트랜잭션을 다시 실행할 수 있으므로 파일 시스템 불일치를 방지할 수 있습니다.

이 방법은 데이터 손실 및 파일 시스템의 불일치로부터 보호하는 또 다른 메커니즘을 제공합니다. 메타데이터 업데이트를 추적하고 적용하는 소프트 업데이트나 파일 시스템의 이미지를 생성하는 스냅샷과는 달리, 이 작업을 위해 특별히 디스크 공간에 로그가 저장됩니다. 성능 향상을 위해 저널을 다른 디스크에 저장할 수 있습니다. 이 구성에서는 저널 제공자 또는 저장 장치를 장치 뒤에 나열하여 저널링을 사용하도록 설정해야 합니다.

[.filename]#GENERIC# 커널은 `gjournal`을 지원합니다. 부팅 시 [.filename]#geom_journal.ko# 커널 모듈을 자동으로 로드하려면 [.filename]#/boot/loader.conf#에 다음 줄을 추가합니다:

[.programlisting]
....
geom_journal_load="YES"
....

사용자 정의 커널을 사용하는 경우 커널 구성 파일에 다음 내용이 있는지 확인하세요:

[.programlisting]
....
options	GEOM_JOURNAL
....

모듈이 로드되면 다음 단계에 따라 새 파일 시스템에 저널을 만들 수 있습니다. 이 예에서 [.filename]#da4#는 새 SCSI 디스크입니다:

[source, shell]
....
# gjournal load
# gjournal label /dev/da4
....

이렇게 하면 모듈이 로드되고 [.filename]#/dev/da4#에 [.filename]#/dev/da4.journal# 장치 노드가 생성됩니다.

이제 저널링된 장치에 UFS 파일 시스템을 생성한 다음 기존 마운트 지점에 마운트할 수 있습니다:

[source, shell]
....
# newfs -O 2 -J /dev/da4.journal
# mount /dev/da4.journal /mnt
....

[NOTE]
====
여러 개의 슬라이스가 있는 경우 각 개별 슬라이스에 대해 저널이 생성됩니다. 예를 들어, [.filename]#ad4s1#과 [.filename]#ad4s2#가 모두 슬라이스인 경우, `gjournal`은 [.filename]#ad4s1.journal#과 [.filename]#ad4s2.journal#을 생성합니다.
====

`tunefs`를 사용해 현재 파일 시스템에서도 저널링을 활성화할 수 있습니다. 그러나 기존 파일 시스템을 변경하기 전에 항상 백업을 만드세요. 대부분의 경우 `gjournal`은 저널을 만들 수 없으면 실패하지만, `tunefs`를 잘못 사용하여 발생하는 데이터 손실을 방지하지는 못합니다. 이 명령에 대한 자세한 내용은 man:gjournal[8] 및 man:tunefs[8]를 참조하십시오.

FreeBSD 시스템의 부팅 디스크를 저널링할 수 있습니다. 자세한 지침은 extref:{gjournal-desktop}[데스크톱 PC에서 UFS 저널링 구현하기] 문서를 참조하세요.
