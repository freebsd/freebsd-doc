---
title: Kapitel 21. Virtualisierung
part: Teil III. Systemadministration
prev: books/handbook/filesystems
next: books/handbook/l10n
showBookMenu: true
weight: 25
path: "/books/handbook/virtualization/"
---

[[virtualization]]
= Virtualisierung
:doctype: book
:toc: macro
:toclevels: 1
:icons: font
:sectnums:
:sectnumlevels: 6
:sectnumoffset: 21
:partnums:
:source-highlighter: rouge
:experimental:
:images-path: books/handbook/virtualization/

ifdef::env-beastie[]
ifdef::backend-html5[]
:imagesdir: ../../../../images/{images-path}
endif::[]
ifndef::book[]
include::shared/authors.adoc[]
include::shared/mirrors.adoc[]
include::shared/releases.adoc[]
include::shared/attributes/attributes-{{% lang %}}.adoc[]
include::shared/{{% lang %}}/teams.adoc[]
include::shared/{{% lang %}}/mailing-lists.adoc[]
include::shared/{{% lang %}}/urls.adoc[]
toc::[]
endif::[]
ifdef::backend-pdf,backend-epub3[]
include::../../../../../shared/asciidoctor.adoc[]
endif::[]
endif::[]

ifndef::env-beastie[]
toc::[]
include::../../../../../shared/asciidoctor.adoc[]
endif::[]

[[virtualization-synopsis]]
== Übersicht

Virtualisierungssoftware erlaubt es, mehrere Betriebssysteme gleichzeitig auf dem selben Computer laufen zu lassen. Derartige Softwaresysteme für PCs setzen in der Regel ein Host-Betriebssystem voraus, auf dem die Virtualisierungssoftware läuft und unterstützen eine nahezu beliebige Anzahl von Gast-Betriebssystemen.

Nachdem Sie dieses Kapitel gelesen haben,

* Kennen Sie den Unterscheid zwischen einem Host-Betriebssystem und einem Gast-Betriebssystem.
* Können Sie FreeBSD auf einem Intel(R)-basierenden Apple(R) Mac(R) installieren.
* Können Sie FreeBSD unter Microsoft(R) Windows(R) und Virtual PC installieren.
* Wissen Sie, wie man ein virtualisiertes FreeBSD-System für optimale Leistung konfiguriert.

Bevor Sie dieses Kapitel lesen, sollten Sie

* Die crossref:basics[basics,Grundlagen von UNIX(R) und FreeBSD] verstehen.
* Wissen, wie Sie crossref:bsdinstall[bsdinstall,FreeBSD installieren] können.
* Wissen, wie Sie eine crossref:advanced-networking[advanced-networking,Netzwerkverbindung konfigurieren].
* Wissen, wie Sie crossref:ports[ports,zusätzliche Software installieren] können.

[[virtualization-guest-parallels]]
== FreeBSD als Gast-Betriebssystem unter Parallels für Mac OS(R) X

Parallels Desktop für Mac(R) ist ein kommerzielles Softwareprodukt, welches für Intel(R)-basierende Apple(R) Mac(R)-Computer mit Mac OS(R) X 10.4.6 oder höher verfügbar ist. FreeBSD wird von diesem Softwarepaket als Gast-Betriebssystem vollständig unterstützt. Nach der Installation von Parallels auf Mac OS(R) X konfigurieren Sie als erstes eine virtuelle Maschine, in der Sie danach das gewünschte Gast-Betriebssystem (in diesem Fall FreeBSD) installieren.

[[virtualization-guest-parallels-install]]
=== Installation von FreeBSD unter Parallels/Mac OS(R) X

Der erste Schritt bei der Installation von FreeBSD unter Parallels ist es, eine virtuelle Maschine zu konfigurieren, in der Sie FreeBSD installieren können. Dazu wählen Sie bei der Frage nach dem menu:Guest OS Type[][.guimenuitem]#FreeBSD# aus:

image::parallels-freebsd1.png[]

Legen Sie geeignete Größen für Festplatten- und Arbeitsspeicher für die zu erstellende FreeBSD-Instanz fest. 4 GB Plattenplatz sowie 512 MB RAM sind in der Regel für die Arbeit unter Parallels ausreichend:

image::parallels-freebsd2.png[]

image::parallels-freebsd3.png[]

image::parallels-freebsd4.png[]

image::parallels-freebsd5.png[]

Wählen Sie den gewünschten Netzwerktyp aus und konfigurieren Sie die Netzwerkverbindung:

image::parallels-freebsd6.png[]

image::parallels-freebsd7.png[]

Speichern Sie Ihre Eingaben, um die Konfiguration abzuschließen:

image::parallels-freebsd8.png[]

image::parallels-freebsd9.png[]

Nachdem Sie die virtuelle Maschine erstellt haben, installieren Sie im nächsten Schritt FreeBSD in dieser virtuellen Maschine. Dazu verwenden Sie am besten eine offizielle FreeBSD-CD/DVD oder Sie laden von einem offiziellen FTP-Server ein ISO-Abbild auf Ihren Mac(R) herunter. Danach klicken Sie auf das Laufwerksymbol in der rechten unteren Ecke des Parallels-Fensters, um das virtuelles Laufwerk mit dem ISO-Abbild oder mit dem physikalischen CD-ROM-Laufwerk des Computers zu verknüpfen.

image::parallels-freebsd11.png[]

Nachdem Sie diese Verknüpfung hergestellt haben, starten sie die virtuelle FreeBSD-Maschine neu, indem Sie auf das Symbol "Neustarten" klicken. Parallels startet nun ein Spezial-BIOS, das zuerst prüft, ob eine CD-ROM eingelegt wurde.

image::parallels-freebsd10.png[]

In diesem Fall findet das BIOS ein FreeBSD-Installationsmedium und beginnt eine normale Installation. Versuchen Sie jetzt noch nicht Xorg zu konfigurieren.

image::parallels-freebsd12.png[]

Nachdem die Installation abgeschlossen ist, können Sie die virtuelle FreeBSD-Maschine starten.

image::parallels-freebsd13.png[]

[[virtualization-guest-parallels-configure]]
=== FreeBSD für den Einsatz unter Parallels konfigurieren

Nachdem FreeBSD erfolgreich unter Mac OS(R) X mit Parallels installiert wurde, sollten Sie das virtuelle FreeBSD-System für virtualisierte Operationen optimieren:

[.procedure]
. Setzen der Bootloader-Variablen
+ 
Die wichtigste Änderung ist es, die Variable `kern.hz` zu verkleinern, um so die CPU-Auslastung in der Parallels-Umgebung zu verringern.
+
[.programlisting]
....
kern.hz=100
....

+ 
Ohne diese Einstellung kann ein unbeschäftigtes FreeBSD unter Parallels trotzdem rund 15 Prozent der CPU-Leistung eines Single Prozessor iMac(R)'s verbrauchen. Nach dieser Änderung reduziert sich dieser Wert auf etwa 5 Prozent.
. Erstellen einer neuen Kernelkonfigurationsdatei
+ 
Sie können alle SCSI-, FireWire- und USB-Laufwerks-Treiber entfernen. Parallels stellt einen virtuellen Netzwerkadapter bereit, der den man:ed[4]-Treiber verwendet. Daher können alle Netzwerkgeräte bis auf man:ed[4] und man:miibus[4] aus dem Kernel entfernt werden.
. Netzwerkbetrieb einrichten
+ 
Die einfachste Netzwerkkonfiguration ist der Einsatz von DHCP, um die virtuelle Maschine mit dem gleichen lokalen Netzwerk, in dem sich der Host-Mac(R) befindet, zu verbinden. Dazu fügen Sie die Zeile `ifconfig_ed0="DHCP"` in [.filename]#/etc/rc.conf# ein. Weitere Informationen zur Konfiguration des Netzwerks unter FreeBSD finden Sie im crossref:advanced-networking[advanced-networking,Netzwerkverbindung konfigurieren].

[[virtualization-guest-virtualpc]]
== FreeBSD als Gast-Betriebssystem unter Virtual PC für Windows(R)

Virtual PC für Windows(R) wird von Microsoft(R) kostenlos zum Download angeboten. Die Systemanforderungen für dieses Programm finden Sie http://www.microsoft.com/windows/downloads/virtualpc/sysreq.mspx[ hier]. Nachdem Virtual PC unter Microsoft(R) Windows(R) installiert wurde, muss eine virtuelle Maschine konfiguriert und das gewünschte Betriebssystem installiert werden.

[[virtualization-guest-virtualpc-install]]
=== FreeBSD in Virtual PC installieren

Der erste Schritt zur Installation von FreeBSD in Virtual PC ist es, eine neue virtuelle Maschine zu erstellen, in die Sie FreeBSD installieren können. Dazu wählen Sie die Option [.guimenuitem]#Create a virtual machine#, wenn Sie danach gefragt werden:

image::virtualpc-freebsd1.png[]

image::virtualpc-freebsd2.png[]

Bei der Frage nach dem [.guimenuitem]#Operating system# wählen Sie [.guimenuitem]#Other#:

image::virtualpc-freebsd3.png[]

Danach müssen Sie den gewünschten Plattenplatz sowie die Größe des Hauptspeichers angeben. 4 GB Plattenplatz sowie 512 MB RAM sollten für die Installation von FreeBSD in Virtual PC ausreichend sein:

image::virtualpc-freebsd4.png[]

image::virtualpc-freebsd5.png[]

Speichern Sie die Eingaben und beenden Sie die Konfiguration:

image::virtualpc-freebsd6.png[]

Wählen Sie nun die für FreeBSD erstellte virtuelle Maschine aus und klicken Sie auf menu:Settings[], um das Netzwerk zu konfigurieren:

image::virtualpc-freebsd7.png[]

image::virtualpc-freebsd8.png[]

Nachdem die virtuelle Maschine erstellt wurde, können Sie FreeBSD installieren. Dazu verwenden Sie am besten eine offizielle FreeBSD-CD/DVD oder ein ISO-Image, das Sie von einem offiziellen FreeBSD-FTP-Server heruntergeladen haben. Wenn Sie ein ISO-Image auf der Festplatte gespeichert haben, oder eine FreeBSD-CD/DVD in das Laufwerk eingelegt haben, doppelklicken Sie auf die virtuelle Maschine, die Sie für FreeBSD angelegt haben. Danach klicken Sie auf menu:CD[] und wählen die Option menu:Capture ISO Image...[] im Virtual PC-Fenster. Danach können Sie im folgenden Fenster das CD-Laufwerk mit dem physikalischen CD-Laufwerk oder mit dem ISO-Image verknüpfen.

image::virtualpc-freebsd9.png[]

image::virtualpc-freebsd10.png[]

Danach starten Sie die virtuelle Maschine neu, indem Sie zuerst auf menu:Action[] und danach auf menu:Reset[] klicken. Virtual PC startet die virtuelle Maschine nun neu und prüft zuerst, ob die virtuelle Maschine über ein CD-Laufwerk verfügt.

image::virtualpc-freebsd11.png[]

Da dies hier der Fall ist, beginnt nun eine normale FreeBSD-Installation. Sie können FreeBSD nun installieren, aber verzichten Sie an dieser Stelle unbedingt auf die Xorg-Konfiguration.

image::virtualpc-freebsd12.png[]

Nachdem die Installation abgeschlossen ist, entfernen Sie die CD/DVD aus dem Laufwerk (oder lösen die Verknüpfung zum ISO-Image). Danach starten Sie die virtuelle Maschine neu, um FreeBSD zu starten.

image::virtualpc-freebsd13.png[]

[[virtualization-guest-virtualpc-configure]]
=== FreeBSD in Virtual PC konfigurieren

Nachdem FreeBSD auf Microsoft(R) Windows(R) mit Virtual PC erfolgreich installiert wurde, sollten Sie das virtuelle FreeBSD noch anpassen, um eine optimale Funktion zu gewährleisten.

[.procedure]
. Setzen der Bootloader-Variablen
+ 
Die wichtigste Änderung ist es, die Variable `kern.hz` zu verkleinern, um so die CPU-Auslastung in der Virtual PC-Umgebung zu verringern. Dazu fügen Sie die folgende Zeile in [.filename]#/boot/loader.conf# ein:
+
[.programlisting]
....
kern.hz=100
....
+ 
Ohne diese Einstellung kann ein unbeschäftigtes FreeBSD unter Virutal PC trotzdem rund 40 Prozent der CPU-Leistung eines Ein-Prozessor-Systems verbrauchen. Nach dieser Änderung reduziert sich dieser Wert auf etwa 3 Prozent.
. Erstellen einer neuen Kernelkonfigurationsdatei
+ 
Alle SCSI-, FireWire- und USB-Laufwerks-Treiber können aus der Kernelkonfigurationsdatei entfernt werden. Virtual PC stellt einen virtuellen Netzwerkadapter bereit, der den man:de[4]-Treiber verwendet. Daher können alle Netzwerkgeräte bis auf man:de[4] und man:miibus[4] aus dem Kernel entfernt werden.
. Das Netzwerk einrichten
+ 
Die einfachste Netzwerkkonfiguration nutzt von DHCP, um die virtuelle Maschine mit dem gleichen lokalen Netzwerk, in dem sich der Host-Microsoft(R) Windows(R) befindet, zu verbinden. Dazu fügen Sie die Zeile `ifconfig_de0="DHCP"` in [.filename]#/etc/rc.conf# ein. Weitere Informationen zur Konfiguration des Netzwerks unter FreeBSD finden Sie in crossref:advanced-networking[advanced-networking,Netzwerkverbindung konfigurieren].

[[virtualization-guest-vmware]]
== FreeBSD als Gast-Betriebssystem unter VMware Fusion für Mac OS(R)

VMware Fusion für Mac(R) ist ein kommerzielles Programm, das für Intel(R) basierte Apple(R) Mac(R)-Computer mit Mac OS(R) 10.4.9 oder neuer erhältlich ist. FreeBSD wird von diesem Produkt vollständig als Gast-Betriebssystem unterstützt. Nachdem Sie VMware Fusion unter Mac OS(R) X installiert haben, können Sie eine virtuelle Maschine konfigurieren und das gewünschte Gastbetriebssystem installieren.

[[virtualization-guest-vmware-install]]
=== FreeBSD in VMware Fusion installieren

Zuerst müssen Sie VMware Fusion starten, um eine virtuelle Maschine zu erstellen. Dazu wählen Sie die Option [.guimenuitem]#New#:

image::vmware-freebsd01.png[]

Dadurch wird ein Assistent gestartet, der bei der Erzeugung einer neuen virtuellen Maschine behilflich ist. Klicken Sie auf [.guimenuitem]#Continue#, um den Prozess zu starten:

image::vmware-freebsd02.png[]

Wählen Sie [.guimenuitem]#Other# als das [.guimenuitem]#Operating System#, danach [.guimenuitem]#FreeBSD# oder [.guimenuitem]#FreeBSD 64-bit#, je nach dem, welche Version Sie installieren wollen, wenn Sie nach der zu installierenden menu:Version[] gefragt werden:

image::vmware-freebsd03.png[]

Vergeben Sie einen Namen für die virtuelle Maschine und legen Sie den Speicherort fest:

image::vmware-freebsd04.png[]

Legen Sie die Größe der virtuellen Festplatte für die virtuelle Maschine fest:

image::vmware-freebsd05.png[]

Wählen Sie die Installationsmethode für die virtuelle Maschine. Entweder von einem ISO-Abbild oder von einer CD/DVD:

image::vmware-freebsd06.png[]

Nachdem Sie auf [.guimenuitem]#Finish# geklickt haben, wird die virtuelle Maschine gestartet:

image::vmware-freebsd07.png[]

Nun können Sie FreeBSD wie gewohnt installieren:

image::vmware-freebsd08.png[]

Nachdem die Installation abgeschlossen ist, können noch verschiedene Parameter der virtuellen Maschine, wie etwa der Speicherverbrauch, konfiguriert werden:

[NOTE]
====
Die Hardware der virtuellen Maschine kann nicht geändert werden, solange die virtuelle Maschine läuft.
====

image::vmware-freebsd09.png[]

Die Anzahl der CPUs der virtuellen Maschine:

image::vmware-freebsd10.png[]

Den Status des CD-Laufwerks. Sie können die CD/DVD/ISO von der virtuellen Maschine lösen, wenn Sie es nicht benötigen.

image::vmware-freebsd11.png[]

Zuletzt sollten Sie noch festlegen, wie sich die virtuelle Maschine mit dem Netzwerk verbinden soll. Sollen neben dem Gastsystem auch andere Rechner auf die virtuelle Maschine zugreifen können, muss die Option [.guimenuitem]#Connect directly to the physical network (Bridged)# gewählt werden. Ist dies nicht der Fall, sollte die Option [.guimenuitem]#Share the host's internet connection (NAT)# gewählt werden. In dieser Einstellung kann die virtuelle Maschine zwar auf das Internet zugreifen, andere Rechner dürfen aber nicht auf die virtuelle Maschine zugreifen.

image::vmware-freebsd12.png[]

Nachdem die Konfiguration abgeschlossen ist, kann FreeBSD gestartet werden.

[[virtualization-guest-vmware-configure]]
=== FreeBSD unter VMware Fusion konfigurieren

Nachdem Sie FreeBSD erfolgreich unter VMware Fusion installiert haben, sollten Sie das virtuelle FreeBSD noch anpassen, um eine optimale Funktion zu gewährleisten.

[.procedure]
. Die wichtigste Änderung ist es, die Variable `kern.hz` zu verkleinern, um so die CPU-Auslastung in der VMware Fusion-Umgebung zu verringern.
+
[.programlisting]
....
kern.hz=100
....

+ 
Ohne diese Einstellung kann ein unbeschäftigtes FreeBSD unter VMware Fusion trotzdem rund 15 Prozent der CPU-Leistung eines Single Prozessor iMac(R)'s verbrauchen. Nach dieser Änderung reduziert sich dieser Wert auf etwa 5 Prozent.
. Erstellen einer neuen Kernelkonfigurationsdatei
+ 
Alle FireWire- und USB-Laufwerks-Treiber können aus der Kernelkonfigurationsdatei entfernt werden. VMware Fusion stellt einen virtuellen Netzwerkadapter bereit, der den man:em[4]-Treiber verwendet. Daher können alle Netzwerkgeräte bis auf man:em[4] und man:miibus[4] aus dem Kernel entfernt werden.
. Netzwerkbetrieb einrichten
+ 
Die einfachste Netzwerkkonfiguration verwendet DHCP, um die virtuelle Maschine mit dem gleichen lokalen Netzwerk, in dem sich der Host-Mac(R) befindet, zu verbinden. Dazu fügen Sie die Zeile `ifconfig_em0="DHCP"` in [.filename]#/etc/rc.conf# ein. Weitere Informationen zur Konfiguration des Netzwerks unter FreeBSD finden Sie im crossref:advanced-networking[advanced-networking,Netzwerkverbindung konfigurieren].

[[virtualization-guest-virtualbox-guest-additions]]
== FreeBSD als Gast mit VirtualBox(TM)

FreeBSD funktioniert einwandfrei als Gast-Betriebssystem unter VirtualBox(TM). Die Virtualisierungs-Software steht für die meisten Betriebssysteme zur Verfügung, einschließlich FreeBSD.

Die VirtualBox(TM) Gasterweiterungen bieten Unterstützung für:

* Gemeinsame Zwischenablage.
* Mauszeiger-Integration.
* Zeitsynchronisation mit dem Host.
* Skalierung von Fenstern.
* Nahtloser Modus.

[NOTE]
====
Diese Kommandos werden im FreeBSD Gastsystem ausgeführt.
====

Installieren Sie das Paket oder den Port package:emulators/virtualbox-ose-additions[] in das FreeBSD Gastsystem. Dieses Beispiel installiert den Port:

[source,shell]
....
# cd /usr/ports/emulators/virtualbox-ose-additions
# make install clean
....

Fügen Sie folgende Einträge in [.filename]#/etc/rc.conf# hinzu:

[.programlisting]
....
vboxguest_enable="YES"
vboxservice_enable="YES"
....

Wenn man:ntpd[8] oder man:ntpdate[8] verwendet wird um die Uhrzeit zu synchronisieren, dann deaktivieren Sie die Synchronisierung mit dem Host:

[.programlisting]
....
vboxservice_flags="--disable-timesync"
....

Xorg wird den `vboxvideo`-Treiber automatisch erkennen. Alternativ kann auch manuell ein entsprechender Eintrag in [.filename]#/etc/X11/xorg.conf# hinzugefügt werden:

[.programlisting]
....
Section "Device"
	Identifier "Card0"
	Driver "vboxvideo"
	VendorName "InnoTek Systemberatung GmbH"
	BoardName "VirtualBox Graphics Adapter"
EndSection
....

Um den `vboxmouse_drv`-Treiber zu verwenden, muss [.filename]#/etc/X11/xorg.conf# ebenfalls angepasst werden:

[.programlisting]
....
Section "InputDevice"
	Identifier "Mouse0"
	Driver "vboxmouse"
EndSection
....

Benutzer von HAL sollten die Datei [.filename]#/usr/local/etc/hal/fdi/policy/90-vboxguest.fdi# erstellen oder sie aus [.filename]#/usr/local/shared/hal/fdi/policy/10osvendor/90-vboxguest.fdi# kopieren:

[.programlisting]
....
<?xml version="1.0" encoding="utf-8"?>
<!--
# Sun VirtualBox
# Hal driver description for the vboxmouse driver
# $Id: chapter.xml,v 1.33 2012-03-17 04:53:52 eadler Exp $

	Copyright (C) 2008-2009 Sun Microsystems, Inc.

	This file is part of VirtualBox Open Source Edition (OSE, as
	available from http://www.virtualbox.org. This file is free software;
	you can redistribute it and/or modify it under the terms of the GNU
	General Public License (GPL) as published by the Free Software
	Foundation, in version 2 as it comes in the "COPYING" file of the
	VirtualBox OSE distribution. VirtualBox OSE is distributed in the
	hope that it will be useful, but WITHOUT ANY WARRANTY of any kind.

	Please contact Sun Microsystems, Inc., 4150 Network Circle, Santa
	Clara, CA 95054 USA or visit http://www.sun.com if you need
	additional information or have any questions.
-->
<deviceinfo version="0.2">
  <device>
    <match key="info.subsystem" string="pci">
      <match key="info.product" string="VirtualBox guest Service">
	<append key="info.capabilities" type="strlist">input</append>
	<append key="info.capabilities" type="strlist">input.mouse</append>
	<merge key="input.x11_driver" type="string">vboxmouse</merge>
	<merge key="input.device" type="string">/dev/vboxguest</merge>
      </match>
    </match>
  </device>
</deviceinfo>
....

Gemeinsame Ordner für die Dateitransfer zwischen Host und VM sind verfügbar, wenn sie mit `mount_vboxvfs` eingebunden werden. Ein gemeinsamer Ordner kann auf dem Host über die graphische Oberfläche von VirtualBox oder mit `vboxmanage` erstellt werden. Um beispielsweise einen freigegebenen Ordner namens _myshare_ unter [.filename]#/mnt/bsdboxshare# für die VM _BSDBox_ zu erstellen, führen Sie folgendes Kommando aus:

[source,shell]
....
# vboxmanage sharedfolder add 'BSDBox' --name myshare --hostpath /mnt/bsdboxshare
....

Beachten Sie, dass der Name des gemeinsamen Ordners keine Leerzeichen enthalten darf. Sie können den freigegebenen Ordner innerhalb des Gastsystems wie folgt einbinden:

[source,shell]
....
# mount_vboxvfs -w myshare /mnt
....

[[virtualization-host-virtualbox]]
== FreeBSD als Host mit Virtualbox

VirtualBox(TM) ist ein vollständigesVirtualisierungspaket, das aktiv weiterentwickelt wird und für die meisten Betriebssysteme einschließlich Windows(R), Mac OS(R), Linux(R) und FreeBSD zur Verfügung steht. Es kann sowohl Windows(R) als auch UNIX(R)-ähnliche Gastsysteme betreiben. Es wird als Open Source Software veröffentlicht, jedoch mit Closed-Source-Komponenten in einem separaten Erweiterungspaket. Zu diesen Komponenten gehört Unterstützung für USB 2.0-Geräte. Weitere Informationen finden Sie auf der http://www.virtualbox.org/wiki/Downloads[ Downloads-Seite im VirtualBox(TM) Wiki]. Derzeit sind diese Erweiterungen für FreeBSD nicht verfügbar.

[[virtualization-virtualbox-install]]
=== VirtualBox(TM) installieren

VirtualBox(TM) steht als Paket oder Port in package:emulators/virtualbox-ose[] bereit. Der Port kann mit folgendem Kommando installiert werden:

[source,shell]
....
# cd /usr/ports/emulators/virtualbox-ose
# make install clean
....

Eine nützliche Option im Konfigurationsdialog ist die `GuestAdditions`-Programmsammlung. Diese stellen eine Reihe von nützlichen Eigenschaften in den Gastbetriebssystemen zur Verfügung, wie beispielsweise Mauszeigerintegration (was es ermöglicht, die Maus zwischen dem Host und dem Gast zu teilen ohne eine spezielle Tastenkombination für diesen Wechsel zu drücken), sowie schnelleres Rendern von Videos, besonders in Windows(R) Gästen. Diese Gastzusätze sind im menu:Devices[]-Menü zu finden, nachdem die Installation des Gastbetriebssystem abgeschlossen ist.

Ein paar Konfigurationsänderungen sind notwendig, bevor VirtualBox(TM) das erste Mal gestartet wird. Der Port installiert ein Kernelmodul in [.filename]#/boot/modules#, das in den laufenden Kernel geladen werden muss:

[source,shell]
....
# kldload vboxdrv
....

Um sicherzustellen, dass das Modul immer nach einem Neustart geladen wird, fügen Sie die folgende Zeile in [.filename]#/boot/loader.conf# ein:

[.programlisting]
....
vboxdrv_load="YES"
....

Um die Kernelmodule für die Unterstützung von Netzwerkbrücken oder Host-Only Netzwerken zu laden, fügen Sie folgendes in [.filename]#/etc/rc.conf# ein und starten Sie den Computer neu:

[.programlisting]
....
vboxnet_enable="YES"
....

Die Gruppe `vboxusers` wird während der Installation von VirtualBox(TM) angelegt. Alle Benutzer, die Zugriff auf VirtualBox(TM) haben sollen, müssen in diese Gruppe aufgenommen werden. `pw` kann benutzt werden, um neue Mitglieder hinzuzufügen:

[source,shell]
....
# pw groupmod vboxusers -m yourusername
....

Damit Netzwerkbrücken funktionieren, müssen die in der Voreinstellung eingeschränkten Berechtigungen für [.filename]#/dev/vboxnetctl# angepasst werden:

[source,shell]
....
# chown root:vboxusers /dev/vboxnetctl
# chmod 0600 /dev/vboxnetctl
....

Um diese Berechtigungen dauerhaft zu speichern, fügen Sie folgende Einträge in [.filename]#/etc/devfs.conf# hinzu:

[.programlisting]
....
own     vboxnetctl root:vboxusers
perm    vboxnetctl 0600
....

Um VirtualBox(TM) zu starten, geben Sie folgenden Befehl in der Xorg-Sitzung ein:

[source,shell]
....
% VirtualBox
....

Besuchen Sie die offizielle Webseite von VirtualBox(TM) unter http://www.virtualbox.org[ http://www.virtualbox.org], um weitere Informationen zur Konfiguration und Verwendung zu erhalten. FreeBSD-spezifische Informationen und Anleitungen zur Fehlerbehebung finden Sie auf der entsprechenden Seite im FreeBSD-Wiki unter http://wiki.FreeBSD.org/VirtualBox[ http://wiki.FreeBSD.org/VirtualBox].

[[virtualization-virtualbox-usb-support]]
=== USB Unterstützung für VirtualBox(TM)

Sie können VirtualBox(TM) so konfigurieren, dass USB-Geräte an das Gastsystem weitergeleitet werden. So lange das Erweiterungspaket für USB 2.0 und 3.0 auf FreeBSD nicht verfügbar ist, ist der Host-Controller der OSE-Version auf die Emulation von USB 1.1-Geräten beschränkt.

Damit VirtualBox(TM) angeschlossene USB-Geräte am Rechner erkennt, muss der Benutzer Mitglied der Gruppe `operator` sein.

[source,shell]
....
# pw groupmod operator -m ihrbenutzername
....

Anschließend fügen Sie folgenden Eintrag in [.filename]#/etc/devfs.rules# ein. Wenn die Datei nicht existiert, muss sie zuvor erstellt werden:

[.programlisting]
....
[system=10]
add path 'usb/*' mode 0660 group operator
....

Um diese neuen Regeln zu laden, fügen Sie Folgendes in [.filename]#/etc/rc.conf# hinzu:

[.programlisting]
....
devfs_system_ruleset="system"
....

Danach starten Sie devfs neu:

[source,shell]
....
# service devfs restart
....

Sie müssen die Anmeldesitzung und VirtualBox(TM) neu starten, damit die Änderungen wirksam werden. Danach können Sie nach Bedarf neue USB-Filter erstellen.

[[virtualbox-virtualization-host-dvd-cd-access]]
=== Host CD/DVD-Zugriff in VirtualBox(TM)

Ein Gastsystem kann auf die DVD/CD-Laufwerke des Hosts zugreifen. Der Zugriff für die virtuellen Maschinen wird in den Einstellungen von VirtualBox(TM) konfiguriert. Falls erforderlich, erstellen Sie zunächst ein leeres IDEDVD/CD-Gerät und wählen Sie dann ein entsprechendes Medium für dieses Laufwerk aus. Das Kontrollkästchen `Passthrough` besagt, dass die virtuelle Maschine die Hardware direkt verwenden kann. Audio-CDs und Brenner funktionieren nur, wenn diese Option ausgewählt ist.

Damit die CD/DVD-Funktionen von VirtualBox(TM) funktionieren, muss HAL in [.filename]#/etc/rc.conf# aktiviert und anschließend gestartet werden:

[.programlisting]
....
hald_enable="YES"
....

[source,shell]
....
# service hald start
....

Damit die CD/DVD-Funktionen von Benutzern verwendet werden können, benötigen diese Zugriff auf [.filename]#/dev/xpt0#, [.filename]#/dev/cdN# und [.filename]#/dev/passN#. Dies wird in der Regel dadurch erreicht, den Benutzer zum Mitglied der Gruppe `operator` zu machen. Die Berechtigungen für diese Geräte werden mit folgenden Zeilen in [.filename]#/etc/devfs.conf# konfiguriert:

[.programlisting]
....
perm cd* 0660
perm xpt0 0660
perm pass* 0660
....

[source,shell]
....
# service devfs restart
....

[[virtualization-host-bhyve]]
== FreeBSD als Host mit bhyve

Beginnend mit FreeBSD 10.0-RELEASE ist bhyve, ein BSD-lizensierter Hypervisor, Teil des Basissystems. Dieser Hypervisor unterstützt eine Reihe von Gastbetriebssystemen, darunter FreeBSD, OpenBSD und viele Linux(R) Distributionen. In der Voreinstellung unterstützt bhyve eine serielle Konsole, graphische Konsolen werden nicht emuliert. bhyve verwendet Offload-Funktionen von neueren CPUs, um manuelle Speicherzuordnungen und Anweisungen zu vermeiden.

Das Design von bhyve erfordert einen Prozessor, der Intel(R) Extended Page Tables (EPT), AMD(R) Rapid Vitualization Indexing (RVI) oder Nested Page Tables (NPT) unterstützt. FreeBSD- oder Linux(R)-Gastsysteme mit mehr als einer vCPU benötigen VMX unrestricted mode support (UG). Die meisten neueren Prozessoren, speziell Intel(R) Core(TM) i3/i5/i7 und Intel(R) Xeon(TM) E3/E5/E7, unterstützen diese Funktionen. Unterstützung für UG wurde mit Intel's Westmere Mikroarchitektur eingeführt. Eine vollständige Liste der Intel(R)-Prozessoren mit EPT-Unterstützung finden Sie unter https://ark.intel.com/content/www/us/en/ark/search/featurefilter.html?productType=873&0_ExtendedPageTables=True[]. RVI wird seit der dritten Generation der AMD Opteron(TM)-Prozessoren (Barcelona) unterstützt. Um zu sehen ob der Prozessor bhyve unterstützt, prüfen Sie die Ausgabe von `dmesg` oder [.filename]#/var/run/dmesg.boot#. Für AMD(R)-Prozessoren suchen Sie in der Zeile `Features2` nach `POPCNT`. Für Intel(R)-Prozessoren suchen Sie in der Zeile `VT-x` nach `EPT` und `UG`.

[[virtualization-bhyve-prep]]
=== Vorbereitung des Hosts

Der erste Schritt bei der Erstellung einer virtuellen Maschine in bhyve ist die Konfiguration des Host-Systems. Laden Sie zunächst das bhyve Kernelmodul:

[source,shell]
....
# kldload vmm
....

Erstellen Sie ein [.filename]#tap#-Gerät, um dieses mit der Netzwerk-Schnittstelle der virtuellen Maschine zu verbinden. Damit sich die Schnittstelle mit dem Netzwerk verbinden kann, müssen Sie zusätzlich eine Bridge-Schnittstelle erzeugen, bestehend aus dem [.filename]#tap#-Gerät und der physikalischen Schnittstelle. In diesem Beispiel wird die physikalische Schnittstelle [.filename]#igb0# verwendet:

[source,shell]
....
# ifconfig tap0 create
# sysctl net.link.tap.up_on_open=1
net.link.tap.up_on_open: 0 -> 1
# ifconfig bridge0 create
# ifconfig bridge0 addm igb0 addm tap0
# ifconfig bridge0 up
....

[[virtualization-bhyve-freebsd]]
=== Ein FreeBSD-Gastsystem erstellen

Erzeugen Sie eine Datei, die als virtuelle Festplatte für das Gastsystem verwendet wird. Geben Sie die Größe und den Namen der virtuellen Festplatte an:

[source,shell]
....
# truncate -s 16G guest.img
....

Laden Sie ein Installationsabbild von FreeBSD:

[source,shell]
....
# fetch ftp://ftp.freebsd.org/pub/FreeBSD/releases/ISO-IMAGES/10.3/FreeBSD-10.3-RELEASE-amd64-bootonly.iso
FreeBSD-10.3-RELEASE-amd64-bootonly.iso       100% of  230 MB  570 kBps 06m17s
....

FreeBSD enthält ein Beispielskript um eine virtuelle Maschine in bhyve auszuführen. Das Skript wird die virtuelle Maschine starten und sie in einer Schleife ausführen. Sollte die virtuelle Maschine abstürzen, wird sie vom Skript automatisch neu gestartet. Das Skript akzeptiert einige Optionen, um die Konfiguration der virtuellen Maschine zu kontrollieren: `-c` bestimmt die Anzahl der virtuellen CPUs, `-m` begrenzt den verfügbaren Speicher des Gastsystems, `-t` bestimmt das verwendete [.filename]#tap#-Gerät, `-d` gibt das zu benutzende Festplattenabbild an, `-i` sagt bhyve dass es von CD booten soll und `-I` bestimmt das CD-Abbild. Der letzte Parameter ist der Name der virtuellen Maschine. Dieses Beispiel startet die virtuelle Maschine im Installationsmodus:

[source,shell]
....
# sh /usr/shared/examples/bhyve/vmrun.sh -c 1 -m 1024M -t tap0 -d guest.img -i -I FreeBSD-10.3-RELEASE-amd64-bootonly.iso guestname
....

Die virtuelle Maschine wird starten und das Installationsprogramm ausführen. Nachdem das System in der virtuellen Maschine installiert ist, werden Sie gefragt, ob eine Shell gestartet werden soll. Wählen Sie btn:[Yes].

Starten Sie die virtuelle Maschine neu. Ein Neustart der virtuellen Maschine wird bhyve beenden, aber da das [.filename]#vmrun.sh#-Skript in einer Schleife läuft, wird bhyve automatisch neu gestartet. Wenn dies passiert, wählen Sie die Option `Reboot` im Bootloader-Menü, um die Schleife zu unterbrechen. Anschließend kann das Gastsystem von der virtuellen Festplatte gestartet werden:

[source,shell]
....
# sh /usr/shared/examples/bhyve/vmrun.sh -c 4 -m 1024M -t tap0 -d guest.img guestname
....

[[virtualization-bhyve-linux]]
=== Ein Linux(R)-Gastsystem erstellen

Um andere Betriebssysteme als FreeBSD zu booten, muss zunächst der Port package:sysutils/grub2-bhyve[] installiert werden.

Als nächstes erzeugen Sie eine Datei, die das Gastsystem als virtuelle Festplatte verwenden kann:

[source,shell]
....
# truncate -s 16G linux.img
....

Der Start einer virtuellen Maschine mit bhyve ist ein zweistufiger Prozess. Zuerst muss ein Kernel geladen werden, dann kann das Gastsystem gestartet werden. Der Linux(R)-Kernel wird mit package:sysutils/grub2-bhyve[] geladen. Erstellen Sie eine [.filename]#device.map#, damit grub die virtuellen Geräte den Dateien auf dem Hostsystem zuordnen kann:

[.programlisting]
....
(hd0) ./linux.img
(cd0) ./somelinux.iso
....

Benutzen Sie package:sysutils/grub2-bhyve[] um den Linux(R)-Kernel vom ISO-Abbild zu laden:

[source,shell]
....
# grub-bhyve -m device.map -r cd0 -M 1024M linuxguest
....

Damit wird grub gestartet. Wenn die Installations-CD eine Datei namens [.filename]#grub.cfg# enthält, wird ein Menü angezeigt. Wenn nicht, müssen die Dateien [.filename]#vmlinuz# und [.filename]#initrd# manuell geladen werden:

[source,shell]
....
grub> ls
(hd0) (cd0) (cd0,msdos1) (host)
grub> ls (cd0)/isolinux
boot.cat boot.msg grub.conf initrd.img isolinux.bin isolinux.cfg memtest
splash.jpg TRANS.TBL vesamenu.c32 vmlinuz
grub> linux (cd0)/isolinux/vmlinuz
grub> initrd (cd0)/isolinux/initrd.img
grub> boot
....

Nun, da der Linux(R)-Kernel geladen ist, kann das Gastsystem gestartet werden:

[source,shell]
....
# bhyve -A -H -P -s 0:0,hostbridge -s 1:0,lpc -s 2:0,virtio-net,tap0 -s 3:0,virtio-blk,./linux.img \
    -s 4:0,ahci-cd,./somelinux.iso -l com1,stdio -c 4 -m 1024M linuxguest
....

Das System wird booten und das Installtionsprogramm starten. Starten Sie die virtuelle Maschine nach der Installation des Betriebssystems neu. Dies führt auch dazu, dass bhyve beendet wird. Die Instanz der virtuellen Maschine muss zerstört werden, bevor sie erneut in Betrieb genommen werden kann:

[source,shell]
....
# bhyvectl --destroy --vm=linuxguest
....

Nun kann das Gastsystem direkt von der virtuellen Festplatte gestartet werden. Laden Sie den Kernel:

[source,shell]
....
# grub-bhyve -m device.map -r hd0,msdos1 -M 1024M linuxguest
grub> ls
(hd0) (hd0,msdos2) (hd0,msdos1) (cd0) (cd0,msdos1) (host)
(lvm/VolGroup-lv_swap) (lvm/VolGroup-lv_root)
grub> ls (hd0,msdos1)/
lost+found/ grub/ efi/ System.map-2.6.32-431.el6.x86_64 config-2.6.32-431.el6.x
86_64 symvers-2.6.32-431.el6.x86_64.gz vmlinuz-2.6.32-431.el6.x86_64
initramfs-2.6.32-431.el6.x86_64.img
grub> linux (hd0,msdos1)/vmlinuz-2.6.32-431.el6.x86_64 root=/dev/mapper/VolGroup-lv_root
grub> initrd (hd0,msdos1)/initramfs-2.6.32-431.el6.x86_64.img
grub> boot
....

Starten Sie die virtuelle Maschine:

[source,shell]
....
# bhyve -A -H -P -s 0:0,hostbridge -s 1:0,lpc -s 2:0,virtio-net,tap0 \$    -s 3:0,virtio-blk,./linux.img -l com1,stdio -c 4 -m 1024M linuxguest
....

Linux(R) wird jetzt in der virtuellen Maschine gestartet und präsentiert Ihnen vielleicht einen Anmeldeprompt. Sie können sich anmelden und die virtuelle Maschine benutzen. Wenn Sie fertig sind, starten Sie die virtuelle Maschine neu, um bhyve zu verlassen. Anschließend zerstören Sie die Instanz der virtuellen Maschine:

[source,shell]
....
# bhyvectl --destroy --vm=linuxguest
....

[[virtualization-bhyve-uefi]]
=== bhyve virtuelle Maschinen mit UEFI Firmware booten

Neben bhyveload und grub-bhyve kann der bhyve Hypervisor virtuelle Maschinen auch über die UEFI-Userspace-Firmware booten. Mit dieser Option werden Gastsysteme unterstützt, die von anderen Bootloadern nicht unterstützt werden.

Um die UEFI-Unterstützung in bhyve nutzen zu können, benötigen Sie zuerst die Abbilder der UEFI-Firmware. Dazu können Sie den Port oder das Paket package:sysutils/bhyve-firmware[] installieren.

Mit der Firmware an Ort und Stelle, fügen Sie die Option `-l bootrom,_/pfad/zur/firmware_` zur bhyve-Befehlszeile hinzu. Der eigentliche bhyve-Befehl könnte wie folgt lauten:

[source,shell]
....
# bhyve -AHP -s 0:0,hostbridge -s 1:0,lpc \
-s 2:0,virtio-net,tap1 -s 3:0,virtio-blk,./disk.img \
-s 4:0,ahci-cd,./install.iso -c 4 -m 1024M \
-l bootrom,/usr/local/shared/uefi-firmware/BHYVE_UEFI.fd \
guest
....

package:sysutils/bhyve-firmware[] enthält auch eine CSM-fähige Firmware, um Gastsysteme ohne UEFI-Unterstützung im alten BIOS-Modus zu booten:

[source,shell]
....
# bhyve -AHP -s 0:0,hostbridge -s 1:0,lpc \
-s 2:0,virtio-net,tap1 -s 3:0,virtio-blk,./disk.img \
-s 4:0,ahci-cd,./install.iso -c 4 -m 1024M \
-l bootrom,/usr/local/shared/uefi-firmware/BHYVE_UEFI_CSM.fd \
guest
....

[[virtualization-bhyve-framebuffer]]
=== Graphische Framebuffer für bhyve-Gastsysteme

Die Unterstützung von UEFI-Firmware ist bei graphischen Betriebssystemen, wie Microsoft Windows(R), besonders nützlich.

Unterstützung für den UEFI-GOP Framebuffer kann auch über die Option `-s 29,fbuf,tcp=_0.0.0.0:5900_` aktiviert werden. Die Framebuffer-Auflösung kann mit `w=_800_` und `h=_600_` konfiguriert werden. Mit der Option `wait` können Sie bhyve anweisen, auf eine VNC-Verbindung zu warten, bevor das Gastsystem gebootet wird. Vom Host oder aus dem Netzwerk kann über das VNC-Protokoll auf den Framebuffer zugegriffen werden. Zusätzlich kann `-s 30,xhci,tablet` hinzugefügt werden, um eine präzise Mauszeigersynchronisation mit dem Host zu gewährleisten.

Der daraus resultierende Befehl würde so aussehen:

[source,shell]
....
# bhyve -AHP -s 0:0,hostbridge -s 31:0,lpc \
-s 2:0,virtio-net,tap1 -s 3:0,virtio-blk,./disk.img \
-s 4:0,ahci-cd,./install.iso -c 4 -m 1024M \
-s 29,fbuf,tcp=0.0.0.0:5900,w=800,h=600,wait \
-l bootrom,/usr/local/shared/uefi-firmware/BHYVE_UEFI.fd \
-s 30,xhci,tablet \
guest
....

Beachten Sie, dass der Framebuffer im BIOS-Modus keine Befehle mehr empfängt, sobald die Steuerung von der Firmware an das Gastsystem übergeben wird.

[[virtualization-bhyve-zfs]]
=== Verwendung von ZFS mit bhyve-Gastsystemen

Wenn auf dem Host-Rechner ZFS eingerichtet ist, können Sie ZFS-Volumes anstelle eines Festplattenabbilds verwenden. Dies kann erhebliche Leistungsvorteile für das Gastsystem mit sich bringen. Ein ZFS-Volume kann wie folgt erstellt werden:

[source,shell]
....
# zfs create -V16G -o volmode=dev zroot/linuxdisk0
....

Geben Sie das ZFS-Volume beim Start der virtuellen Maschine an:

[source,shell]
....
# bhyve -A -H -P -s 0:0,hostbridge -s 1:0,lpc -s 2:0,virtio-net,tap0 -s3:0,virtio-blk,/dev/zvol/zroot/linuxdisk0 \
    -l com1,stdio -c 4 -m 1024M linuxguest
....

[[virtualization-bhyve-nmdm]]
=== Konsolen in der virtuellen Maschine

Es ist vorteilhaft, die bhyve-Konsole mit einem Werkzeug wie package:sysutils/tmux[] oder package:sysutils/screen[] zu bedienen. Damit ist es leicht, die Konsole zu verbinden oder zu trennen. Es ist auch möglich, die Konsole als Nullmodem-Gerät zu nutzen, auf das Sie mit `cu` zugreifen können. Laden Sie dazu das [.filename]#nmdm# Kernelmodul und ersetzen Sie `-l com1,stdio` mit `-l com1,/dev/nmdm0A`. Die [.filename]#/dev/nmdm#-Geräte werden bei Bedarf automatisch erstellt, jeweils paarweise, entsprechend den beiden Enden eines Nullmodemkabels ([.filename]#/dev/nmdm0A# und [.filename]#/dev/nmdm0B#). Weitere Informationen finden Sie in man:nmdm[4].

[source,shell]
....
# kldload nmdm
# bhyve -A -H -P -s 0:0,hostbridge -s 1:0,lpc -s 2:0,virtio-net,tap0 -s 3:0,virtio-blk,./linux.img \
    -l com1,/dev/nmdm0A -c 4 -m 1024M linuxguest
# cu -l /dev/nmdm0B
Connected

Ubuntu 13.10 handbook ttyS0

handbook login:
....

[[virtualization-bhyve-managing]]
=== Virtuelle Maschinen verwalten

Für jede virtuelle Maschine wird unterhalb von [.filename]#/dev/vmm# ein Gerätename erzeugt. Dadurch kann der Administrator einfach feststellen, welche virtuellen Maschinen zur Zeit ausgeführt werden:

[source,shell]
....
# ls -al /dev/vmm
total 1
dr-xr-xr-x   2 root  wheel    512 Mar 17 12:19 ./
dr-xr-xr-x  14 root  wheel    512 Mar 17 06:38 ../
crw-------   1 root  wheel  0x1a2 Mar 17 12:20 guestname
crw-------   1 root  wheel  0x19f Mar 17 12:19 linuxguest
crw-------   1 root  wheel  0x1a1 Mar 17 12:19 otherguest
....

Mit Hilfe von `bhyvectl` kann eine virtuelle Maschine zerstört werden:

[source,shell]
....
# bhyvectl --destroy --vm=guestname
....

[[virtualization-bhyve-onboot]]
=== Persistente Konfiguration

Um das System so zu konfigurieren, dass bhyve-Gastsysteme beim Booten gestartet werden, müssen die folgenden Konfigurationen in den jeweiligen Dateien vorgenommen werden:

[.procedure]
. [.filename]#/etc/sysctl.conf#
+
[.programlisting]
....
net.link.tap.up_on_open=1
....

. [.filename]#/etc/rc.conf#
+
[.programlisting]
....
cloned_interfaces="bridge0 tap0"
ifconfig_bridge0="addm igb0 addm tap0"
kld_list="vmm nmdm"
....

[[virtualization-host-xen]]
== FreeBSD als Xen(TM)-Host

Xen ist ein GPLv2-lizensierter https://de.wikipedia.org/wiki/Hypervisor#Klassifizierung[ Typ-1-Hypervisor] für Intel(R) und ARM(R) Architekturen. Seit FreeBSD 8.0 gibt es Unterstützung für i386(TM) und AMD(R) 64-Bit https://wiki.xenproject.org/wiki/DomU[DomU] sowie https://en.wikipedia.org/wiki/Amazon_Elastic_Compute_Cloud[Amazon EC2] unpriviligierte Domänen (virtuelle Maschinen). Dom0 priviligierte Domänen (Host) wird seit FreeBSD 11.0 unterstützt. Aus Performancegründen wurde in FreeBSD 11 die Unterstützung für paravirtualisierte Domänen (PV) zugunsten von Hardware virtualisierten Domänen (HVM) entfernt.

Xen(TM) ist ein Bare-Metal-Hypervisor, was bedeutet, dass es das erste Programm ist, welches nach dem BIOS geladen wird. Anschließend wird ein spezieller priviligierter Gast namens Domain-0 (kurz `Dom0`) gestartet. Dom0 nutzt seine speziellen Privilegien, um direkt auf die zugrunde liegende Hardware zuzugreifen, was es zu einer sehr leistungsstarken Lösung macht. Es ist in der Lage, direkt auf Festplattencontroller und Netzwerkadapter zuzugreifen. Die Xen(TM) Werkzeuge zum Verwalten und Steuern des Xen(TM) Hypervisors werden auch von Dom0 zum Erstellen, Auflisten und Zerstören von VMs verwendet. Dom0 stellt virtuelle Festplatten und Netzwerkfunktionalität für unpriviligierte Domänen bereit, die oft als DomU bezeichnet werden. Dom0 kann mit der Servicekonsole anderer Hypervisor verglichen werden, wohingegen DomU die einzelnen Gast-VMs ausführt.

Xen(TM) kann VMs zwischen verschiedenen Xen(TM) Servern migrieren. Wenn beide Xen-Hosts denselben zugrundeliegenden Speicher teilen, kann die Migration durchgeführt werden, ohne dass die VM zuerst heruntergefahren werden muss. Stattdessen wird die Migration live durchgeführt, während die DomU läuft. Sie brauchen daher keinen Neustart oder Ausfallzeit einplanen. Dies ist bei Wartungsarbeiten und Upgrade-Fenstern sinnvoll, um sicherzustellen, dass die von der DomU bereitgestellten Dienste weiterhin zur Verfügung stehen. Viele weitere Funktionen von Xen(TM) finden Sie im https://wiki.xenproject.org/wiki/Category:Overview[ Xen Wiki]. Sie sollten jedoch beachten, dass derzeit noch nicht alle Funktionen von FreeBSD unterstützt werden.

[[virtualization-host-xen-requirements]]
=== Hardwareanforderungen für Xen(TM) Dom0

Um den Xen(TM) Hypervisor auf einem Host auszuführen, ist eine bestimmte Hardwarefunktionalität erforderlich. Hardware-virtualisierte Domänen benötigen Unterstützung für Extended Page Table (https://de.wikipedia.org/wiki/Extended_Page_Table[ EPT]) und Input/Output Memory Management Unit (https://de.wikipedia.org/wiki/IOMMU[IOMMU]) im Host-Prozessor.

[NOTE]
====
Um ein FreeBSD Xen(TM) Dom0 betreiben zu können, muss die Maschine mit Legacy Boot (BIOS) gestartet werden.
====

[[virtualization-host-xen-dom0-setup]]
=== Xen(TM) Dom0 Control Domain Konfiguration

Benutzer von FreeBSD 11 sollten die Pakete package:emulators/xen-kernel47[] und package:sysutils/xen-tools47[] installieren. Diese Pakete basieren auf Xen Version 4.7. Mit FreeBSD-12.0 und neueren Versionen können die Pakete package:emulators/xen-kernel411[] und package:sysutils/xen-tools411[] für Xen 4.11 verwendet werden.

Nach der Installation der Xen Pakete müssen die Konfigurationsdateien angepasst werden, um den Host für die Integration von Dom0 vorzubereiten. Ein Eintrag in [.filename]#/etc/sysctl.conf# deaktiviert die Begrenzung für Speicherseiten. Andernfalls lassen sich DomU VMs mit höheren Speicheranforderungen nicht ausführen.

[source,shell]
....
# echo 'vm.max_wired=-1' >> /etc/sysctl.conf
....

Für eine andere speicherbezogene Einstellung muss in [.filename]#/etc/login.conf# die Option `memorylocked` auf `unlimited` gesetzt werden. Ansonsten kann das Erstellen von DomU-Domänen mit der Meldung `Cannot allocate memory` fehlschlagen. Nachdem Sie die Änderung in [.filename]#/etc/login.conf# gemacht haben, müssen Sie `cap_mkdb` ausführen um die Datenbank zu aktualisieren. crossref:security[security-resourcelimits,"Einschränkung von Ressourcen"] enthält hierzu ausführliche Informationen.

[source,shell]
....
# sed -i '' -e 's/memorylocked=64K/memorylocked=unlimited/' /etc/login.conf
# cap_mkdb /etc/login.conf
....

Fügen Sie einen Eintrag für die Xen(TM) Konsole in [.filename]#/etc/ttys# ein:

[source,shell]
....
# echo 'xc0     "usr/libexec/getty Pc"        xterm   onifconsole  secure' >> /etc/ttys
....

Dom0 wird durch die Auswahl eines Xen(TM)-Kernels in [.filename]#/boot/loader.conf# aktiviert. Xen(TM) benötigt von dem Hostsystem auch Ressourcen wie CPU und Speicher, sowohl für sich selbst als auch für andere DomU Domains. Wie viele Ressourcen benötigt werden, hängt von den individuellen Anforderungen und der eingesetzten Hardware ab. In diesem Beispiel werden der Dom0 8 GB Speicher und 4 virtuelle CPUs zur Verfügung gestellt. Die serielle Konsole und Protokollierung wird ebenfalls aktiviert.

Benutzen Sie die folgenden Kommandos, wenn Sie die Xen 4.7 Pakete verwenden:

[source,shell]
....
# sysrc -f /boot/loader.conf hw.pci.mcfg=0
# sysrc -f /boot/loader.conf if_tap_load="YES"
# sysrc -f /boot/loader.conf xen_kernel="/boot/xen"
# sysrc -f /boot/loader.conf xen_cmdline="dom0_mem=8192M dom0_max_vcpus=4 dom0pvh=1 console=com1,vga com1=115200,8n1 guest_loglvl=all loglvl=all"
....

Für Xen Version 4.11 oder höher, benutzen Sie stattdessen diese Kommandos:

[source,shell]
....
# sysrc -f /boot/loader.conf if_tap_load="YES"
# sysrc -f /boot/loader.conf xen_kernel="/boot/xen"
# sysrc -f /boot/loader.conf xen_cmdline="dom0_mem=8192M dom0_max_vcpus=4 dom0=pvh console=com1,vga com1=115200,8n1 guest_loglvl=all loglvl=all"
....

[TIP]
====

Protokolldateien, die Xen(TM) für die Dom0- und DomU-VMs erstellt, werden in [.filename]#/var/log/xen# gespeichert. Sie sollten dieses Verzeichnis überprüfen, falls es zu Problemen kommt.
====

Aktivieren Sie den xencommons Dienst während des Systemstarts:

[source,shell]
....
# sysrc xencommons_enable=yes
....

Diese Einstellungen reichen zwar aus, um ein Dom0-fähiges System zu starten, allerdings fehlt es dann an Netzwerkfunktionalität für die DomU-Rechner. Um dies zu beheben, können Sie eine Netzwerkbrücke über die Netzwerkschnittstelle des Hosts herstellen, die die DomU-VMs für die Verbindung zum Netzwerk benutzen können. Ersetzen Sie _em0_ durch den Namen der Netzwerkschnittstelle des Hosts.

[source,shell]
....
# sysrc cloned_interfaces="bridge0"
# sysrc ifconfig_bridge0="addm em0 SYNCDHCP"
# sysrc ifconfig_em0="up"
....

Starten Sie den Host neu, um den Xen(TM)-Kernel zu laden und den Dom0 zu starten.

[source,shell]
....
# reboot
....

Nach dem erfolgreichen Booten des Xen(TM)-Kernels und der Anmeldung am System wird das Xen(TM)-Werkzeug `xl` verwendet, um Informationen über die Domänen anzuzeigen.

[source,shell]
....
# xl list
Name                                        ID   Mem VCPUs      State   Time(s)
Domain-0                                     0  8192     4     r-----     962.0
....

Die Ausgabe bestätigt, dass der Dom0 (auch Domain-0 genannt) die ID `0` hat und ausgeführt wird. Der vorher in [.filename]#/boot/loader.conf# definierte Speicher und die virtuellen CPUs sind ebenfalls vorhanden. Weitere Informationen finden Sie in der https://www.xenproject.org/help/documentation.html[ Xen(TM) Dokumentation]. Jetzt können DomU Gast-VMs erstellt werden.

[[virtualization-host-xen-domu-setup]]
=== Xen(TM) DomU Gast-VM Konfiguration

Unpriviligierte Domänen bestehen aus einer Konfigurationsdatei und virtuellen oder physikalischen Festplatten. Der virtuelle Plattenspeicher für die DomU kann aus Dateien bestehen, die mit man:truncate[1] erstellt wurden, oder ZFS Volumes wie in crossref:zfs[zfs-zfs-volume,“Volumes erstellen und zerstören”] beschrieben. In diesem Beispiel wird ein 20 GB Volume verwendet. Eine VM wird mit dem ZFS Volume erstellt, ein FreeBSD ISO-Abbild, 1 GB RAM und zwei virtuelle CPUs. Das ISO-Abbild mit den Installationsdateien wird mit man:fetch[1] heruntergeladen und lokal in der Datei [.filename]#freebsd.iso# gespeichert.

[source,shell]
....
# fetch ftp://ftp.freebsd.org/pub/FreeBSD/releases/ISO-IMAGES/12.0/FreeBSD-12.0-RELEASE-amd64-bootonly.iso -o freebsd.iso
....

Ein ZFS Volume von 20 GB namens [.filename]#xendisk0# wird erstellt und dient der VM als Festplatte.

[source,shell]
....
# zfs create -V20G -o volmode=dev zroot/xendisk0
....

Die neue DomU Gast-VM wird in einer Datei definiert. Einige spezifische Einstellungen wie Name, Tastaturbelegung und VNC-Verbindungsdetails werden ebenfalls konfiguriert. Für dieses Beispiel enthält die folgende [.filename]#freebsd.cfg# eine minimale DomU-Konfiguration:

[source,shell]
....
# cat freebsd.cfg
builder = "hvm" <.>
name = "freebsd" <.>
memory = 1024 <.>
vcpus = 2 <.>
vif = [ 'mac=00:16:3E:74:34:32,bridge=bridge0' ] <.>
disk = [
'/dev/zvol/tank/xendisk0,raw,hda,rw', <.>
'/root/freebsd.iso,raw,hdc:cdrom,r' <.>
]
vnc = 1 <.>
vnclisten = "0.0.0.0"
serial = "pty"
usbdevice = "tablet"
....

Erklärung der einzelnen Zeilen:

<.> Dies definiert, welche Art von Virtualisierung verwendet wird. `hvm` bezieht sich auf hardwaregestützte Virtualisierung oder Hardware Virtual Machine. Gastbetriebssysteme können unverändert auf der CPU mit Virtualisierungserweiterungen laufen und bieten nahezu die gleiche Leistung wie auf physikalischer Hardware. `generic` ist der voreingestellte Wert und erstellt eine PV-Domain.

<.> Der Name dieser virtuellen Maschine. Er dient zur Unterscheidung von anderen virtuellen Maschinen auf der selben Dom0. Diese Angabe ist zwingend erforderlich.

<.> Die Größe an RAM in Megabytes, die der VM zur Verfügung steht. Die Größe wird vom verfügbaren Speicher des Hypervisors subtrahiert, nicht vom Speicher der Dom0.

<.> Die Anzahl der virtuellen CPUs, die dem Gast zur Verfügung stehen. Für die beste Leistung sollten Sie dem Gast nicht mehr CPUs zuteilen, als die Anzahl der CPUs auf dem physikalischen Host.

<.> Der virtuelle Netzwerkadapter. Dies ist die Brücke, die mit der Netzwerkschnittstelle des Hosts verbunden ist. Der Parameter `mac` definiert die MAC-Adresse der virtuellen Schnittstelle. Dieser Parameter ist optional. Falls keine MAC definiert ist, wird Xen(TM) eine zufällige MAC generieren.

<.> Der vollständige Pfad zur Festplatte, Datei, oder ZFS Volume für den Plattenspeicher dieser VM. Optionen und Festplattendefinitionen werden durch Kommata getrennt.

<.> Das Boot-Medium, aus dem das initiale Betriebssystem installiert wird. In diesem Beispiel wird das zuvor heruntergeladene ISO-Abbild benutzt. Andere Geräte und weitere Optionen sind in der Xen(TM) Dokumentation beschrieben.

<.> Optionen, die die VNC-Konnektivität der seriellen Konsole der DomU steuern. Dabei handelt es sich um die aktive VNC-Unterstützung, die verwendete IP-Adresse, der Gerätename der seriellen Konsole und die Eingabemethoden für Maus, Tastatur und andere Geräte. `keymap` konfiguriert die Tastaturbelegung, die in der Voreinstellung `english` ist.

Nachdem die Konfigurationsdatei mit allen notwendigen Optionen erstellt wurde, wird die DomU erstellt, indem die Datei als Parameter an `xl` übergeben wird.

[source,shell]
....
# xl create freebsd.cfg
....

[NOTE]
====
Jedes mal, wenn die Dom0 neu gestartet wird, muss die Konfigurationsdatei nochmals an `xl` übergeben werden, um die DomU neu zu erstellen. In der Voreinstellung wird nur die Dom0 nach einem Neustart angelegt, nicht die einzelnen VMs. Die VMs können dort fortfahren, wo sie aufgehört haben, weil sie das Betriebssystem auf der virtuellen Festplatte gespeichert haben. Die Konfiguration der virtuellen Maschine kann sich mit der Zeit ändern (bspw. beim Hinzufügen von mehr Arbeitsspeicher). Die Konfigurationsdateien der virtuellen Maschinen müssen ordnungsgemäß gesichert und vorgehalten werden, um die Gast-VM bei Bedarf neu erstellen zu können.
====

Die Ausgabe von `xl list` bestätigt, dass die DomU erstellt wurde.

[source,shell]
....
# xl list
Name                                        ID   Mem VCPUs      State   Time(s)
Domain-0                                     0  8192     4     r-----  1653.4
freebsd                                      1  1024     1     -b----   663.9
....

Um die Installation des Basis-Betriebssystems zu beginnen, starten Sie den VNC-Client und verbinden Sie sich mit Netzwerkadresse des Hosts oder mit der IP-Adresse, die auf der Zeile `vnclisten` in [.filename]#freebsd.cfg# konfiguriert wurde. Nachdem das Betriebssystem installiert ist, fahren Sie die DomU herunter und trennen den VNC-Viewer. Bearbeiten Sie dann die [.filename]#freebsd.cfg#, entfernen Sie die Zeile mit der `cdrom` Definiton, oder kommentieren Sie die Zeile mit `#` aus. Um diese neue Konfiguration zu laden, ist es notwendig, die alte DomU mit `xl` zu zerstören, indem Sie entweder den Namen oder die ID als Parameter übergeben. Danach kann die DomU mit der angepassten [.filename]##freebsd.cfg## neu erstellt werden.

[source,shell]
....
# xl destroy freebsd
# xl create freebsd.cfg
....

Auf die Maschine kann jetzt wieder mit dem VNC-Viewer zugegriffen werden. Dieses mal wird sie von einer virtuellen Festplatte booten, auf der das Betriebssystem installiert wurde. Die virtuelle Maschine kann nun verwendet werden.

[[virtualization-host-xen-troubleshooting]]
=== Fehlerbehebung

Dieser Abschnitt enthält grundlegende Informationen, um Probleme zu beheben, die bei der Verwendung von FreeBSD als Host oder Gast von Xen(TM) auftreten können.

[[virtualization-host-xen-troubleshooting-host]]
==== Fehlerbehebung beim Booten des Hosts

Bitte beachten Sie, dass die folgenden Tipps zur Fehlerbehebung für Xen(TM) 4.11 oder neuer gedacht sind. Wenn Sie noch Xen(TM) 4.7 benutzen und Probleme haben, sollten Sie die Migration auf eine neuere Version in Betracht ziehen.

Um Probleme beim Booten des Hosts zu beheben, benötigen Sie wahrscheinlich ein serielles Kabel oder ein USB-Kabel. Ausführliche Informationen während des Bootens erhalten Sie, wenn Sie die Option `xen_cmdline` in [.filename]#loader.conf# hinzufügen. Einige relevante Optionen sind:

* `iommu=debug`: kann benutzt werden, um zusätzliche Informationen über das iommu auszugeben.
* `dom0=verbose`: kann benutzt werden, um zusätzliche Informationen über den dom0 Build Prozess auszugeben.
* `sync_console`: diese Option erzwingt eine synchrone Konsolenausgabe. Dies ist sehr nützlich für die Fehlersuche, um den Verlust von Nachrichten durch die Begrenzung zu vermeiden. Verwenden Sie diese Option niemals in produktiven Umgebungen, da sie es böswilligen Gästen ermöglichen kann, DoS-Angriffe gegen Xen(TM) über die Konsole durchzuführen.

Um Probleme zu identifizieren, sollte FreeBSD beim Booten ebenfalls detaillierte Informationen anzeigen. Dies können Sie wie folgt aktivieren:

[source,shell]
....
# sysrc -f /boot/loader.conf boot_verbose="YES"
....

Wenn keine dieser Optionen zur Lösung des Problems beiträgt, senden Sie bitte das serielle Bootprotokoll zur weiteren Analyse an mailto:freebsd-xen@FreeBSD.org[freebsd-xen@FreeBSD.org] und mailto:xen-devel@lists.xenproject.org[xen-devel@lists.xenproject.org].

[[virtualization-host-xen-troubleshooting-guest]]
==== Fehlerbehebung beim Erstellen von Gastsystemen

Die folgenden Informationen können helfen, Probleme beim Erstellen von Gastsystemen zu diagnostizieren.

Die häufigste Ursache für Fehler beim Erstellen von Gastsystemen ist der `xl` Befehl, der einen Fehler generiert und mit einem Rückgabewert ungleich 0 endet. Wenn der angezeigte Fehler nicht ausreicht, um das Problem zu identifizieren, kann auch eine umfangreichere Ausgabe von `xl` erhalten werden, indem die Option `v` wiederholt verwendet wird.

[source,shell]
....
# xl -vvv create freebsd.cfg
Parsing config from freebsd.cfg
libxl: debug: libxl_create.c:1693:do_domain_create: Domain 0:ao 0x800d750a0: create: how=0x0 callback=0x0 poller=0x800d6f0f0
libxl: debug: libxl_device.c:397:libxl__device_disk_set_backend: Disk vdev=xvda spec.backend=unknown
libxl: debug: libxl_device.c:432:libxl__device_disk_set_backend: Disk vdev=xvda, using backend phy
libxl: debug: libxl_create.c:1018:initiate_domain_create: Domain 1:running bootloader
libxl: debug: libxl_bootloader.c:328:libxl__bootloader_run: Domain 1:not a PV/PVH domain, skipping bootloader
libxl: debug: libxl_event.c:689:libxl__ev_xswatch_deregister: watch w=0x800d96b98: deregister unregistered
domainbuilder: detail: xc_dom_allocate: cmdline="", features=""
domainbuilder: detail: xc_dom_kernel_file: filename="/usr/local/lib/xen/boot/hvmloader"
domainbuilder: detail: xc_dom_malloc_filemap    : 326 kB
libxl: debug: libxl_dom.c:988:libxl__load_hvm_firmware_module: Loading BIOS: /usr/local/shared/seabios/bios.bin
...
....

Wenn die ausführliche Ausgabe nicht bei der Diagnose des Problems hilft, gibt es auch noch die Protokolle des QEMU und Xen(TM) Toolstacks in [.filename]#/var/log/xen#. Beachten Sie, dass der Name der Domäne an den Protokollnamen angehängt wird. Wenn die Domäne also `freebsd` heißt, sollten Sie wahrscheinlich die Dateien [.filename]#/var/log/xen/xl-freebsd.log# und [.filename]#/var/log/xen/qemu-dm.freebsd.log# finden. Beide Dateien können nützliche Informationen zur Fehlerbehebung enthalten. Wenn nichts davon zur Lösung des Problems beiträgt, senden Sie bitte die Beschreibung des Problems und so viele Informationen wie möglich an mailto:freebsd-xen@FreeBSD.org[freebsd-xen@FreeBSD.org] und mailto:xen-devel@lists.xenproject.org[xen-devel@lists.xenproject.org], um Hilfe zu erhalten.
