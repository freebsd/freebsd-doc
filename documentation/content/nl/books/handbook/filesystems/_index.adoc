---
title: Hoofdstuk 21. Ondersteuning van bestandssystemen
part: Deel III. Systeembeheer
prev: books/handbook/geom
next: books/handbook/virtualization
---

[[filesystems]]
= Ondersteuning van bestandssystemen
:doctype: book
:toc: macro
:toclevels: 1
:icons: font
:sectnums:
:sectnumlevels: 6
:source-highlighter: rouge
:experimental:
:skip-front-matter:
:toc-title: Inhoudsopgave
:table-caption: Tabel
:figure-caption: Afbeelding
:example-caption: Voorbeeld
:xrefstyle: basic
:relfileprefix: ../
:outfilesuffix:
:sectnumoffset: 21

ifeval::["{backend}" == "html5"]
:imagesdir: ../../../images/books/handbook/filesystems/
endif::[]

ifeval::["{backend}" == "pdf"]
:imagesdir: ../../../../static/images/books/handbook/filesystems/
endif::[]

ifeval::["{backend}" == "epub3"]
:imagesdir: ../../../../static/images/books/handbook/filesystems/
endif::[]

include::shared/authors.adoc[]
include::shared/releases.adoc[]
include::shared/nl/mailing-lists.adoc[]
include::shared/nl/teams.adoc[]
include::shared/nl/urls.adoc[]

toc::[]

[[filesystems-synopsis]]
== Overzicht

Bestandssystemen zijn een integraal onderdeel van ieder besturingssysteem. Ze stellen gebruikers in de gelegenheid om bestanden te uploaden en op te slaan, geven toegang tot gegevens en maken natuurlijk harde schijven bruikbaar. Verschillende besturingssystemen hebben gewoonlijk één gezamenlijk aspect, namelijk het bestandssysteem. Op FreeBSD staat dit bestandssysteem bekend onder de naam Fast File System ofwel FFS, dat is gebaseerd op het oorspronkelijke Unix(TM) File System, ook bekend als UFS. Dit is het oorspronkelijke bestandssysteem van FreeBSD dat op harde schijven wordt geplaatst voor gegevenstoegang.

FreeBSD ondersteunt daarnaast ook een groot aantal andere bestandssystemen om lokaal toegang tot gegevens van andere besturingssystemen te bewerkstelligen; dat wil zeggen: gegevens opgeslagen op lokaal aangesloten USB opslagapparaten, flash drives, en harde schijven. Verder is er ook ondersteuning voor vreemde bestandssystemen. Dit zijn bestandssystemen ontwikkeld voor andere besturingssystemen zoals het Linux(R) Extended File System (EXT) en het Sun(TM) Z File System (ZFS).

Er zijn verschillende gradaties van ondersteuning voor de verschillende bestandssystemen op FreeBSD. Sommigen vereisen het laden van een kernelmodule, voor anderen moet een toolset worden geïnstalleerd. Dit hoofdstuk is geschreven om gebruikers van FreeBSD te helpen om op hun systeem toegang te verkrijgen tot andere bestandssystemen, te beginnen met het Sun(TM) Z File System.

Na het lezen van dit hoofstuk weet de lezer:

* Het verschil tussen eigen en ondersteunde bestandssystemen.
* Welke bestandssystemen zijn ondersteund in FreeBSD.
* Hoe niet-eigen bestandssystemen geactiveerd, geconfigureerd, benaderd en gebruikt kunnen worden.

Voorafgaand aan het lezen van dit hoofdstuk dient de lezer:

* Begrip te hebben van de beginselen van UNIX(R) en FreeBSD (crossref:basics[basics,UNIX® beginselen]).
* Bekend te zijn met de beginselen van kernelconfiguratie en -compilatie (crossref:kernelconfig[kernelconfig,De FreeBSD-kernel instellen]).
* Vertrouwd te zijn met installatie van software van derden in FreeBSD (crossref:ports[ports,Applicaties installeren. pakketten en ports]).
* Enigszins bekend te zijn met schijven, opslag en apparaatnamen in FreeBSD (crossref:disks[disks,Opslag]).

[[filesystems-zfs]]
== Het Z File System (ZFS)

Het Z File System, ontwikkeld door Sun(TM), is een nieuwe technologie ontwikkeld om gebruik te maken van een pool-gebaseerde opslagmethode. Dit houdt in dat ruimte pas wordt gebruikt wanneer het nodig is voor dataopslag. Verder is het ontworpen voor maximale integriteit van gegevens, ondersteuning van gegevens-snapshots, meerdere kopieën, en gegevenschecksums. Ook is een nieuw gegevensreplicatiemodel, bekend als RAID-Z, toegevoegd; RAID-Z lijkt op RAID5, maar is ontworpen om corruptie tijdens het schrijven van gegevens te voorkomen.

=== ZFS tuning

Het ZFS subsysteem maakt gebruik van veel systeembronnen waardoor het nodig kan zijn een en ander af te stellen, zodat voor het dagelijks gebruik maximale efficiëntie wordt behaald. Doordat het een experimentele eigenschap van FreeBSD is, kan dit in de nabije toekomst veranderen; op dit moment echter, worden de volgende stappen aangeraden.

==== Geheugen

De totale hoeveelheid systeemgeheugen dient minstens één gigabyte te zijn, maar twee gigabytes of meer wordt aanbevolen. In alle voorbeelden hier heeft het systeem één gigabyte geheugen, met verschillende andere afstelmechanismen in werking.

Sommigen hebben succes gehad met minder dan een gigabyte geheugen, maar met een dergelijke, beperkte hoeveelheid geheugen is de kans groot dat onder zware belasting een kernelpanic in FreeBSD op zal treden door uitputting van het geheugen.

==== Kernelconfiguratie

Het wordt aangeraden om ongebruikte stuurprogramma's en opties te verwijderen uit het kernelconfiguratiebestand. Omdat de meeste stuurprogramma's beschikbaar zijn als modules kunnen ze alsnog worden geladen door middel van het bestand [.filename]#/boot/loader.conf#.

Gebruikers van de i386(TM)-architectuur dienen de volgende optie aan hun kernelconfiguratiebestand toe te voegen, de kernel opnieuw te compileren, en opnieuw op te starten:

[.programlisting]
....
options		KVA_PAGES=512
....

Deze optie vergroot de kerneladresruimte, waarmee het mogelijk wordt gemaakt om de `vm.kvm_size` afstelling hoger dan de huidige limiet van 1 GB (2 GB voor PAE) in te stellen. Deel, om de meest geschikte waarde voor deze optie te vinden, de gewenste hoeveelheid adresruimte door vier (4). In dit geval is dat `512` voor 2 GB.

==== Loader tunables

De [.filename]#kmem# adresruimte dient te worden vergroot op alle FreeBSD architecturen. Op het testsysteem met één gigabyte fysiek geheugen werd succes behaald met de volgende opties, die in het bestand [.filename]#/boot/loader.conf# geplaatst dienen te worden, waarna het systeem opnieuw moet worden opgestart:

[.programlisting]
....
vm.kmem_size="330M"
vm.kmem_size_max="330M"
vfs.zfs.arc_max="40M"
vfs.zfs.vdev.cache.size="5M"
....

Zie voor een meer gedetailleerde lijst van aanbevelingen aangaande ZFS-afstelling: http://wiki.freebsd.org/ZFSTuningGuide[http://wiki.freebsd.org/ZFSTuningGuide] .

=== Gebruik maken van ZFS

Er is een opstartmechanisme dat FreeBSD in staat stelt om ZFS pools te mounten tijdens initialisatie van het systeem. Voer de volgende commando's uit om dit in te stellen:

[source,bash]
....
# echo 'zfs_enable="YES"' >> /etc/rc.conf
# service zfs start
....

In het resterende deel van dit document wordt aangenomen dat er drie SCSI-schijven beschikbaar zijn, en dat hun apparaatnamen respectievelijk [.filename]#da0#, [.filename]#da1# en [.filename]#da2# zijn. Gebruikers van IDE-hardware kunnen de [.filename]#ad# apparaten gebruiken in plaats van SCSI-apparaten.

==== Een pool op een enkele schijf

Voer het commando `zpool` uit om een simpele, niet-redundante ZFS-pool op een enkele schijf aan te maken:

[source,bash]
....
# zpool create example /dev/da0
....

Bestudeer de uitvoer van het commando `df` om de nieuwe pool te zien:

[source,bash]
....
# df
Filesystem  1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a   2026030  235230  1628718    13%    /
devfs               1       1        0   100%    /dev
/dev/ad0s1d  54098308 1032846 48737598     2%    /usr
example      17547136       0 17547136     0%    /example
....

In deze uitvoer wordt duidelijk dat de `example`-pool niet alleen is aangemaakt, maar ook direct _gemount_ is. Hij is ook toegankelijk, net als een gewoon bestandssysteem; er kunnen bestanden op worden aangemaakt en gebruikers kunnen er op rondkijken zoals in het volgende voorbeeld:

[source,bash]
....
# cd /example
# ls
# touch testfile
# ls -al
total 4
drwxr-xr-x   2 root  wheel    3 Aug 29 23:15 .
drwxr-xr-x  21 root  wheel  512 Aug 29 23:12 ..
-rw-r--r--   1 root  wheel    0 Aug 29 23:15 testfile
....

Helaas benut deze pool nog geen ZFS-mogelijkheden. Maak een bestandssysteem aan op deze pool en activeer er compressie op:

[source,bash]
....
# zfs create example/compressed
# zfs set compression=gzip example/compressed
....

`example/compressed` is nu een gecomprimeerd ZFS-bestandssysteem. Probeer er een paar grote bestanden naartoe te kopiëren door ze naar [.filename]#/example/compressed# te kopiëren.

De compressie kan nu worden uitgeschakeld met:

[source,bash]
....
# zfs set compression=off example/compressed
....

Voer het volgende commando uit om het bestandssysteem te unmounten, en controleer dat daarna met `df`:

[source,bash]
....
# zfs umount example/compressed
# df
Filesystem  1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a   2026030  235232  1628716    13%    /
devfs               1       1        0   100%    /dev
/dev/ad0s1d  54098308 1032864 48737580     2%    /usr
example      17547008       0 17547008     0%    /example
....

Mount het bestandssysteem opnieuw om het weer toegankelijk te maken en controleer met `df`:

[source,bash]
....
# zfs mount example/compressed
# df
Filesystem         1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a          2026030  235234  1628714    13%    /
devfs                      1       1        0   100%    /dev
/dev/ad0s1d         54098308 1032864 48737580     2%    /usr
example             17547008       0 17547008     0%    /example
example/compressed  17547008       0 17547008     0%    /example/compressed
....

De pool en het bestandssysteem zijn ook zichtbaar in de uitvoer van `mount`:

[source,bash]
....
# mount
/dev/ad0s1a on / (ufs, local)
devfs on /dev (devfs, local)
/dev/ad0s1d on /usr (ufs, local, soft-updates)
example on /example (zfs, local)
example/data on /example/data (zfs, local)
example/compressed on /example/compressed (zfs, local)
....

Zoals is te zien kunnen ZFS-bestandssystemen, nadat ze zijn gecreëerd, net als gewone bestandssystemen worden gebruikt; er zijn echter ook vele andere mogelijkheden beschikbaar. In het volgende voorbeeld wordt er een nieuw bestandssysteem `data` gecreëerd. Er zullen belangrijke bestanden op worden bewaard, dus het bestandssysteem wordt zodanig ingesteld dat het twee kopieën van ieder gegevensblok opslaat:

[source,bash]
....
# zfs create example/data
# zfs set copies=2 example/data
....

Het is nu mogelijk om het gegevens- en ruimtegebruik te bekijken door `df` opnieuw te draaien:

[source,bash]
....
# df
Filesystem         1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a          2026030  235234  1628714    13%    /
devfs                      1       1        0   100%    /dev
/dev/ad0s1d         54098308 1032864 48737580     2%    /usr
example             17547008       0 17547008     0%    /example
example/compressed  17547008       0 17547008     0%    /example/compressed
example/data        17547008       0 17547008     0%    /example/data
....

Merk op dat ieder bestandssysteem in de pool dezelfde hoeveelheid vrije ruimte heeft. Dit is de reden dat `df` steeds wordt gebruikt tussen de voorbeelden door, om te laten zien dat de bestandssystemen slechts zoveel ruimte gebruiken als ze nodig hebben en allemaal putten uit dezelfde pool. Het ZFS bestandssysteem elimineert concepten als volumes en partities, en staat verschillende bestandssystemen toe om in dezelfde pool te bestaan. Verwijder nu de bestandssystemen en verwijder daarna de pool, omdat deze niet meer nodig zijn:

[source,bash]
....
# zfs destroy example/compressed
# zfs destroy example/data
# zpool destroy example
....

Schijven gaan slechter werken en begeven het, een onvermijdelijke eigenschap. Wanneer de schijf stukgaat zullen de gegevens verloren gaan. Een methode om gegevensverlies ten gevolge van een kapotte harde schijf te vermijden is het implementeren van RAID. ZFS ondersteunt deze mogelijkheid in zijn pool-ontwerp en wordt beschreven in de volgende sectie.

==== ZFS RAID-Z

Zoals eerder opgemerkt wordt in deze sectie aangenomen dat er drie SCSI-schijven bestaan als de apparaten [.filename]#da0#, [.filename]#da1# en [.filename]#da2# (of [.filename]#ad0# en hoger als IDE-schijven worden gebruikt). Voer het volgende commando uit om een RAID-Z-pool te creëren:

[source,bash]
....
# zpool create storage raidz da0 da1 da2
....

[NOTE]
====
Sun(TM) raadt aan om tussen de drie en negen schijven te gebruiken voor een RAID-Z-configuratie. Overweeg, als u een enkele pool met 10 of meer schijven nodig heeft, om deze te splitsen in kleine RAID-Z-groepen. Overweeg, als u slechts twee schijven heeft en nog steeds redundantie nodig heeft, om in plaats hiervan een ZFS-spiegel te gebruiken. Bekijk de handleidingpagina man:zpool[8] voor meer details.
====

De `storage` zpool zou gecreëerd moeten zijn. Dit kan worden geverifieerd met de man:mount[8] en man:df[1] commando's zoals eerder. Er kunnen meer schijfapparaten worden toegewezen door ze aan het einde van de bovenstaande lijst toe te voegen. Maak een nieuw bestandssysteem in de pool, genaamd `home`, waar op den duur de gebruikersbestanden geplaatst zullen worden:

[source,bash]
....
# zfs create storage/home
....

Het is nu mogelijk om compressie in te schakelen en extra kopieën te bewaren van de gebruikersmappen en -bestanden. Dit kan net als eerder worden bewerkstelligd door de volgende commando's uit te voeren:

[source,bash]
....
# zfs set copies=2 storage/home
# zfs set compression=gzip storage/home
....

Kopieer, om dit als de nieuwe home-map voor gebruikers in te stellen, de gebruikersgegevens naar deze map en creëer de benodigde links:

[source,bash]
....
# cp -rp /home/* /storage/home
# rm -rf /home /usr/home
# ln -s /storage/home /home
# ln -s /storage/home /usr/home
....

De gebruikersgegevens zouden nu op het nieuw aangemaakte [.filename]#/storage/home# bestandssysteem moeten staan. Test dit door een nieuwe gebruiker aan te maken en daarmee in te loggen.

Probeer een snapshot te maken dat later weer hersteld kan worden:

[source,bash]
....
# zfs snapshot storage/home@08-30-08
....

Merk op dat de snapshot-optie alleen een echt bestandssysteem vastlegt, geen mappen of bestanden. Het `@`-karakter wordt gebruikt als scheidingsteken tussen de naam van het bestandssysteem of de naam van het volume. Wanneer de home-map van een gebruiker wordt weggegooid, kan deze worden hersteld met:

[source,bash]
....
# zfs rollback storage/home@08-30-08
....

Voer `ls` in de [.filename]#.zfs/snapshot# directory van het bestandssysteem uit om een lijst van alle beschikbare snapshots te krijgen. Voer, om bijvoorbeeld het zojuist gemaakte snapshot te zien, het volgende commando uit:

[source,bash]
....
# ls /storage/home/.zfs/snapshot
....

Het is mogelijk om een script te schrijven dat maandelijks een snapshot van de gebruikersgegevens maakt; na verloop van tijd kunnen snapshots echter een grote hoeveelheid schrijfruimte in beslag nemen. Het vorige snapshot kan worden verwijderd met het volgende commando:

[source,bash]
....
# zfs destroy storage/home@08-30-08
....

Na al dit testen is er geen reden om [.filename]#/storage/home# in zijn huidige staat nog te bewaren. Maak er het echte [.filename]#/home# bestandssysteem van:

[source,bash]
....
# zfs set mountpoint=/home storage/home
....

Het uitvoeren van de commando's `df` en `mount` laat zien dat het systeem ons bestandssysteem nu als de echte [.filename]#/home# behandelt:

[source,bash]
....
# mount
/dev/ad0s1a on / (ufs, local)
devfs on /dev (devfs, local)
/dev/ad0s1d on /usr (ufs, local, soft-updates)
storage on /storage (zfs, local)
storage/home on /home (zfs, local)
# df
Filesystem   1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a    2026030  235240  1628708    13%    /
devfs                1       1        0   100%    /dev
/dev/ad0s1d   54098308 1032826 48737618     2%    /usr
storage       26320512	     0 26320512     0%    /storage
storage/home  26320512       0 26320512     0%    /home
....

Hiermee is de RAID-Z configuratie compleet. Voer het volgende commando uit om status-updates van de gecreëerde bestandssystemen te krijgen tijdens het draaien van de nachtelijke man:periodic[8]:

[source,bash]
....
# echo 'daily_status_zfs_enable="YES"' >> /etc/periodic.conf
....

==== Het herstellen van RAID-Z

Iedere software-RAID heeft een methode om zijn `status` te inspecteren. ZFS is geen uitzondering. De status van RAID-Z-apparaten kan worden geïnspecteerd met het volgende commando:

[source,bash]
....
# zpool status -x
....

Als alle pools in orde zijn en alles is normaal, dan wordt het volgende bericht weergegeven:

[source,bash]
....
all pools are healthy
....

Als er een probleem is, misschien een schijf die offine is gegaan, dan wordt de status van de pool weergegeven en dat zal er als volgt uitzien:

[source,bash]
....
  pool: storage
 state: DEGRADED
status: One or more devices has been taken offline by the administrator.
	Sufficient replicas exist for the pool to continue functioning in a
	degraded state.
action: Online the device using 'zpool online' or replace the device with
	'zpool replace'.
 scrub: none requested
config:

	NAME        STATE     READ WRITE CKSUM
	storage     DEGRADED     0     0     0
	  raidz1    DEGRADED     0     0     0
	    da0     ONLINE       0     0     0
	    da1     OFFLINE      0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors
....

Hier staat dat het apparaat offline is gezet door de beheerder. Dat is waar voor dit specifieke voorbeeld. Om de schijf offline te zetten werd het volgende commando gebruikt:

[source,bash]
....
# zpool offline storage da1
....

Het is nu mogelijk om de schijf [.filename]#da1# te vervangen nadat het systeem uitgeschakeld is. Zodra het systeem weer opgestart is, kan het volgende commando worden uitgevoerd om de schijf te vervangen:

[source,bash]
....
# zpool replace storage da1
....

Nu kan de status opnieuw geïnspecteerd worden, dit keer zonder de `-x` vlag, om de statusinformatie op te vragen:

[source,bash]
....
# zpool status storage
 pool: storage
 state: ONLINE
 scrub: resilver completed with 0 errors on Sat Aug 30 19:44:11 2008
config:

	NAME        STATE     READ WRITE CKSUM
	storage     ONLINE       0     0     0
	  raidz1    ONLINE       0     0     0
	    da0     ONLINE       0     0     0
	    da1     ONLINE       0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors
....

Zoals te zien in dit voorbeeld lijkt alles normaal te zijn.

==== Gegevensverificatie

Zoals eerder opgemerkt gebruikt ZFS `checksums` om de integriteit van opgeslagen gegevens te verifiëren. Ze worden automatisch ingeschakeld bij het creëeren van bestandssystemen en kunnen worden uitgeschakeld door middel van het volgende commando:

[source,bash]
....
# zfs set checksum=off storage/home
....

Dit is echter geen verstandig idee, omdat checksums zeer weinig opslagruimte innemen en nuttiger zijn wanneer ze zijn ingeschakeld. Het lijkt daarnaast ook geen merkbare invloed op de prestaties te hebben wanneer ze zijn ingeschakeld. Wanneer ze aanstaan is het mogelijk om ZFS gegevensintegriteit te laten controleren door middel van checksum-verificatie. Dit proces staat bekend als "scrubbing". Voer het volgende commando uit om de gegevensintegriteit van de `storage`-pool te controleren:

[source,bash]
....
# zpool scrub storage
....

Dit proces kan, afhankelijk van de hoeveelheid opgeslagen gegevens, een aanzienlijke hoeveelheid tijd in beslag nemen. Het is daarnaast ook zeer I/O-intensief, zozeer dat slechts één van deze operaties tegelijkertijd uitgevoerd kan worden. Nadat de scrub is voltooid wordt de status bijgewerkt en kan deze worden bekeken door een statusaanvraag te doen:

[source,bash]
....
# zpool status storage
 pool: storage
 state: ONLINE
 scrub: scrub completed with 0 errors on Sat Aug 30 19:57:37 2008
config:

	NAME        STATE     READ WRITE CKSUM
	storage     ONLINE       0     0     0
	  raidz1    ONLINE       0     0     0
	    da0     ONLINE       0     0     0
	    da1     ONLINE       0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors
....

De voltooiingstijd is in dit voorbeeld duidelijk zichtbaar. Deze eigenschap helpt om gegevensintegriteit te garanderen gedurende een langere tijdsperiode.

Er zijn vele andere opties voor het Z-bestandssysteem, zie de handleidingpagina's man:zfs[8] en man:zpool[8].

==== ZFS quota

ZFS ondersteunt verschillende soorten quota: de refquota, de algemene quota, de gebruikersquota en de groepsquota. Deze sectie legt de beginselen van ieder van deze uit en bevat wat instructies voor gebruik.

Quota beperken de hoeveelheid ruimte die een gegevensverzameling en zijn afstammelingen kunnen gebruiken en dwingen een limiet af op de hoeveelheid ruimte dat gebruikt wordt door bestandssystemen en snapshots voor deze afstammelingen. Vanuit gebruikers zijn quota handig om de hoeveelheid ruimte die een bepaalde gebruiker kan gebruiken te beperken.

[NOTE]
====
Quota kunnen niet op volumes worden ingesteld, aangezien de eigenschap `volsize` als een impliciet quotum optreedt.
====

De refquota, `refquota=grootte`, beperkt de hoeveelheid ruimte die een gegevensverzameling in beslag kan nemen door een harde grens aan de gebruikte ruimte te stellen. Deze harde grens bevat echter niet de ruimte gebruikt door afstammelingen, zoals bestandssystemen of snapshots.

Gebruik het volgende om een algemeen quotum van 10 GB voor [.filename]#/home/storage/bob# af te dwingen:

[source,bash]
....
# zfs set quota=10G storage/home/bob
....

Gebruikersquota beperken de hoeveelheid ruimte die door de aangegeven gebruiker kan worden gebruikt. Het algemene formaat is `userquota@gebruiker=grootte` waarbij de gebruikersnaam in één van de volgende formaten dient te zijn:

* Naam compatibel met POSIX (bijvoorbeeld _jan_).
* Numeriek POSIX-ID (bijvoorbeeld _789_).
* SID-naam (bijvoorbeeld _jan.bloggs@example.com_).
* Numeriek SID-ID (bijvoorbeeld _S-1-123-456-789_).

Gebruik het volgende om bijvoorbeeld een quotum van 50 GB voor een gebruiker _jan_ af te dwingen:

[source,bash]
....
# zfs set userquota@jan=50G
....

Gebruik in plaats hiervan, om het quotum te verwijderen of er zeker van te zijn dat er geen is ingesteld:

[source,bash]
....
# zfs set userquota@jan=none
....

Eigenschappen van gebruikersquota worden niet weergegeven door `zfs get all`. Niet-`root` gebruikers kunnen alleen hun eigen quota zien tenzij het privilege `userquota` aan ze is gegeven. Gebruikers met dit privilege kunnen ieders quota bekijken en instellen.

Groepsquota beperken de hoeveelheid ruimte die de gespecificeerde gebruikersgroep in beslag kan nemen. Het algemene formaat is `groupquota@groep=grootte`.

Gebruik om het quotum voor de groep _eerstegroep_ op 50 GB in te stellen:

[source,bash]
....
# zfs set groupquota@eerstegroep=50G
....

Gebruik in plaats hiervan, om het quotum voor de groep _eerstegroep_ te verwijderen of om er voor te zorgen dat deze niet is ingesteld:

[source,bash]
....
# zfs set groupquota@eerstegroep=none
....

Net zoals bij de eigenschappen van gebruikersquota kunnen niet-`root`-gebruikers alleen de quota zien die geassocieerd zijn met de gebruikersgroepen waar ze bij horen, een `root`-gebruiker of een gebruiker met het privilege `groupquota` kan alle quota voor alle groepen bekijken en instellen.

Het deelcommando `zfs userspace` geeft de hoeveelheid ruimte weer die door elke gebruiker op de snapshot van het gespecificeerde bestandssysteem in beslag wordt genomen, tezamen met alle ingestelde quota. Het deelcommando `zfs groupspace` doet hetzelfde voor groepen. Bekijk man:zfs[1] voor meer informatie over ondersteunde opties of het weergegeven van specifieke opties.

Gebruik het volgende om de quota voor [.filename]#storage/home/bob# weer te geven, als u de juiste privileges heeft of `root` bent:

[source,bash]
....
# zfs get quota storage/home/bob
....

==== Reserveringen in ZFS

ZFS ondersteunt twee soorten van ruimtereserveringen. Deze sectie legt de beginselen van elk van de twee uit en bevat enkele instructies voor gebruik.

De eigenschap `reservation` maakt het mogelijk om een gegarandeerde minimale hoeveelheid ruimte voor een gegevensverzameling en zijn afstammelingen te reserveren. Dit betekent dat als er een reservering van 10 GB is ingesteld voor [.filename]#storage/home/bob# en de schijfruimte op raakt, er tenminste 10 GB aan ruimte is gereserveerd voor deze gegevensverzameling. De eigenschap `reservation` stelt de minimale hoeveelheid ruimte in die gegarandeerd is voor een gegevensverzameling exclusief afstammelingen zoals snapshots, of geeft deze aan. Als er bijvoorbeeld een snapshot is genomen van [.filename]#storage/home/bob# moet er genoeg schijfruimte zijn buiten de `refreservation` hoeveelheid om de operatie te laten slagen omdat afstammelingen van de hoofdgegevensverzameling niet worden meegeteld in de `refreservation` hoeveelheid en dus niet stiekem de vastgestelde ruimte wijzigen.

Reserveringen kunnen in allerlei situaties nuttig zijn, bijvoorbeeld voor het plannen en testen van de geschiktheid van het toewijzen van schijfruimte in een nieuw systeem, of om ervoor te zorgen dat er genoeg schijfruimte beschikbaar is op bestandsssystemen voor systeemherstelprocedures en bestanden.

Het algemene formaat van de eigenschap `reservation` is `reservation=grootte`, dus gebruik het onderstaande commando om een reservering van 10 GB op [.filename]#storage/home/bob# te plaatsen:

[source,bash]
....
# zfs set reservation=10G storage/home/bob
....

Gebruik, om te controleren of er geen reservatie is geplaatst of om een reservatie te verwijderen:

[source,bash]
....
# zfs set reservation=none storage/home/bob
....

Het zelfde principe kan worden toegepast op de eigenschap `refreservation` om een refreservation in te stellen, met het algemene formaat `refreservation=grootte`.

Gebruik één van de volgende commando's om te kijken of er een reservatie of refreservation bestaat op [.filename]#storage/home/bob#:

[source,bash]
....
# zfs get reservation storage/home/bob
# zfs get refreservation storage/home/bob
....

[[filesystems-linux]]
== Linux(R) bestandssystemen

Deze sectie beschrijft enkele van de Linux(R) bestandssystemen die door FreeBSD worden ondersteund.

=== Ext2FS

De kernelimplementatie van het man:ext2fs[5] bestandssysteem was geschreven door Godmar Back, het eerste stuurprogramma verscheen in FreeBSD 2.2. In FreeBSD 8 en eerder is de code gelicenseerd onder de GNU Public License, onder FreeBSD 9 is de code echter herschreven en nu beschikbaar onder de BSD-licentie.

Het stuurprogramma man:ext2fs[5] stelt de FreeBSD-kernel in staat om ext2 bestandssystemen te lezen en er naar te schrijven.

Laad ten eerste de kernelmodule:

[source,bash]
....
# kldload ext2fs
....

Koppel daarna een man:ext2fs[5]-volume aan dat zich op [.filename]#/dev/ad1s1# bevindt:

[source,bash]
....
# mount -t ext2fs /dev/ad1s1 /mnt
....

=== XFS

Het X-bestandssysteem, XFS, is origineel geschreven door SGI voor het besturingssysteem IRIX, ze hebben het overgebracht naar Linux(R). De broncode is vrijgegeven onder de GNU Public License. Kijk op https://oss.sgi.com/projects/xfs[deze pagina] voor meer details. De FreeBSD-port werd gestart door Russel Cattelan, {kan} en {rodrigc}.

Om XFS als een kernelmodule te laden:

[source,bash]
....
# kldload xfs
....

Het stuurprogramma man:xfs[5] stelt de FreeBSD-kernel in staat om XFS-bestandssystemen te benaderen. Momenteel is echter alleen ondersteuning voor lezen aanwezig. Schrijven naar een volume is niet mogelijk.

Om een man:xfs[5]-volume wat op [.filename]#/dev/ad1s1# aan te koppelen:

[source,bash]
....
# mount -t xfs /dev/ad1s1 /mnt
....

Merk op dat de port package:sysutils/xfsprogs[] het gereedschap `mkfs.xfs` bevat wat het mogelijk maakt om XFS-bestandssystemen aan te maken, en verder gereedschappen om ze te analyseren en repareren.

De vlag `-p` van `mkfs.xfs` kan worden gebruikt om een man:xfs[5]-bestandssysteem aan te maken welke bevolkt wordt met bestanden en andere meta-gegevens. Dit kan worden gebruikt om snel een alleen-lezen bestandssysteem aan te maken welke op FreeBSD getest kan worden.

=== ReiserFS

Het Reiser bestandssysteem, ReiserFS, was overgebracht naar FreeBSD door {dumbbell} en is vrijgegeven onder de GNU Public License.

Het stuurprogramma voor ReiserFS stelt de FreeBSD-kernel momenteel in staat om ReiserFS bestandssystemen te benaderen en hun inhoud te lezen, maar het kan ze momenteel niet beschrijven.

Laad ten eerste eerst de kernelmodule:

[source,bash]
....
# kldload reiserfs
....

Om ten tweede een ReiserFS-volume dat zich op [.filename]#/dev/ad1s1# aan te koppelen:

[source,bash]
....
# mount -t reiserfs /dev/ad1s1 /mnt
....
