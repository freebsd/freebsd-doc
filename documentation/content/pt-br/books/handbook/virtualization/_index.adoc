---
title: Capítulo 21. Virtualização
part: Parte III. Administração do Sistema
prev: books/handbook/filesystems
next: books/handbook/l10n
---

[[virtualization]]
= Virtualização
:doctype: book
:toc: macro
:toclevels: 1
:icons: font
:sectnums:
:sectnumlevels: 6
:source-highlighter: rouge
:experimental:
:skip-front-matter:
:toc-title: Índice
:table-caption: Tabela
:figure-caption: Figura
:example-caption: Exemplo
:xrefstyle: basic
:relfileprefix: ../
:outfilesuffix:
:sectnumoffset: 21

ifeval::["{backend}" == "html5"]
:imagesdir: ../../../../images/books/handbook/virtualization/
endif::[]

ifeval::["{backend}" == "pdf"]
:imagesdir: ../../../../static/images/books/handbook/virtualization/
endif::[]

ifeval::["{backend}" == "epub3"]
:imagesdir: ../../../../static/images/books/handbook/virtualization/
endif::[]

include::shared/authors.adoc[]
include::shared/releases.adoc[]
include::shared/pt-br/mailing-lists.adoc[]
include::shared/pt-br/teams.adoc[]
include::shared/pt-br/urls.adoc[]

toc::[]

[[virtualization-synopsis]]
== Sinopse

O software de virtualização permite que vários sistemas operacionais sejam executados simultaneamente no mesmo computador. Tais sistemas de software para PCs geralmente envolvem um sistema operacional host que executa o software de virtualização e suporta qualquer número de sistemas operacionais convidados.

Depois de ler este capítulo, você saberá:

* A diferença entre um sistema operacional host e um sistema operacional convidado.
* Como instalar o FreeBSD em um computador baseado em um Intel(TM)Apple(TM)Mac(TM).
* Como instalar o FreeBSD no Microsoft(TM)Windows(TM) com Virtual PC.
* Como instalar o FreeBSD como um host convidado no bhyve.
* Como ajustar um sistema FreeBSD para melhor desempenho sob virtualização.

Antes de ler este capítulo, você deve:

* Entender o crossref:basics[basics,básico sobre sistemas UNIX(TM) e sobre o FreeBSD].
* Saber como crossref:bsdinstall[bsdinstall,instalar o FreeBSD].
* Saber como crossref:advanced-networking[advanced-networking,configurar uma conexão de rede].
* Saber como crossref:ports[ports,instalar software adicional de terceiros].

[[virtualization-guest-parallels]]
== FreeBSD como Sistema Operacional Convidado no Parallels para Mac OS(TM) X

O Parallels Desktop para Mac(TM) é um produto de software comercial disponível para computadores baseados em Intel(TM)Apple(TM)Mac(TM) rodando Mac OS(TM) 10.4.6 ou superior. O FreeBSD é um sistema operacional convidado completamente suportado. Uma vez que o Parallels tiver sido instalado no Mac OS(TM) X, o usuário deve configurar uma maquina virtual e então instalar o sistema operacional convidado desejado.

[[virtualization-guest-parallels-install]]
=== Instalando o FreeBSD no Parallels/Mac OS(TM) X

O primeiro passo para instalar o FreeBSD no Parallels é criar uma nova máquina virtual para instalar o FreeBSD. Selecione [.guimenuitem]#FreeBSD# como o menu:Guest OS Type[] quando solicitado:

image::parallels-freebsd1.png[]

Escolha uma quantidade razoável de disco e memória, dependendo dos planos para esta instância virtual do FreeBSD. 4GB de espaço em disco e 512MB de RAM funcionam bem para a maioria dos usos do FreeBSD executando sob o Parallels:

image::parallels-freebsd2.png[]

image::parallels-freebsd3.png[]

image::parallels-freebsd4.png[]

image::parallels-freebsd5.png[]

Selecione o tipo de rede e uma interface de rede:

image::parallels-freebsd6.png[]

image::parallels-freebsd7.png[]

Salve e finalize a configuração:

image::parallels-freebsd8.png[]

image::parallels-freebsd9.png[]

Após a criação da máquina virtual do FreeBSD, o FreeBSD pode ser instalado nela. Isto é feito melhor com um CD/DVD oficial do FreeBSD ou com uma imagem ISO baixada de um site FTP oficial. Copie a imagem ISO apropriada para o sistema de arquivos local do Mac(TM) ou insira um CD/DVD na unidade de CD-ROM do Mac(TM). Clique no ícone do disco no canto inferior direito da janela do FreeBSD no Parallels. Isso abrirá uma janela a qual pode ser usada para associar a unidade de CD-ROM na máquina virtual com o arquivo ISO no disco ou com drive CD.

image::parallels-freebsd11.png[]

Uma vez que esta associação com a fonte do CD-ROM estiver feita, reinicialize a máquina virtual do FreeBSD clicando no ícone de reinicialização. O Parallels irá reiniciar com um BIOS especial o qual primeiro irá verificar se existe um CD-ROM.

image::parallels-freebsd10.png[]

Neste caso, ele encontrará a mídia de instalação do FreeBSD e iniciará uma instalação normal do FreeBSD. Execute a instalação, mas não tente configurar o Xorg neste momento.

image::parallels-freebsd12.png[]

Quando a instalação estiver concluída, reinicie a máquina virtual FreeBSD recém-instalada.

image::parallels-freebsd13.png[]

[[virtualization-guest-parallels-configure]]
=== Configurando o FreeBSD no Parallels

Depois que o FreeBSD foi instalado com sucesso no Mac OS(TM) X com o  Parallels , existem várias etapas de configuração que podem ser executadas para otimizar o sistema para operar virtualizado.

[.procedure]
====

. Definir variáveis do Boot Loader
+ 
O passo mais importante é reduzir o `kern.hz` ajustável para reduzir a utilização de CPU no FreeBSD sob ambiente Parallels. Isso é feito adicionando a seguinte linha ao [.filename]#/boot/loader.conf#:
+
[.programlisting]
....
kern.hz=100
....
+ 
Sem essa configuração, um sistema convidado inativo do FreeBSD no Parallels usará aproximadamente 15% da CPU de um único processador iMac(TM). Após essa alteração, o uso ficará mais próximo de 5%.
. Criar um novo arquivo de configuração do kernel
+ 
Todos os drivers de dispositivos SCSI, FireWire e USB podem ser removidos de um arquivo de configuração de kernel personalizado. O Parallels fornece um adaptador de rede virtual usado pelo driver man:ed[4], portanto, todos os dispositivos de rede, exceto o man:ed[4] e o man:miibus[4] podem ser removidos do kernel .
. Configure a rede
+ 
A configuração de rede mais básica usa o DHCP para conectar a máquina virtual à mesma rede local que o host Mac(TM). Isso pode ser feito adicionando `ifconfig_ed0="DHCP"` ao [.filename]#/etc/rc.conf#. Configurações de rede mais avançadas são descritas em crossref:advanced-networking[advanced-networking, Rede Avançada].
====

[[virtualization-guest-virtualpc]]
== FreeBSD como sistema convidado no Virtual PC para Windows(TM)

O Virtual PC para Windows(TM) é um software da Microsoft(TM) disponível para download gratuito. Consulte este site para os http://www.microsoft.com/windows/downloads/virtualpc/sysreq.mspx[requisitos do sistema]. Depois que o Virtual PC tiver sido instalado no Microsoft(TM)Windows(TM), o usuário poderá configurar uma máquina virtual e depois instalar o sistema operacional convidado desejado.

[[virtualization-guest-virtualpc-install]]
=== Instalando o FreeBSD no Virtual PC

O primeiro passo para instalar o FreeBSD no Virtual PC é criar uma nova máquina virtual para instalar o FreeBSD. Selecione [.guimenuitem]#Criar uma máquina virtual# quando solicitado:

image::virtualpc-freebsd1.png[]

image::virtualpc-freebsd2.png[]

Selecione a opção [.guimenuitem]#Outro# para o [.guimenuitem]#Sistema operacional# quando solicitado:

image::virtualpc-freebsd3.png[]

Em seguida, escolha uma quantidade razoável de disco e de memória, dependendo dos planos para esta instância virtual do FreeBSD. 4GB de espaço em disco e 512MB de RAM funcionam bem para a maioria dos usos do FreeBSD sob o Virtual PC:

image::virtualpc-freebsd4.png[]

image::virtualpc-freebsd5.png[]

Salve e finalize a configuração:

image::virtualpc-freebsd6.png[]

Selecione a máquina virtual do FreeBSD e clique em menu:Configurações[], em seguida, defina o tipo de rede e uma interface de rede:

image::virtualpc-freebsd7.png[]

image::virtualpc-freebsd8.png[]

Após a criação da máquina virtual do FreeBSD, o FreeBSD pode ser instalado nela. Isso é feito da melhor maneira com um CD/DVD oficial ou com uma imagem ISO baixada de um site FTP oficial. Copie a imagem ISO apropriada para o sistema de arquivos local do Windows(TM) ou insira um CD/DVD na unidade de CD-ROM, então clique duas vezes na máquina virtual FreeBSD para inicializar. Em seguida, clique em menu:CD[] e escolha menu:Capturar imagem ISO...[] na janela do Virtual PC. Isso abrirá uma janela na qual a unidade de CD-ROM na máquina virtual poderá ser associada a um arquivo ISO no disco ou com o drive de CD-ROM real.

image::virtualpc-freebsd9.png[]

image::virtualpc-freebsd10.png[]

Uma vez que a associação com a fonte do CD-ROM estiver feita, reinicie a máquina virtual do FreeBSD clicando em menu:Action[] e depois em menu:Reset[]. O Virtual PC será reiniciado com um BIOS especial que irá procurar por um CD-ROM para inicializar.

image::virtualpc-freebsd11.png[]

Neste caso, ele encontrará a mídia de instalação do FreeBSD e iniciará uma instalação normal do FreeBSD. Continue com a instalação, mas não tente configurar o Xorg neste momento.

image::virtualpc-freebsd12.png[]

Quando a instalação estiver concluída, lembre-se de ejetar o CD/DVD ou de liberar a imagem ISO. Finalmente, reinicie a máquina virtual FreeBSD recém-instalada.

image::virtualpc-freebsd13.png[]

[[virtualization-guest-virtualpc-configure]]
=== Configuring FreeBSD on Virtual PC

Depois que o FreeBSD tiver sido instalado com sucesso no Microsoft(TM)Windows(TM) com o Virtual PC, existem várias etapas de configurações que podem ser executadas para otimizar o sistema para operação virtualizada.

[.procedure]
====

. Definir variáveis do Boot Loader
+ 
O passo mais importante é reduzir o valor do parâmetro `kern.hz` para reduzir a utilização da CPU do FreeBSD sob o ambiente do Virtual PC. Isso é feito adicionando a seguinte linha ao [.filename]#/boot/loader.conf#:
+
[.programlisting]
....
kern.hz=100
....
+ 
Sem esta configuração, uma VM idle do FreeBSD rodando sob o Virtual PC utilizará aproximadamente 40% da CPU de um computador com um único processador. Após essa mudança, o uso ficará mais próximo de 3%.
. Criar um novo arquivo de configuração do kernel
+ 
Todos os drivers de dispositivos SCSI, FireWire e USB podem ser removidos do arquivo de configuração do kernel personalizado. O Virtual PC fornece um adaptador de rede virtual usado pelo driver man:de[4], portanto, todos os dispositivos de rede, exceto o man:de[4] e o man:miibus[4] podem ser removidos do kernel.
. Configure a rede
+ 
A configuração de rede mais básica usa o DHCP para conectar a máquina virtual à mesma rede local que o host Microsoft(TM)Windows(TM). Isso pode ser feito adicionando `ifconfig_de0="DHCP"` ao [.filename]#/etc/rc.conf#. Configurações de rede mais avançadas são descritas em crossref:advanced-networking[advanced-networking, Rede Avançada].
====

[[virtualization-guest-vmware]]
== FreeBSD como Sistema Operacional Convidado no VMware Fusion para Mac OS(TM)

O VMware Fusion para Mac(TM) é um software comercial disponível para computadores Apple(TM)Mac(TM) baseados em processadores Intel(TM) e que rodam o Mac OS(TM) 10.4.9 ou superior. O FreeBSD é um sistema operacional convidado totalmente suportado. Depois que o VMware Fusion for instalado no  Mac OS(TM) X, o usuário poderá configurar uma máquina virtual e, em seguida, instalar o sistema operacional convidado desejado.

[[virtualization-guest-vmware-install]]
=== Instalando o FreeBSD no VMware Fusion

A primeira etapa é iniciar o VMware Fusion, que irá carregar a biblioteca de máquinas virtuais. Clique em [.guimenuitem]#Novo# para criar a máquina virtual:

image::vmware-freebsd01.png[]

Isto irá carregar o Assistente de Nova Máquina Virtual. Clique em [.guimenuitem]#Continuar# para prosseguir:

image::vmware-freebsd02.png[]

Selecione [.guimenuitem]#Outro# como o [.guimenuitem]#Sistema Operacional# e [.guimenuitem]#FreeBSD# ou [.guimenuitem]#FreeBSD 64-bit#, como menu:Versão[] quando solicitado:

image::vmware-freebsd03.png[]

Escolha o nome da máquina virtual e o diretório onde ela deve ser salva:

image::vmware-freebsd04.png[]

Escolha o tamanho do disco rígido virtual para a máquina virtual:

image::vmware-freebsd05.png[]

Escolha o método para instalar a máquina virtual, a partir de uma imagem ISO ou de um CD/DVD:

image::vmware-freebsd06.png[]

Clique em [.guimenuitem]#Concluir# e a máquina virtual inicializará:

image::vmware-freebsd07.png[]

Instale o FreeBSD como de costume:

image::vmware-freebsd08.png[]

Quando a instalação estiver concluída, as configurações da máquina virtual poderão ser modificadas, como o uso de memória:

[NOTE]
====
As configurações de hardware do sistema da máquina virtual não podem ser modificadas enquanto a máquina virtual estiver em execução.
====

image::vmware-freebsd09.png[]

O número de CPUs a que a máquina virtual terá acesso:

image::vmware-freebsd10.png[]

O status do dispositivo CD-ROM. Normalmente, o CD/DVD/ISO é desconectado da máquina virtual quando não é mais necessário.

image::vmware-freebsd11.png[]

A última coisa a mudar é como a máquina virtual se conectará à rede. Para permitir conexões à máquina virtual de outras máquinas além do host, escolha [.guimenuitem]#Conectar diretamente à rede física (Bridged)#. Caso contrário, [.guimenuitem]#Compartilhar a conexão de internet do host (NAT)# é preferível para que a máquina virtual possa ter acesso à Internet, porém sem que as demais maquinas da rede possam acessá-la.

image::vmware-freebsd12.png[]

Depois de modificar as configurações, inicialize a máquina virtual FreeBSD recém-instalada.

[[virtualization-guest-vmware-configure]]
=== Configurando o FreeBSD no VMware Fusion

Depois que o FreeBSD for instalado com sucesso no Mac OS(TM) X rodando o VMware Fusion, existem várias etapas de configuração que podem ser executadas para otimizar o sistema para operar virtualizado.

[.procedure]
====

. Definir variáveis do Boot Loader
+ 
O passo mais importante é reduzir o valor do parâmetro `kern.hz` para reduzir a utilização da CPU do FreeBSD sob o ambiente do VMware Fusion. Isso é feito adicionando a seguinte linha ao [.filename]#/boot/loader.conf#:
+
[.programlisting]
....
kern.hz=100
....
+ 
Sem esta configuração, uma VM idle do FreeBSD rodando sob o VMware Fusion usará aproximadamente 15% da CPU de um único processador iMac(TM). Após esta mudança, o uso ficará próximo de 5%.
. Criar um novo arquivo de configuração do kernel
+ 
Todos os drivers de dispositivos FireWire e USB podem ser removidos do arquivo de configuração do kernel personalizado. O VMware Fusion fornece um adaptador de rede virtual usado pelo driver man:em[4], portanto, todos os dispositivos de rede, exceto o man:em[4] podem ser removidos do kernel.
. Configure a rede
+ 
A configuração de rede mais básica usa o DHCP para conectar a máquina virtual à mesma rede local que o host Mac(TM). Isso pode ser feito adicionando `ifconfig_em0="DHCP"` ao [.filename]#/etc/rc.conf#. Configurações de rede mais avançadas estão descritas em crossref:advanced-networking[advanced-networking, Rede Avançada].
====

[[virtualization-guest-virtualbox]]
== FreeBSD como Sistema Operacional Convidado no VirtualBox(TM)

O FreeBSD funciona bem como um sistema operacional convidado no VirtualBox(TM). O software de virtualização está disponível para a maioria dos sistemas operacionais comuns, incluindo o próprio FreeBSD.

Os complementos de sistema operacional convidado do VirtualBox(TM) fornecem suporte para:

* Compartilhamento de área de transferência.
* Integração do ponteiro do mouse.
* Sincronização de hora com o host.
* Redimensionamento de janela.
* Modo Seamless.

[NOTE]
====
Estes comandos são executados na instancia virtualizada do FreeBSD.
====

Primeiro, instale o pacote ou o port package:emulators/virtualbox-ose-additions[] na instancia virtualizada do FreeBSD. Isso irá instalar o port:

[source,bash]
....
# cd /usr/ports/emulators/virtualbox-ose-additions && make install clean
....

Adicione estas linhas ao [.filename]#/etc/rc.conf#:

[.programlisting]
....
vboxguest_enable="YES"
vboxservice_enable="YES"
....

Se o man:ntpd[8] ou o man:ntpdate[8] estiver sendo utilizado, desabilite a sincronização de horário com o host:

[.programlisting]
....
vboxservice_flags="--disable-timesync"
....

O Xorg reconhecerá automaticamente o driver `vboxvideo`. Ele também pode ser inserido manualmente no [.filename]#/etc/X11/xorg.conf#:

[.programlisting]
....
Section "Device"
	Identifier "Card0"
	Driver "vboxvideo"
	VendorName "InnoTek Systemberatung GmbH"
	BoardName "VirtualBox Graphics Adapter"
EndSection
....

Para usar o driver `vboxmouse`, ajuste a seção do mouse no [.filename]#/etc/X11/xorg.conf#:

[.programlisting]
....
Section "InputDevice"
	Identifier "Mouse0"
	Driver "vboxmouse"
EndSection
....

Usuários do HAL devem criar o arquivo [.filename]#/usr/local/etc/hal/fdi/policy/90-vboxguest.fdi# com o conteúdo abaixo ou copiá-lo de [.filename]#/usr/local/shared/hal/fdi/policy/10osvendor/90-vboxguest.fdi#:

[.programlisting]
....
<?xml version="1.0" encoding="utf-8"?>
<!--
# Sun VirtualBox
# Hal driver description for the vboxmouse driver
# $Id: chapter.xml,v 1.33 2012-03-17 04:53:52 eadler Exp $

	Copyright (C) 2008-2009 Sun Microsystems, Inc.

	This file is part of VirtualBox Open Source Edition (OSE, as
	available from http://www.virtualbox.org. This file is free software;
	you can redistribute it and/or modify it under the terms of the GNU
	General Public License (GPL) as published by the Free Software
	Foundation, in version 2 as it comes in the "COPYING" file of the
	VirtualBox OSE distribution. VirtualBox OSE is distributed in the
	hope that it will be useful, but WITHOUT ANY WARRANTY of any kind.

	Please contact Sun Microsystems, Inc., 4150 Network Circle, Santa
	Clara, CA 95054 USA or visit http://www.sun.com if you need
	additional information or have any questions.
-->
<deviceinfo version="0.2">
  <device>
    <match key="info.subsystem" string="pci">
      <match key="info.product" string="VirtualBox guest Service">
        <append key="info.capabilities" type="strlist">input</append>
	<append key="info.capabilities" type="strlist">input.mouse</append>
        <merge key="input.x11_driver" type="string">vboxmouse</merge>
	<merge key="input.device" type="string">/dev/vboxguest</merge>
      </match>
    </match>
  </device>
</deviceinfo>
....

Pastas compartilhadas para transferências de arquivos entre o host e a VM são acessíveis montando-as usando `mount_vboxvfs`. Uma pasta compartilhada pode ser criada no host usando a GUI do VirtualBox ou via `vboxmanage`. Por exemplo, para criar uma pasta compartilhada chamada _myshare_ em [.filename]#/mnt/bsdboxshare# para a VM denominada _BSDBox_, execute :

[source,bash]
....
# vboxmanage sharedfolder add 'BSDBox' --name myshare --hostpath /mnt/bsdboxshare
....

Observe que o nome da pasta compartilhada não deve conter espaços. Monte a pasta compartilhada de dentro do sistema convidado desta forma:

[source,bash]
....
# mount_vboxvfs -w myshare /mnt
....

[[virtualization-host-virtualbox]]
== FreeBSD como Host com VirtualBox(TM)

O VirtualBox(TM) é um pacote de virtualização completo e ativamente desenvolvido, disponível para a maioria dos sistemas operacionais, incluindo Windows(TM), Mac OS(TM), Linux(TM) e FreeBSD. Ele é igualmente capaz de executar sistemas operacionais convidados como o Windows(TM) ou UNIX(TM)-like. Ele é distribuído como um software de código aberto, mas com componentes de código fechado disponíveis em um pacote de extensão separado. Esses componentes incluem suporte para dispositivos USB 2.0. Maiores informações podem ser encontradas na página wiki sobre http://www.virtualbox.org/wiki/Downloads[Downloads do VirtualBox]. Atualmente, essas extensões não estão disponíveis para o FreeBSD.

[[virtualization-virtualbox-install]]
=== Instalando o VirtualBox(TM)

O VirtualBox(TM) está disponível como um pacote ou port do FreeBSD em package:emulators/virtualbox-ose[]. O port pode ser instalado usando estes comandos:

[source,bash]
....
# cd /usr/ports/emulators/virtualbox-ose
# make install clean
....

Uma opção útil no menu de configuração do port é o conjunto de programas `GuestAdditions`. Eles fornecem vários recursos úteis em sistemas operacionais convidados, como integração de ponteiro de mouse (permitindo que o mouse seja compartilhado entre host e o sistema convidado sem a necessidade de pressionar um atalho de teclado especial para alternar) e renderização de vídeo mais rápida, especialmente em sistemas convidados Windows(TM). Os complementos para os sistemas convidados estão disponíveis no menu menu:Dispositivos[], após a conclusão da instalação do sistema convidado.

Algumas alterações de configuração são necessárias antes do VirtualBox(TM) ser iniciado pela primeira vez. O port instala um módulo de kernel em [.filename]#/boot/modules# o qual deve ser carregado no kernel em execução:

[source,bash]
....
# kldload vboxdrv
....

Para garantir que o módulo seja sempre carregado após uma reinicialização, adicione esta linha ao [.filename]#/boot/loader.conf#:

[.programlisting]
....
vboxdrv_load="YES"
....

Para usar os módulos do kernel que permitem conexões de rede bridged ou host-only, adicione esta linha ao [.filename]#/etc/rc.conf# e reinicie o computador:

[.programlisting]
....
vboxnet_enable="YES"
....

O grupo `vboxusers` é criado durante a instalação do VirtualBox(TM). Todos os usuários que precisam acessar o VirtualBox(TM) deverão ser adicionados como membros desse grupo. O comando `pw` pode ser usado para adicionar novos membros:

[source,bash]
....
# pw groupmod vboxusers -m yourusername
....

As permissões padrão para o [.filename]#/dev/vboxnetctl# são restritivas e precisam ser alteradas para redes em modo Bridged:

[source,bash]
....
# chown root:vboxusers /dev/vboxnetctl
# chmod 0660 /dev/vboxnetctl
....

Para tornar esta permissão permanente, adicione estas linhas ao [.filename]#/etc/devfs.conf#:

[.programlisting]
....
own     vboxnetctl root:vboxusers
perm    vboxnetctl 0660
....

Para iniciar o VirtualBox(TM), digite a partir de uma sessão Xorg:

[source,bash]
....
% VirtualBox
....

Para mais informações sobre como configurar e usar o VirtualBox(TM), consulte o http://www.virtualbox.org[site oficial]. Para obter informações específicas sobre o FreeBSD e instruções para a solução de problemas, consulte a http://wiki.FreeBSD.org/VirtualBox[página relevante no wiki do FreeBSD].

[[virtualization-virtualbox-usb-support]]
=== Suporte USB no VirtualBox(TM)

O VirtualBox(TM) pode ser configurado para passar dispositivos USB para o sistema operacional convidado. O controlador host da versão do OSE está limitado a emular dispositivos USB 1.1 até que o pacote de extensão que suporta dispositivos USB 2.0 e 3.0 esteja disponível no FreeBSD.

Para que o VirtualBox(TM) esteja ciente dos dispositivos USB conectados à máquina, o usuário precisa ser um membro do grupo `operator`.

[source,bash]
....
# pw groupmod operator -m yourusername
....

Em seguida, adicione as seguintes linhas ao [.filename]#/etc/rc.conf#:

[.programlisting]
....
[system=10]
add path 'usb/*' mode 0660 group operator
....

Em seguida, adicione as seguintes linhas ao [.filename]#/etc/rc.conf#:

[.programlisting]
....
devfs_system_ruleset="system"
....

Então reinicie o devfs:

[source,bash]
....
# service devfs restart
....

Reinicie a sessão de login e o VirtualBox(TM) para que essas alterações entrem em vigor e crie os filtros USB conforme necessário.

[[virtualization-virtualbox-host-dvd-cd-access]]
=== Acesso ao drive de DVD/CD no Host VirtualBox(TM)

O acesso às unidades de DVD/CD do Host a partir dos convidados é obtido através do compartilhamento das unidades físicas. Dentro do VirtualBox(TM), isso é configurado a partir da janela Armazenamento nas Configurações da máquina virtual. Se necessário, crie primeiro um dispositivo vazio IDECD/DVD. Em seguida, escolha a unidade do host no menu pop-up para a seleção de unidade virtual de CD/DVD. Uma caixa de seleção rotulada como `Passthrough` será exibida. Isso permitirá que a máquina virtual use o hardware diretamente. Por exemplo, CDs de áudio ou o gravador só funcionará se esta opção estiver selecionada.

O HAL precisa ser executado para que as funções de DVD/CD do VirtualBox(TM) funcionem, então habilite-o no [.filename]#/etc/rc.conf# e inicie-o se ele ainda não estiver em execução:

[.programlisting]
....
hald_enable="YES"
....

[source,bash]
....
# service hald start
....

Para que os usuários possam usar as funções de DVD/CD do VirtualBox(TM), eles precisam acessar [.filename]#/dev/xpt0#, [.filename]#/dev/cdN#, e [.filename]#/dev/passN#. Isso geralmente é obtido tornando o usuário um membro do grupo `operator`. As permissões para esses dispositivos devem ser corrigidas adicionando estas linhas ao [.filename]#/etc/devfs.conf#:

[.programlisting]
....
perm cd* 0660
perm xpt0 0660
perm pass* 0660
....

[source,bash]
....
# service devfs restart
....

[[virtualization-host-bhyve]]
== FreeBSD como um Host bhyve

O hypervisor bhyveBSD-licensed tornou-se parte do sistema base com o FreeBSD 10.0-RELEASE. Este hypervisor suporta uma grande variedade de sistemas operacionais convidados, incluindo FreeBSD, OpenBSD e muitas distribuições Linux(TM). Por padrão, o bhyve fornece acesso ao console serial e não emula um console gráfico. Os recursos de offload de virtualização das CPUs mais recentes são usados para evitar os métodos legados de tradução de instruções e de gerenciamento manual de mapeamentos de memória.

O design do bhyve requer um processador que suporte tabelas de páginas estendidas da Intel(TM) (EPT) ou a Indexação Rápida de Virtualização da AMD(TM) (RVI) ou Tabelas de Páginas Aninhadas (NPT). Hospedar sistemas operacionais convidados Linux(TM) ou convidados FreeBSD com mais de uma vCPU requer suporte a modo irrestrito de VMX (UG). A maioria dos processadores mais recentes, especificamente o Intel(TM)Core(TM) i3/i5/i7 e o Intel(TM)Xeon(TM) E3/E5/E7, suportam esses recursos. O suporte UG foi introduzido com a microarquitetura Westmere da Intel. Para obter uma lista completa dos processadores Intel(TM) que suportam EPT, consulte https://ark.intel.com/content/www/us/en/ark/search/featurefilter.html?productType=873&0_ExtendedPageTables=True[]. O RVI é encontrado na terceira geração e depois nos processadores AMD Opteron(TM) (Barcelona). A maneira mais fácil de saber se um processador suporta o bhyve é executar o `dmesg` ou procurar no [.filename]#/var/run/dmesg.boot# pelo o Sinalizador de recurso do processador `POPCNT` na linha `Features2` para processadores AMD(TM) ou `EPT` e `UG` na linha `VT-x` para os processadores Intel(TM).

[[virtualization-bhyve-prep]]
=== Preparando o host

O primeiro passo para criar uma máquina virtual no bhyve é configurar o sistema host. Primeiro, carregue o módulo do kernel bhyve:

[source,bash]
....
# kldload vmm
....

Em seguida, crie uma interface [.filename]#tap# para o dispositivo de rede na máquina virtual para anexar. Para que o dispositivo de rede participe da rede, crie também uma interface de bridge contendo a interface [.filename]#tap# e a interface física como membros. Neste exemplo, a interface física é _igb0_:

[source,bash]
....
# ifconfig tap0 create
# sysctl net.link.tap.up_on_open=1
net.link.tap.up_on_open: 0 -> 1
# ifconfig bridge0 create
# ifconfig bridge0 addm igb0 addm tap0
# ifconfig bridge0 up
....

[[virtualization-bhyve-freebsd]]
=== Criando um Sistema Operacional Convidado do FreeBSD

Crie um arquivo para usar como o disco virtual da máquina convidada. Especifique o tamanho e o nome do disco virtual:

[source,bash]
....
# truncate -s 16G guest.img
....

Baixe uma imagem de instalação do FreeBSD para instalar:

[source,bash]
....
# fetch ftp://ftp.freebsd.org/pub/FreeBSD/releases/ISO-IMAGES/10.3/FreeBSD-10.3-RELEASE-amd64-bootonly.iso
FreeBSD-10.3-RELEASE-amd64-bootonly.iso       100% of  230 MB  570 kBps 06m17s
....

O FreeBSD vem com um script de exemplo para executar uma máquina virtual com o bhyve. O script iniciará a máquina virtual e a executará em um loop, para que ela seja reiniciada automaticamente se houver falha. O script usa várias opções para controlar a configuração da máquina: `-c` controla o número de CPUs virtuais, `-m` limita a quantidade de memória disponível para o sistema operacional convidado, `-t` define qual dispositivo [.filename]#tap# usar, `-d` indica qual imagem de disco usar, `-i` indica ao bhyve para inicializar a partir da imagem CD em vez do disco, e `-I` define qual imagem de CD deve ser usada. O último parâmetro é o nome da máquina virtual, usada para rastrear as máquinas em execução. Este exemplo inicia a máquina virtual no modo de instalação:

[source,bash]
....
# sh /usr/shared/examples/bhyve/vmrun.sh -c 1 -m 1024M -t tap0 -d guest.img -i -I FreeBSD-10.3-RELEASE-amd64-bootonly.iso guestname
....

A máquina virtual inicializará e iniciará o instalador. Depois de instalar um sistema na máquina virtual, quando o sistema perguntar sobre a inserção em um shell no final da instalação, escolha btn:[Yes].

Reinicialize a máquina virtual. Enquanto a reinicialização da máquina virtual fará o bhyve finalizar, o script [.filename]#vmrun.sh# executa o `bhyve` em um loop e o reiniciará automaticamente. Quando isso acontecer, escolha a opção de reinicialização no menu do carregador de inicialização para escapar do loop. Agora o convidado pode ser iniciado a partir do disco virtual:

[source,bash]
....
# sh /usr/shared/examples/bhyve/vmrun.sh -c 4 -m 1024M -t tap0 -d guest.img guestname
....

[[virtualization-bhyve-linux]]
=== Criando um Sistema Operacional convidado Linux(TM)

Para inicializar sistemas operacionais diferentes do FreeBSD, o port package:sysutils/grub2-bhyve[] deve ser instalada primeiro.

Em seguida, crie um arquivo para usar como o disco virtual da máquina convidada:

[source,bash]
....
# truncate -s 16G linux.img
....

Iniciar uma máquina virtual com o bhyve é um processo de duas etapas. Primeiro um kernel deve ser carregado, então o sistema operacional convidado pode ser iniciado. O kernel Linux(TM) é carregado com o package:sysutils/grub2-bhyve[]. Crie um [.filename]#device.map# que o grub usará para mapear os dispositivos virtuais para os arquivos no sistema host:

[.programlisting]
....
(hd0) ./linux.img
(cd0) ./somelinux.iso
....

Use o package:sysutils/grub2-bhyve[] para carregar o kernel Linux(TM) de uma imagem ISO:

[source,bash]
....
# grub-bhyve -m device.map -r cd0 -M 1024M linuxguest
....

Isto irá iniciar o grub. Se o CD de instalação contiver um [.filename]#grub.cfg#, um menu será exibido. Caso contrário, os arquivos `vmlinuz` e `initrd` devem ser localizados e carregados manualmente:

[source,bash]
....
grub> ls
(hd0) (cd0) (cd0,msdos1) (host)
grub> ls (cd0)/isolinux
boot.cat boot.msg grub.conf initrd.img isolinux.bin isolinux.cfg memtest
splash.jpg TRANS.TBL vesamenu.c32 vmlinuz
grub> linux (cd0)/isolinux/vmlinuz
grub> initrd (cd0)/isolinux/initrd.img
grub> boot
....

Agora que o kernel Linux(TM) está carregado, o sistema convidado pode ser iniciado:

[source,bash]
....
# bhyve -A -H -P -s 0:0,hostbridge -s 1:0,lpc -s 2:0,virtio-net,tap0 -s 3:0,virtio-blk,./linux.img \
    -s 4:0,ahci-cd,./somelinux.iso -l com1,stdio -c 4 -m 1024M linuxguest
....

O sistema inicializará e iniciará o instalador. Depois de instalar um sistema na máquina virtual, reinicialize a máquina virtual. Isso fará com que o bhyve seja encerrado. A instância da máquina virtual precisa ser destruída antes de poder ser iniciada novamente:

[source,bash]
....
# bhyvectl --destroy --vm=linuxguest
....

Agora, o sistema convidado pode ser iniciado diretamente do disco virtual. Carregue o kernel:

[source,bash]
....
# grub-bhyve -m device.map -r hd0,msdos1 -M 1024M linuxguest
grub> ls
(hd0) (hd0,msdos2) (hd0,msdos1) (cd0) (cd0,msdos1) (host)
(lvm/VolGroup-lv_swap) (lvm/VolGroup-lv_root)
grub> ls (hd0,msdos1)/
lost+found/ grub/ efi/ System.map-2.6.32-431.el6.x86_64 config-2.6.32-431.el6.x
86_64 symvers-2.6.32-431.el6.x86_64.gz vmlinuz-2.6.32-431.el6.x86_64
initramfs-2.6.32-431.el6.x86_64.img
grub> linux (hd0,msdos1)/vmlinuz-2.6.32-431.el6.x86_64 root=/dev/mapper/VolGroup-lv_root
grub> initrd (hd0,msdos1)/initramfs-2.6.32-431.el6.x86_64.img
grub> boot
....

Inicialize a máquina virtual:

[source,bash]
....
# bhyve -A -H -P -s 0:0,hostbridge -s 1:0,lpc -s 2:0,virtio-net,tap0 \
    -s 3:0,virtio-blk,./linux.img -l com1,stdio -c 4 -m 1024M linuxguest
....

O Linux(TM) iniciará agora na máquina virtual e, eventualmente, apresentará o prompt de login. Faça o login e use a máquina virtual. Quando terminar, reinicialize a máquina virtual para sair do bhyve. Destrua a instância da máquina virtual:

[source,bash]
....
# bhyvectl --destroy --vm=linuxguest
....

[[virtualization-bhyve-uefi]]
=== Inicializando máquinas virtuais bhyve com Firmware UEFI

Além do bhyveload e do grub-bhyve, o hypervisor bhyve também pode inicializar máquinas virtuais usando o firmware do espaço de usuário UEFI . Esta opção pode suportar sistemas operacionais convidados que não são suportados pelos outros carregadores.

Para utilizar o suporte ao UEFI no bhyve, primeiro obtenha as imagens de firmware UEFI. Isto pode ser feito instalando o port ou pacote package:sysutils/bhyve-firmware[].

Com o firmware no lugar, adicione os sinalizadores `-l bootrom,_/path/to/firmware_` à linha de comando do bhyve. A sintaxe real do bhyve pode se parecer com a seguinte:

[source,bash]
....
# bhyve -AHP -s 0:0,hostbridge -s 1:0,lpc \
-s 2:0,virtio-net,tap1 -s 3:0,virtio-blk,./disk.img \
-s 4:0,ahci-cd,./install.iso -c 4 -m 1024M \
-l bootrom,/usr/local/shared/uefi-firmware/BHYVE_UEFI.fd \
guest
....

O package:sysutils/bhyve-firmware[] também contém um firmware habilitado para CSM, para inicializar sistemas operacionais hóspedes sem suporte à UEFI no modo de BIOS legado:

[source,bash]
....
# bhyve -AHP -s 0:0,hostbridge -s 1:0,lpc \
-s 2:0,virtio-net,tap1 -s 3:0,virtio-blk,./disk.img \
-s 4:0,ahci-cd,./install.iso -c 4 -m 1024M \
-l bootrom,/usr/local/shared/uefi-firmware/BHYVE_UEFI_CSM.fd \
guest
....

[[virtualization-bhyve-framebuffer]]
=== Framebuffer UEFI Gráfico para bhyve

O suporte ao firmware UEFI é particularmente útil em sistemas operacionais convidados predominantemente gráficos, como o Microsoft Windows(TM).

O suporte para o framebuffer UEFI-GOP também pode ser ativado com os sinalizadores `-s 29,fbuf,tcp=_0.0.0.0:5900_`. A resolução do framebuffer pode ser configurada com `w=_800_` e `h=_600_` e o bhyve pode ser instruído para aguardar uma conexão VNC antes de inicializar o sistema operacional convidado adicionando `wait`. O framebuffer pode ser acessado pelo host ou pela rede através do protocolo VNC.

O comando bhyve resultante ficaria assim:

[source,bash]
....
# bhyve -AHP -s 0:0,hostbridge -s 31:0,lpc \
-s 2:0,virtio-net,tap1 -s 3:0,virtio-blk,./disk.img \
-s 4:0,ahci-cd,./install.iso -c 4 -m 1024M \
-s 29,fbuf,tcp=0.0.0.0:5900,w=800,h=600,wait \
-l bootrom,/usr/local/shared/uefi-firmware/BHYVE_UEFI.fd \
guest
....

Observe que, no modo de emulação do BIOS, o framebuffer deixará de receber atualizações quando o controle for passado do firmware para o sistema operacional convidado.

[[virtualization-bhyve-zfs]]
=== Usando o ZFS com os sistemas operacionais convidados no bhyve

Se o ZFS estiver disponível na máquina host, o uso de volumes ZFS em vez de arquivos de imagem de disco pode fornecer benefícios significativos de desempenho para as VMs convidadas. Um volume ZFS pode ser criado por:

[source,bash]
....
# zfs create -V16G -o volmode=dev zroot/linuxdisk0
....

Ao iniciar a VM, especifique o volume ZFS como a unidade de disco:

[source,bash]
....
# bhyve -A -H -P -s 0:0,hostbridge -s 1:0,lpc -s 2:0,virtio-net,tap0 -s3:0,virtio-blk,/dev/zvol/zroot/linuxdisk0 \
    -l com1,stdio -c 4 -m 1024M linuxguest
....

[[virtualization-bhyve-nmdm]]
=== Consoles de máquinas virtuais

É vantajoso executar o console do bhyve em uma ferramenta de gerenciamento de sessão, como o package:sysutils/tmux[] ou package:sysutils/screen[], para que possa desanexar e reanexar o console. Também é possível ter o console do bhyve como um dispositivo de modem nulo o qual pode ser acessado com o comando `cu`. Para fazer isso, carregue o módulo do kernel [.filename]#nmdm# e substitua `-l com1,stdio` with `-l com1,/dev/nmdm0A`. Os dispositivos [.filename]#/dev/nmdm# são criados automaticamente conforme necessário, onde cada um é um par, correspondente às duas extremidades do cabo de modem nulo ([.filename]#/dev/nmdm0A# e [.filename]#/dev/nmdm0B#). Veja man:nmdm[4] para maiores informações.

[source,bash]
....
# kldload nmdm
# bhyve -A -H -P -s 0:0,hostbridge -s 1:0,lpc -s 2:0,virtio-net,tap0 -s 3:0,virtio-blk,./linux.img \
    -l com1,/dev/nmdm0A -c 4 -m 1024M linuxguest
# cu -l /dev/nmdm0B
Connected

Ubuntu 13.10 handbook ttyS0

handbook login:
....

[[virtualization-bhyve-managing]]
=== Gerenciando Máquinas Virtuais

Um nó de dispositivo é criado em [.filename]#/dev/vmm# para cada máquina virtual. Isso permite que o administrador veja facilmente uma lista das máquinas virtuais em execução:

[source,bash]
....
# ls -al /dev/vmm
total 1
dr-xr-xr-x   2 root  wheel    512 Mar 17 12:19 ./
dr-xr-xr-x  14 root  wheel    512 Mar 17 06:38 ../
crw-------   1 root  wheel  0x1a2 Mar 17 12:20 guestname
crw-------   1 root  wheel  0x19f Mar 17 12:19 linuxguest
crw-------   1 root  wheel  0x1a1 Mar 17 12:19 otherguest
....

Uma máquina virtual especificada pode ser destruída usando `bhyvectl`:

[source,bash]
....
# bhyvectl --destroy --vm=guestname
....

[[virtualization-bhyve-onboot]]
=== Configuração Persistente

Para configurar o sistema para iniciar os sistemas operacionais convidados do bhyve no momento da inicialização, as seguintes configurações devem ser feitas nos arquivos especificados:

[.procedure]
====
. [.filename]#/etc/sysctl.conf#
+
[.programlisting]
....
net.link.tap.up_on_open=1
....
+
. [.filename]#/etc/rc.conf#
+
[.programlisting]
....
cloned_interfaces="bridge0 tap0"
ifconfig_bridge0="addm igb0 addm tap0"
kld_list="nmdm vmm"
....
====

[[virtualization-host-xen]]
== FreeBSD como Host Xen(TM)

O Xen é um https://en.wikipedia.org/wiki/Hypervisor#Classification[hypervisor tipo 1] licenciado sob a GPLv2 para arquiteturas Intel(TM) e ARM(TM). O FreeBSD suporta domínios não privilegiados (máquina virtual) nas plataformas i386(TM) e AMD(TM) 64-Bit https://wiki.xenproject.org/wiki/DomU[DomU] e https://en.wikipedia.org/wiki/Amazon_Elastic_Compute_Cloud[Amazon EC2] desde o FreeBSD 8.0 e incluiu o suporte ao domínio de controle Dom0 (host) no FreeBSD 11.0. O suporte para domínios para-virtualizados (PV) foi removido do FreeBSD 11 em favor de domínios virtualizados de hardware (HVM), o que proporciona melhor desempenho.

O Xen(TM) é um hypervisor bare-metal, o que significa que é o primeiro programa carregado após o BIOS. Um convidado especial privilegiado chamado Domain-0 (`Dom0` para abreviar) é então iniciado. O Dom0 usa seus privilégios especiais para acessar diretamente o hardware físico subjacente, tornando-o uma solução de alto desempenho. Ele é capaz de acessar os controladores de disco e adaptadores de rede diretamente. As ferramentas de gerenciamento do Xen(TM) para gerenciar e controlar o hypervisor Xen(TM) também são usadas pelo Dom0 para criar, listar e destruir VMs. Dom0 fornece discos virtuais e recursos de rede para domínios sem privilégios, geralmente chamados de `DomU`. O Xen(TM) Dom0 pode ser comparado ao console de serviço de outras soluções de hypervisor , enquanto o DomU é onde as VMs convidadas são executadas.

O Xen(TM) pode migrar VMs entre diferentes servidores Xen(TM). Quando os dois hosts xen compartilham o mesmo armazenamento subjacente, a migração pode ser feita sem a necessidade de primeiro desligar a VM. Em vez disso, a migração é executada ao vivo enquanto o DomU está em execução e não há necessidade de reiniciá-lo ou planejar um tempo de inatividade. Isso é útil em cenários de manutenção ou em janelas de atualização para garantir que os serviços fornecidos pelo DomU continuem disponiveis. Muitos outros recursos do Xen(TM) estão listados na https://wiki.xenproject.org/wiki/Category:Overview[página wiki com a visão global sobre o Xen]. Note que ainda nem todos os recursos são suportados no FreeBSD.

[[virtualization-host-xen-requirements]]
=== Requisitos de hardware para o Xen(TM) Dom0

Para executar o hypervisor Xen(TM) em um host, são necessárias certas funcionalidades de hardware. Os domínios virtualizados de hardware requerem o suporte à Tabela de Páginas Estendidas (http://en.wikipedia.org/wiki/Extended_Page_Table[EPT]) e à Unidade de Gerenciamento de Memória de Entrada / Saída (http://en.wikipedia.org/wiki/List_of_IOMMU-supporting_hardware[IOMMU]) no processador do host.

[NOTE]
====
Para executar um Xen(TM) Dom0 no FreeBSD, a maquina deve ser inicializada usando o boot legado (BIOS).
====

[[virtualization-host-xen-dom0-setup]]
=== Configuração do Xen(TM) Dom0 Domínio de Controle

Os usuários do FreeBSD 11 devem instalar os pacotes package:emulators/xen-kernel47[] e package:sysutils/xen-tools47[] que são baseados no Xen versão 4.7. Sistemas rodando o FreeBSD-12.0 ou mais novo podem usar o Xen 4.11 fornecido por package:emulators/xen-kernel411[] e package:sysutils/xen-tools411[], respectivamente.

Os arquivos de configuração devem ser editados para preparar o host para a integração do Dom0 após a instalação dos pacotes do Xen. Uma entrada para [.filename]#/etc/sysctl.conf# desabilita o limite de quantas páginas de memória podem ser conectadas. Caso contrário, as VMs do DomU com requisitos de memória mais altos não serão executadas.

[source,bash]
....
# echo 'vm.max_wired=-1' >> /etc/sysctl.conf
....

Outra configuração relacionada à memória envolve a alteração do [.filename]#/etc/login.conf#, configurando a opção `memorylocked` para `unlimited`. Caso contrário, a criação de domínios DomU poderá falhar com erros `Cannot allocate memory`. Depois de fazer a mudança no [.filename]#/etc/login.conf#, execute o comando `cap_mkdb` para atualizar o banco de dados de recursos. Veja crossref:security[security-resourcelimits,Limites de Recursos] para detalhes.

[source,bash]
....
# sed -i '' -e 's/memorylocked=64K/memorylocked=unlimited/' /etc/login.conf
# cap_mkdb /etc/login.conf
....

Adicione uma entrada para o console do Xen(TM) ao [.filename]#/etc/ttys#:

[source,bash]
....
# echo 'xc0     "/usr/libexec/getty Pc"         xterm   onifconsole  secure' >> /etc/ttys
....

A seleção de um kernel Xen(TM) no [.filename]#/boot/loader.conf# ativa o Dom0. O Xen(TM) também requer recursos como CPU e memória da máquina host para ele mesmo e para outros domínios DomU. Quanto de CPU e memória depende dos requisitos individuais e das capacidades de hardware. Neste exemplo, 8 GB de memória e 4 CPUs virtuais são disponibilizados para o Dom0. O console serial também é ativado e as opções de log são definidas.

O seguinte comando é usado para pacotes Xen 4.7:

[source,bash]
....
# sysrc -f /boot/loader.conf hw.pci.mcfg=0
# sysrc -f /boot/loader.conf if_tap_load="YES"
# sysrc -f /boot/loader.conf xen_kernel="/boot/xen"
# sysrc -f /boot/loader.conf xen_cmdline="dom0_mem=8192M dom0_max_vcpus=4 dom0pvh=1 console=com1,vga com1=115200,8n1 guest_loglvl=all loglvl=all"
....

Para as versões Xen 4.11 e superiores, o seguinte comando deve ser usado:

[source,bash]
....
# sysrc -f /boot/loader.conf if_tap_load="YES"
# sysrc -f /boot/loader.conf xen_kernel="/boot/xen"
# sysrc -f /boot/loader.conf xen_cmdline="dom0_mem=8192M dom0_max_vcpus=4 dom0=pvh console=com1,vga com1=115200,8n1 guest_loglvl=all loglvl=all"
....

[TIP]
====

Os arquivos de log criados pelo Xen(TM) para as VMs do DomU são armazenados em [.filename]#/var/log/xen#. Por favor, certifique-se de verificar o conteúdo do diretório em caso de problemas.
====

Ative o serviço xencommons durante a inicialização do sistema:

[source,bash]
....
# sysrc xencommons_enable=yes
....

Essas configurações são suficientes para iniciar um sistema habilitado para Dom0. No entanto, falta a funcionalidade de rede para as máquinas DomU. Para corrigir isso, defina uma interface em bridge com a NIC principal do sistema que as VMs DomU poderão usar para se conectar à rede. Substitua _em0_ pelo nome da interface de rede do host.

[source,bash]
....
# sysrc cloned_interfaces="bridge0"
# sysrc ifconfig_bridge0="addm em0 SYNCDHCP"
# sysrc ifconfig_em0="up"
....

Reinicie o host para carregar o kernel Xen(TM) e inicie o Dom0.

[source,bash]
....
# reboot
....

Após inicializar com sucesso o kernel Xen(TM) e efetuar login no sistema novamente, a ferramenta de gerenciamento do Xen(TM), `xl` é usada para mostrar informações sobre os domínios.

[source,bash]
....
# xl list
Name                                        ID   Mem VCPUs      State   Time(s)
Domain-0                                     0  8192     4     r-----     962.0
....

A saída confirma que o Dom0 (chamado `Domain-0`) tem o ID `0` e está em execução. Ele também possui a memória e as CPUs virtuais que foram definidas anteriormente no [.filename]#/boot/loader.conf#. Mais informações podem ser encontradas na https://www.xenproject.org/help/documentation.html[Documentação do Xen]. Agora as VMs convidadas do DomU podem ser criadas.

[[virtualization-host-xen-domu-setup]]
=== Configuração da VM Convidada Xen(TM) DomU

Domínios desprivilegiados consistem em um arquivo de configuração e discos rígidos virtuais ou físicos. Os discos virtuais para armazenamento do DomU podem ser arquivos criados pelo man:truncate[1] ou volumes ZFS, conforme descrito em crossref:zfs[zfs-zfs-volume,Criando e Destruindo Volumes]. Neste exemplo, um volume de 20 GB é usado. Uma VM é criada com o volume ZFS, uma imagem ISO do FreeBSD, 1 GB de RAM e duas CPUs virtuais. O arquivo ISO de instalação é obtido com o man:fetch[1] e salvo localmente em um arquivo chamado [.filename]#freebsd.iso#.

[source,bash]
....
# fetch ftp://ftp.freebsd.org/pub/FreeBSD/releases/ISO-IMAGES/12.0/FreeBSD-12.0-RELEASE-amd64-bootonly.iso -o freebsd.iso
....

Um volume de 20 GB do ZFS chamado [.filename]#xendisk0# é criado para servir como espaço em disco para a VM.

[source,bash]
....
# zfs create -V20G -o volmode=dev zroot/xendisk0
....

A nova VM DomU convidada é definida em um arquivo. Algumas definições específicas, como nome, mapa de teclado e detalhes da conexão VNC, também são definidas. O seguinte [.filename]#freebsd.cfg# contém uma configuração mínima de DomU para este exemplo:

[source,bash]
....
# cat freebsd.cfg
builder = "hvm" <.>
name = "freebsd" <.>
memory = 1024 <.>
vcpus = 2 <.>
vif = [ 'mac=00:16:3E:74:34:32,bridge=bridge0' ] <.>
disk = [
'/dev/zvol/tank/xendisk0,raw,hda,rw', <.>
'/root/freebsd.iso,raw,hdc:cdrom,r' <.>
  ]
vnc = 1 <.>
vnclisten = "0.0.0.0"
serial = "pty"
usbdevice = "tablet"
....

Estas linhas são explicadas com mais detalhes:

<.> Isso define que tipo de virtualização usar. `hvm` refere-se à virtualização assistida por hardware ou à máquina virtual de hardware. Os sistemas operacionais convidados podem ser executados sem modificação em CPUs com extensões de virtualização, fornecendo quase o mesmo desempenho que a execução em hardware físico. `generic` é o valor padrão e cria um domínio PV.

<.> Nome desta máquina virtual para distingui-la de outras executadas no mesmo Dom0. Requerido.

<.> Quantidade de RAM em megabytes para disponibilizar para a VM. Esse valor é subtraído da memória total disponível do hypervisor, não da memória do Dom0.

<.> Número de CPUs virtuais disponíveis para a VM convidada. Para um melhor desempenho, não crie convidados com mais CPUs virtuais do que o número de CPUs físicas no host.

<.> Adaptador de rede virtual. Esta é a bridge conectada à interface de rede do host. O parâmetro `mac` é o endereço MAC definido na interface de rede virtual. Este parâmetro é opcional, se nenhum MAC for fornecido, o Xen(TM) irá gerar um aleatório.

<.> Caminho completo para o disco, arquivo ou volume ZFS do armazenamento em disco para essa VM. As opções e as várias definições de disco são separadas por vírgulas.

<.> Define o meio de inicialização a partir do qual o sistema operacional inicial é instalado. Neste exemplo, é a imagem ISO baixada anteriormente. Consulte a documentação do Xen(TM) para outros tipos de dispositivos e outras opções para configurar.

<.> Opções que controlam a conectividade do VNC para o console serial do DomU. Em ordem, estes são: ativa suporte ao VNC, define o endereço IP no qual escutar, device node para o console serial e o método de entrada para posicionamento preciso do mouse e outros métodos de entrada. `keymap` define qual mapa de teclas usar, sendo `english` por padrão.

Após o arquivo ter sido criado com todas as opções necessárias, o DomU é criado passando-o como um parâmetro para o comando `xl create`.

[source,bash]
....
# xl create freebsd.cfg
....

[NOTE]
====
Cada vez que o Dom0 é reiniciado, o arquivo de configuração deve ser passado para `xl create` novamente para recriar o DomU. Por padrão, somente o Dom0 é criado após uma reinicialização, não as VMs individuais. As VMs podem continuar de onde pararam, pois armazenaram o sistema operacional no disco virtual. A configuração da máquina virtual pode mudar com o tempo (por exemplo, ao adicionar mais memória). Os arquivos de configuração da máquina virtual devem ter um backup e manter-se disponíveis para poder recriar a VM convidada quando necessário.
====

A saída de `xl list` confirma que o DomU foi criado.

[source,bash]
....
# xl list
Name                                        ID   Mem VCPUs      State   Time(s)
Domain-0                                     0  8192     4     r-----  1653.4
freebsd                                      1  1024     1     -b----   663.9
....

Para iniciar a instalação do sistema operacional base, inicie o cliente VNC, direcionando-o para o endereço de rede principal do host ou para o endereço IP definido na linha `vnclisten` do [.filename]#freebsd.cfg#. Depois que o sistema operacional tiver sido instalado, desligue o DomU e desconecte o visualizador VNC. Edite o [.filename]#freebsd.cfg#, removendo a linha com a definição `cdrom` ou comentando-a inserindo um caractere `#` no início da linha. Para carregar esta nova configuração, é necessário remover o DomU antigo com `xl destroy`, passando o nome ou o id como parâmetro. Depois, recrie-o usando o [.filename]##freebsd.cfg## modificado.

[source,bash]
....
# xl destroy freebsd
# xl create freebsd.cfg
....

A máquina pode então ser acessada novamente usando o visualizador VNC. Desta vez, ele será inicializado a partir do disco virtual em que o sistema operacional foi instalado e pode ser usado como uma máquina virtual.

[[virtualization-host-xen-troubleshooting]]
=== Solução de problemas

Esta seção contém informações básicas para ajudar a solucionar problemas encontrados ao usar o FreeBSD como host ou convidado do Xen(TM).

[[virtualization-host-xen-troubleshooting-host]]
==== Solução de problemas de inicialização do host

Observe que as dicas de solução de problemas a seguir são destinadas ao Xen(TM) 4.11 ou mais recente. Se você ainda estiver usando o Xen(TM) 4.7 e tendo problemas, considere migrar para uma versão mais recente do Xen(TM).

Para solucionar problemas de inicialização do host, você provavelmente precisará de um cabo serial ou de um cabo USB de depuração. Uma saída de boot verbosa do Xen(TM) pode ser obtida adicionando-se parametros à opção `xen_cmdline` encontrada no [.filename]#loader.conf#. Alguns parametros de depuração relevantes são:

* `iommu=debug`: pode ser usado para imprimir informações de diagnóstico adicionais sobre o iommu.
* `dom0=verbose`: pode ser usado para imprimir informações de diagnóstico adicionais sobre o processo de compilação dom0.
* `sync_console`: flag para forçar a saída síncrona do console. Útil para depuração para evitar a perda de mensagens devido à limitação de taxa. Nunca use essa opção em ambientes de produção, pois ela pode permitir que convidados mal-intencionados realizem ataques DoS contra o Xen(TM) usando o console.

O FreeBSD também deve ser inicializado no modo verbose para identificar quaisquer problemas. Para ativar a inicialização detalhada, execute este comando:

[source,bash]
....
# sysrc -f /boot/loader.conf boot_verbose="YES"
....

Se nenhuma dessas opções ajudar a resolver o problema, envie o registro de inicialização serial para mailto:freebsd-xen@FreeBSD.org[freebsd-xen@FreeBSD.org] e mailto:xen-devel@lists.xenproject.org[xen-devel@lists.xenproject.org] para uma análise mais aprofundada.

[[virtualization-host-xen-troubleshooting-guest]]
==== Solução de problemas na criação de VMs convidadas

Problemas também podem surgir ao criar convidados, as informações a seguir tentam fornecer alguma ajuda para aqueles que precisarem diagnosticar problemas de criação de convidados.

A causa mais comum de falhas na criação de convidados é o comando `xl` cuspindo algum erro e saindo com um código de retorno diferente de 0. Se o erro fornecido não for suficiente para ajudar a identificar o problema, uma saída mais detalhada pode ser obtida do comando `xl` usando-se a opção `v` repetidamente.

[source,bash]
....
# xl -vvv create freebsd.cfg
Parsing config from freebsd.cfg
libxl: debug: libxl_create.c:1693:do_domain_create: Domain 0:ao 0x800d750a0: create: how=0x0 callback=0x0 poller=0x800d6f0f0
libxl: debug: libxl_device.c:397:libxl__device_disk_set_backend: Disk vdev=xvda spec.backend=unknown
libxl: debug: libxl_device.c:432:libxl__device_disk_set_backend: Disk vdev=xvda, using backend phy
libxl: debug: libxl_create.c:1018:initiate_domain_create: Domain 1:running bootloader
libxl: debug: libxl_bootloader.c:328:libxl__bootloader_run: Domain 1:not a PV/PVH domain, skipping bootloader
libxl: debug: libxl_event.c:689:libxl__ev_xswatch_deregister: watch w=0x800d96b98: deregister unregistered
domainbuilder: detail: xc_dom_allocate: cmdline="", features=""
domainbuilder: detail: xc_dom_kernel_file: filename="/usr/local/lib/xen/boot/hvmloader"
domainbuilder: detail: xc_dom_malloc_filemap    : 326 kB
libxl: debug: libxl_dom.c:988:libxl__load_hvm_firmware_module: Loading BIOS: /usr/local/shared/seabios/bios.bin
...
....

Se a saída detalhada não ajudar a diagnosticar o problema, verifique também os logs do toolstack QEMU e do Xen(TM) em [.filename]#/var/log/xen#. Observe que o nome do domínio é anexado ao nome do registro, portanto, se o domínio tiver o nome `freebsd`, você deverá encontrar um [.filename]#/var/log/xen/xl-freebsd.log# e provavelmente um [.filename]#/var/log/xen/qemu-dm-freebsd.log#. Ambos os arquivos de log podem conter informações úteis para a depuração. Se nada disso ajudar a resolver o problema, envie a descrição do problema que você está enfrentando e o máximo de informações possíveis para mailto:freebsd-xen@FreeBSD.org[freebsd-xen@FreeBSD.org] e mailto:xen-devel@lists.xenproject.org[xen-devel@lists.xenproject.org] para obter ajuda.
